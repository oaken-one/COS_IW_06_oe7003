{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TYZMi0LROEfkO3SMhB3T3FCrmecTIVkE",
      "authorship_tag": "ABX9TyM1BF+zKvAzsZR3HG8gi/EQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaken-one/COS_IW_06_oe7003/blob/main/Independent_Work_Code_Using_Machine_Learning_Models_to_Predict_Discharging_Capacity_in_Lithium_Ion_Batteries_OkezieEze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsM8IYaSZe4-",
        "outputId": "a1bd30a3-e433-4951-a28b-d6bd987c152b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Uploading MATLAB files\n",
        "import scipy.io as sio\n",
        "bat05 = sio.loadmat(\"/content/drive/MyDrive/NASA Battery Data/B0005.ordered.mat\")\n",
        "bat06 = sio.loadmat(\"/content/drive/MyDrive/NASA Battery Data/B0006.ordered.mat\")"
      ],
      "metadata": {
        "id": "Ove8LV6bW-8q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Constant Current Charging Voltage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ccvB0005 = np.zeros([167, 5])\n",
        "ccvB0006 = np.zeros([167, 5])\n",
        "\n",
        "## Find the maximum and minimum values of Constant Current Charging Voltage\n",
        "ccvB0005_max = bat05['B0005'][0,0]['cycle'][0,0]['data'][0,0]['Voltage_measured'].max()\n",
        "ccvB0005_min = bat05['B0005'][0,0]['cycle'][0,0]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "ccvB0006_max = bat06['B0006'][0,0]['cycle'][0,0]['data'][0,0]['Voltage_measured'].max()\n",
        "ccvB0006_min = bat06['B0006'][0,0]['cycle'][0,0]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "for x in range(167):\n",
        "  if ccvB0005_max < bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max():\n",
        "    ccvB0005_max = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max()\n",
        "\n",
        "for x in range(167):\n",
        "  if ccvB0006_max < bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max():\n",
        "    ccvB0006_max = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max()\n",
        "\n",
        "for x in range(167):\n",
        "  if ccvB0005_min > bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min():\n",
        "    ccvB0005_min = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "for x in range(167):\n",
        "  if ccvB0006_min > bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min():\n",
        "    ccvB0006_min = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "## Choose specific points for training models and normalize them\n",
        "for x in range(167):\n",
        "  ccvB0005[x, 0] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 3] - ccvB0005_min)/(ccvB0005_max - ccvB0005_min)\n",
        "  ccvB0005[x, 1] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 36] - ccvB0005_min)/(ccvB0005_max - ccvB0005_min)\n",
        "  ccvB0005[x, 2] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 69] - ccvB0005_min)/(ccvB0005_max - ccvB0005_min)\n",
        "  ccvB0005[x, 3] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 127] - ccvB0005_min)/(ccvB0005_max - ccvB0005_min)\n",
        "  ccvB0005[x, 4] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 249] - ccvB0005_min)/(ccvB0005_max - ccvB0005_min)\n",
        "\n",
        "for x in range(167):\n",
        "  ccvB0006[x, 0] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 3] - ccvB0006_min)/(ccvB0006_max - ccvB0006_min)\n",
        "  ccvB0006[x, 1] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 36] - ccvB0006_min)/(ccvB0006_max - ccvB0006_min)\n",
        "  ccvB0006[x, 2] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 69] - ccvB0006_min)/(ccvB0006_max - ccvB0006_min)\n",
        "  ccvB0006[x, 3] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 127] - ccvB0006_min)/(ccvB0006_max - ccvB0006_min)\n",
        "  ccvB0006[x, 4] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'][0, 249] - ccvB0006_min)/(ccvB0006_max - ccvB0006_min)"
      ],
      "metadata": {
        "id": "UvykHs2T-t4S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Constant Voltage Charging Current\n",
        "cvccB0005 = np.zeros([167, 5])\n",
        "cvccB0006 = np.zeros([167, 5])\n",
        "\n",
        "## Find the maximum and minimum values of Constant Voltage Charging Current\n",
        "cvccB0005_max = bat05['B0005'][0,0]['cycle'][0,0]['data'][0,0]['Current_measured'].max()\n",
        "cvccB0005_min = bat05['B0005'][0,0]['cycle'][0,0]['data'][0,0]['Current_measured'].min()\n",
        "\n",
        "cvccB0006_max = bat06['B0006'][0,0]['cycle'][0,0]['data'][0,0]['Current_measured'].max()\n",
        "cvccB0006_min = bat06['B0006'][0,0]['cycle'][0,0]['data'][0,0]['Current_measured'].min()\n",
        "\n",
        "for x in range(167):\n",
        "  if cvccB0005_max < bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].max():\n",
        "    cvccB0005_max = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].max()\n",
        "\n",
        "for x in range(167):\n",
        "  if cvccB0006_max < bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].max():\n",
        "    cvccB0006_max = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].max()\n",
        "\n",
        "for x in range(167):\n",
        "  if cvccB0005_min > bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].min():\n",
        "    cvccB0005_min = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].min()\n",
        "\n",
        "for x in range(167):\n",
        "  if cvccB0006_min > bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].min():\n",
        "    cvccB0006_min = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'].min()\n",
        "\n",
        "## Choose specific points for training models and normalize them (cycle 32 does not have the same shape as other cycles and must be handled differently)\n",
        "for x in range(167):\n",
        "  if x == 32:\n",
        "    cvccB0005[x, 0] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 4] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 1] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 8] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 2] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 13] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 3] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 28] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 4] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 32] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "  if x != 32:\n",
        "    cvccB0005[x, 0] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 518] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 1] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 535] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 2] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 557] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 3] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 573] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "    cvccB0005[x, 4] = (bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 594] - cvccB0005_min)/(cvccB0005_max - cvccB0005_min)\n",
        "\n",
        "for x in range(167):\n",
        "  if x == 32:\n",
        "    cvccB0006[x, 0] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 4] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 1] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 8] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 2] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 13] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 3] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 28] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 4] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 32] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "  if x != 32:\n",
        "    cvccB0006[x, 0] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 518] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 1] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 535] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 2] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 557] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 3] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 573] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)\n",
        "    cvccB0006[x, 4] = (bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Current_measured'][0, 594] - cvccB0006_min)/(cvccB0006_max - cvccB0006_min)"
      ],
      "metadata": {
        "id": "pY8oKU9CogZ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Constant Current Charging Time\n",
        "ccctB0005 = np.zeros([167, 1])\n",
        "ccctB0006 = np.zeros([167, 1])\n",
        "\n",
        "for x in range(167):\n",
        "  max_voltage_index_B5 = np.argmax(bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'])\n",
        "  ccctB0005[x,0] = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Time'][0, max_voltage_index_B5]\n",
        "\n",
        "for x in range(167):\n",
        "  max_voltage_index_B6 = np.argmax(bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'])\n",
        "  ccctB0006[x,0] = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Time'][0, max_voltage_index_B6]\n",
        "\n",
        "## Find the maximum and minimum values of Constant Current Charging Time\n",
        "ccct_B5_max = ccctB0005.max()\n",
        "ccct_B5_min = ccctB0005.min()\n",
        "\n",
        "ccct_B6_max = ccctB0006.max()\n",
        "ccct_B6_min = ccctB0006.min()\n",
        "\n",
        "## Choose specific points for training models and normalize them\n",
        "for x in range(167):\n",
        "  ccctB0005[x,0] = (ccctB0005[x,0] - ccct_B5_min)/(ccct_B5_max - ccct_B5_min)\n",
        "  ccctB0006[x,0] = (ccctB0006[x,0] - ccct_B6_min)/(ccct_B6_max - ccct_B6_min)"
      ],
      "metadata": {
        "id": "E3Pf3BsYEdpI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Constant Voltage Discharging Current\n",
        "ccdvB0005 = np.zeros([167, 5])\n",
        "ccdvB0006 = np.zeros([167, 5])\n",
        "\n",
        "## Find the maximum and minimum values of Constant Voltage Discharging Current\n",
        "ccdvB0005_max = bat05['B0005'][0,0]['cycle'][0,170]['data'][0,0]['Voltage_measured'].max()\n",
        "ccdvB0005_min = bat05['B0005'][0,0]['cycle'][0,170]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "ccdvB0006_max = bat06['B0006'][0,0]['cycle'][0,170]['data'][0,0]['Voltage_measured'].max()\n",
        "ccdvB0006_min = bat06['B0006'][0,0]['cycle'][0,170]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "for x in range(170, 338):\n",
        "  if ccdvB0005_max < bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max():\n",
        "    ccdvB0005_max = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max()\n",
        "\n",
        "for x in range(170, 338):\n",
        "  if ccdvB0006_max < bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max():\n",
        "    ccdvB0006_max = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].max()\n",
        "\n",
        "for x in range(170, 338):\n",
        "  if ccdvB0005_min > bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min():\n",
        "    ccdvB0005_min = bat05['B0005'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "for x in range(170, 338):\n",
        "  if ccdvB0006_min > bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min():\n",
        "    ccdvB0006_min = bat06['B0006'][0,0]['cycle'][0,x]['data'][0,0]['Voltage_measured'].min()\n",
        "\n",
        "## Choose specific points for training models and normalize them\n",
        "for x in range(167):\n",
        "  ccdvB0005[x, 0] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 99] - ccdvB0005_min)/(ccdvB0005_max - ccdvB0005_min)\n",
        "  ccdvB0005[x, 1] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 110] - ccdvB0005_min)/(ccdvB0005_max - ccdvB0005_min)\n",
        "  ccdvB0005[x, 2] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 115] - ccdvB0005_min)/(ccdvB0005_max - ccdvB0005_min)\n",
        "  ccdvB0005[x, 3] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 121] - ccdvB0005_min)/(ccdvB0005_max - ccdvB0005_min)\n",
        "  ccdvB0005[x, 4] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 126] - ccdvB0005_min)/(ccdvB0005_max - ccdvB0005_min)\n",
        "\n",
        "for x in range(167):\n",
        "  ccdvB0006[x, 0] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 99] - ccdvB0006_min)/(ccdvB0006_max - ccdvB0006_min)\n",
        "  ccdvB0006[x, 1] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 110] - ccdvB0006_min)/(ccdvB0006_max - ccdvB0006_min)\n",
        "  ccdvB0006[x, 2] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 115] - ccdvB0006_min)/(ccdvB0006_max - ccdvB0006_min)\n",
        "  ccdvB0006[x, 3] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 121] - ccdvB0006_min)/(ccdvB0006_max - ccdvB0006_min)\n",
        "  ccdvB0006[x, 4] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 126] - ccdvB0006_min)/(ccdvB0006_max - ccdvB0006_min)\n"
      ],
      "metadata": {
        "id": "UOxQdREqL9wi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Constant Current Discharging Time\n",
        "ccdtB0005 = np.zeros([167, 1])\n",
        "ccdtB0006 = np.zeros([167, 1])\n",
        "\n",
        "for x in range(167):\n",
        "  max_voltage_index_B5 = np.argmax(bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'])\n",
        "  ccdtB0005[x,0] = bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, max_voltage_index_B5]\n",
        "\n",
        "for x in range(167):\n",
        "  max_voltage_index_B6 = np.argmax(bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'])\n",
        "  ccdtB0006[x,0] = bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, max_voltage_index_B6]\n",
        "\n",
        "## Find the maximum and minimum values of Constant Current Discharging Time\n",
        "ccdt_B5_max = ccdtB0005.max()\n",
        "ccdt_B5_min = ccdtB0005.min()\n",
        "\n",
        "ccdt_B6_max = ccdtB0006.max()\n",
        "ccdt_B6_min = ccdtB0006.min()\n",
        "\n",
        "## Choose specific points for training models and normalize them\n",
        "for x in range(167):\n",
        "  ccdtB0005[x,0] = (ccdtB0005[x,0] - ccdt_B5_min)/(ccdt_B5_max - ccdt_B5_min)\n",
        "  ccdtB0006[x,0] = (ccdtB0006[x,0] - ccdt_B6_min)/(ccdt_B6_max - ccdt_B6_min)"
      ],
      "metadata": {
        "id": "hhVriKaPUY4U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocessing Rate of Change of Discharging Voltage\n",
        "ccdv_roc_B0005 = np.zeros([167, 4])\n",
        "ccdv_roc_B0006 = np.zeros([167, 4])\n",
        "\n",
        "for x in range(167):\n",
        "  ccdv_roc_B0005[x, 0] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 110] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 99])/(bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 110] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 99])\n",
        "  ccdv_roc_B0005[x, 1] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 115] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 110])/(bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 115] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 110])\n",
        "  ccdv_roc_B0005[x, 2] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 121] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 115])/(bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 121] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 115])\n",
        "  ccdv_roc_B0005[x, 3] = (bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 126] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 121])/(bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 126] - bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 121])\n",
        "\n",
        "  ccdv_roc_B0006[x, 0] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 110] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 99])/(bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 110] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 99])\n",
        "  ccdv_roc_B0006[x, 1] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 115] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 110])/(bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 115] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 110])\n",
        "  ccdv_roc_B0006[x, 2] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 121] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 115])/(bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 121] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 115])\n",
        "  ccdv_roc_B0006[x, 3] = (bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 126] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Voltage_measured'][0, 121])/(bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 126] - bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Time'][0, 121])\n",
        "\n",
        "## Find the maximum and minimum values of Rate of Change of Discharging Voltage\n",
        "ccdv_roc_B0005_max = ccdv_roc_B0005.max()\n",
        "ccdv_roc_B0005_min = ccdv_roc_B0005.min()\n",
        "\n",
        "ccdv_roc_B0006_max = ccdv_roc_B0006.max()\n",
        "ccdv_roc_B0006_min = ccdv_roc_B0006.min()\n",
        "\n",
        "## Choose specific points for training models and normalize them\n",
        "for x in range(167):\n",
        "  ccdv_roc_B0005[x, 0] = (ccdv_roc_B0005[x, 0] - ccdv_roc_B0005_min)/(ccdv_roc_B0005_max - ccdv_roc_B0005_min)\n",
        "  ccdv_roc_B0005[x, 1] = (ccdv_roc_B0005[x, 1] - ccdv_roc_B0005_min)/(ccdv_roc_B0005_max - ccdv_roc_B0005_min)\n",
        "  ccdv_roc_B0005[x, 2] = (ccdv_roc_B0005[x, 2] - ccdv_roc_B0005_min)/(ccdv_roc_B0005_max - ccdv_roc_B0005_min)\n",
        "  ccdv_roc_B0005[x, 3] = (ccdv_roc_B0005[x, 3] - ccdv_roc_B0005_min)/(ccdv_roc_B0005_max - ccdv_roc_B0005_min)\n",
        "\n",
        "  ccdv_roc_B0006[x, 0] = (ccdv_roc_B0006[x, 0] - ccdv_roc_B0006_min)/(ccdv_roc_B0006_max - ccdv_roc_B0006_min)\n",
        "  ccdv_roc_B0006[x, 1] = (ccdv_roc_B0006[x, 1] - ccdv_roc_B0006_min)/(ccdv_roc_B0006_max - ccdv_roc_B0006_min)\n",
        "  ccdv_roc_B0006[x, 2] = (ccdv_roc_B0006[x, 2] - ccdv_roc_B0006_min)/(ccdv_roc_B0006_max - ccdv_roc_B0006_min)\n",
        "  ccdv_roc_B0006[x, 3] = (ccdv_roc_B0006[x, 3] - ccdv_roc_B0006_min)/(ccdv_roc_B0006_max - ccdv_roc_B0006_min)"
      ],
      "metadata": {
        "id": "zdv-zDFFWDmo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocesing Discharging Capacity\n",
        "dcB0005 = np.zeros([167, 1])\n",
        "dcB0006 = np.zeros([167, 1])\n",
        "dcInputB0005 = np.zeros([167, 1])\n",
        "dcInputB0006 = np.zeros([167, 1])\n",
        "\n",
        "for x in range(167):\n",
        "  dcB0005[x, 0] = bat05['B0005'][0,0]['cycle'][0,x + 170]['data'][0,0]['Capacity'][0,0]\n",
        "  dcB0006[x, 0] = bat06['B0006'][0,0]['cycle'][0,x + 170]['data'][0,0]['Capacity'][0,0]\n",
        "\n",
        "## Find the maximum and minimum values of Discharging Capacity\n",
        "dcB0005_max = dcB0005.max()\n",
        "dcB0006_max = dcB0006.max()\n",
        "dcB0005_min = dcB0005.min()\n",
        "dcB0006_min = dcB0006.min()\n",
        "\n",
        "## Choose specific points for training models and normalize them\n",
        "for x in range(167):\n",
        "  dcInputB0005[x, 0] = (dcB0005[x, 0] - dcB0005_min)/(dcB0005_max - dcB0005_min)\n",
        "  dcInputB0006[x, 0] = (dcB0006[x, 0] - dcB0006_min)/(dcB0006_max - dcB0006_min)"
      ],
      "metadata": {
        "id": "JKGyhceAEXT8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 1 (Inputs are CCCT and CCV)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt92IV_jR2ik",
        "outputId": "b81f37cf-3e46-411f-9216-1ee25823db34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.19272419774141278\n",
            "MAE: 0.4049060749094907\n",
            "R^2: -18.834480577934034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 2 (Inputs are Discharging Capacity and CVCC)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFVAEpNAPiGL",
        "outputId": "62fff409-f64d-468c-9d9a-d41e57d5123e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.003936459240739472\n",
            "MAE: 0.04637880948447572\n",
            "R^2: 0.5948737871461451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 3 (Inputs are Discharging Capacity, CCCT, and CCV)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeJldQkYP0kM",
        "outputId": "5119c826-7c39-460c-e194-959c44f6c2f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.02313528327127691\n",
            "MAE: 0.1222239532627117\n",
            "R^2: -1.3810000616779852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 4 (Inputs are Discharging Capacity, CCCT, CCV, and CVCC)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "id": "wMdyUvbthFcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78613443-2a1d-43cc-ed76-d767f657857e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.021423571272003963\n",
            "MAE: 0.1143413805623242\n",
            "R^2: -1.2048368252890111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 5 (Inputs are CCDT and CCDV)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQyJbcHkP6ZF",
        "outputId": "26c9d297-bee4-4477-98c4-a0403823409e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.10433688432085234\n",
            "MAE: 0.3020994735065836\n",
            "R^2: -9.737976496344269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 6 (Inputs are CCDV and RoCV)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbOs6T8tUuF4",
        "outputId": "236ddfed-0084-4f72-85e9-50e41b1b4f7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.004546387363834529\n",
            "MAE: 0.055570130923738574\n",
            "R^2: 0.5321021806056079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 7 (Inputs are Discharging Capacity, CCDT, and CCDV)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVhWZ_9tZBwx",
        "outputId": "870ac445-8a15-4b7c-c89e-d4c6808535ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.00811091149302768\n",
            "MAE: 0.07036350201336979\n",
            "R^2: 0.16525419037595868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Regression Model with Case 8 (Inputs are Discharging Capacity, CCDT, CCDV, and RoCV)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ6o5htXbDg0",
        "outputId": "a89b96f8-3bee-4f55-bb6c-9cbd04328f4b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0007072429236683814\n",
            "MAE: 0.02029747652312289\n",
            "R^2: 0.9272131045412182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 1 (Inputs are CCCT and CCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSy4_V8MkDzh",
        "outputId": "938bd2ab-e35f-4a24-ec32-c80c8117d7f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 54ms/step - loss: 6.4042 - val_loss: 2.3185\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.1751 - val_loss: 2.3597\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.4033 - val_loss: 2.3637\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7339 - val_loss: 2.2878\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.9547 - val_loss: 2.1814\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.5348 - val_loss: 2.1265\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.7354 - val_loss: 2.0795\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.3561 - val_loss: 2.0334\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9233 - val_loss: 1.9691\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.5707 - val_loss: 1.9045\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9378 - val_loss: 1.8259\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.6094 - val_loss: 1.7222\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.3193 - val_loss: 1.6175\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.8558 - val_loss: 1.5283\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8337 - val_loss: 1.4969\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4296 - val_loss: 1.4539\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5276 - val_loss: 1.4078\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.7331 - val_loss: 1.3932\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.1208 - val_loss: 1.3729\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.9065 - val_loss: 1.3273\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.3381 - val_loss: 1.2686\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2118 - val_loss: 1.2472\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6087 - val_loss: 1.1930\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.3774 - val_loss: 1.1186\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3391 - val_loss: 1.0606\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0828 - val_loss: 1.0214\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.1636 - val_loss: 1.0046\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1065 - val_loss: 0.9837\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5938 - val_loss: 0.9654\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0706 - val_loss: 0.9615\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1636 - val_loss: 0.9641\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4371 - val_loss: 0.9757\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9337 - val_loss: 0.9769\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0804 - val_loss: 0.9403\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8235 - val_loss: 0.9181\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.5055 - val_loss: 0.9038\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9497 - val_loss: 0.8822\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8381 - val_loss: 0.8264\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2721 - val_loss: 0.7751\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5288 - val_loss: 0.7458\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9562 - val_loss: 0.7235\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3006 - val_loss: 0.7149\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4061 - val_loss: 0.7375\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4477 - val_loss: 0.7617\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1317 - val_loss: 0.7380\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5455 - val_loss: 0.6785\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7158 - val_loss: 0.6116\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3200 - val_loss: 0.5776\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6064 - val_loss: 0.5561\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6345 - val_loss: 0.5501\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3048 - val_loss: 0.5521\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3381 - val_loss: 0.5378\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.5726 - val_loss: 0.5167\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6880 - val_loss: 0.5310\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3935 - val_loss: 0.4958\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0057 - val_loss: 0.4516\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1966 - val_loss: 0.4248\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5287 - val_loss: 0.4176\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4745 - val_loss: 0.3904\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1804 - val_loss: 0.3690\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9059 - val_loss: 0.3731\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1842 - val_loss: 0.3645\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9957 - val_loss: 0.3341\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0424 - val_loss: 0.2947\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8896 - val_loss: 0.2532\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9381 - val_loss: 0.2270\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9109 - val_loss: 0.2169\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9716 - val_loss: 0.2144\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7933 - val_loss: 0.2129\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9627 - val_loss: 0.2141\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9184 - val_loss: 0.1970\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0076 - val_loss: 0.1690\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7249 - val_loss: 0.1543\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7543 - val_loss: 0.1475\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7158 - val_loss: 0.1351\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8129 - val_loss: 0.1356\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7828 - val_loss: 0.1360\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8636 - val_loss: 0.1292\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9790 - val_loss: 0.1316\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1396 - val_loss: 0.1364\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7471 - val_loss: 0.1430\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7983 - val_loss: 0.1421\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5918 - val_loss: 0.1335\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8658 - val_loss: 0.1317\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0947 - val_loss: 0.1407\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8492 - val_loss: 0.1512\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7144 - val_loss: 0.1421\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8744 - val_loss: 0.1330\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7604 - val_loss: 0.1300\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1079 - val_loss: 0.1131\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7475 - val_loss: 0.1035\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7450 - val_loss: 0.1095\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5810 - val_loss: 0.1247\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7328 - val_loss: 0.1313\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8390 - val_loss: 0.1357\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5821 - val_loss: 0.1410\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8509 - val_loss: 0.1520\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6604 - val_loss: 0.1494\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5425 - val_loss: 0.1419\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5459 - val_loss: 0.1375\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6995 - val_loss: 0.1316\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8087 - val_loss: 0.1325\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7122 - val_loss: 0.1343\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4920 - val_loss: 0.1405\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6358 - val_loss: 0.1307\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5769 - val_loss: 0.1189\n",
            "Epoch 107/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6109 - val_loss: 0.1053\n",
            "Epoch 108/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5762 - val_loss: 0.0975\n",
            "Epoch 109/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5228 - val_loss: 0.0951\n",
            "Epoch 110/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4324 - val_loss: 0.0910\n",
            "Epoch 111/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5463 - val_loss: 0.0886\n",
            "Epoch 112/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6915 - val_loss: 0.0899\n",
            "Epoch 113/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6327 - val_loss: 0.0871\n",
            "Epoch 114/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5494 - val_loss: 0.0838\n",
            "Epoch 115/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5795 - val_loss: 0.0867\n",
            "Epoch 116/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5508 - val_loss: 0.0927\n",
            "Epoch 117/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4480 - val_loss: 0.0950\n",
            "Epoch 118/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5419 - val_loss: 0.0980\n",
            "Epoch 119/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7381 - val_loss: 0.0843\n",
            "Epoch 120/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5986 - val_loss: 0.0725\n",
            "Epoch 121/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5840 - val_loss: 0.0546\n",
            "Epoch 122/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4263 - val_loss: 0.0458\n",
            "Epoch 123/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4636 - val_loss: 0.0422\n",
            "Epoch 124/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4831 - val_loss: 0.0432\n",
            "Epoch 125/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3471 - val_loss: 0.0432\n",
            "Epoch 126/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4076 - val_loss: 0.0425\n",
            "Epoch 127/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4700 - val_loss: 0.0437\n",
            "Epoch 128/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6731 - val_loss: 0.0446\n",
            "Epoch 129/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4902 - val_loss: 0.0459\n",
            "Epoch 130/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5033 - val_loss: 0.0476\n",
            "Epoch 131/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4266 - val_loss: 0.0487\n",
            "Epoch 132/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5057 - val_loss: 0.0489\n",
            "Epoch 133/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4087 - val_loss: 0.0519\n",
            "Epoch 134/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5780 - val_loss: 0.0495\n",
            "Epoch 135/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5011 - val_loss: 0.0486\n",
            "Epoch 136/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3688 - val_loss: 0.0436\n",
            "Epoch 137/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3769 - val_loss: 0.0392\n",
            "Epoch 138/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4032 - val_loss: 0.0387\n",
            "Epoch 139/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3493 - val_loss: 0.0389\n",
            "Epoch 140/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4686 - val_loss: 0.0403\n",
            "Epoch 141/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4315 - val_loss: 0.0407\n",
            "Epoch 142/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4648 - val_loss: 0.0475\n",
            "Epoch 143/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4688 - val_loss: 0.0578\n",
            "Epoch 144/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4104 - val_loss: 0.0588\n",
            "Epoch 145/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4969 - val_loss: 0.0546\n",
            "Epoch 146/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4802 - val_loss: 0.0507\n",
            "Epoch 147/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3778 - val_loss: 0.0470\n",
            "Epoch 148/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3660 - val_loss: 0.0464\n",
            "Epoch 149/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4075 - val_loss: 0.0463\n",
            "Epoch 150/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5093 - val_loss: 0.0445\n",
            "Epoch 151/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2793 - val_loss: 0.0439\n",
            "Epoch 152/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4392 - val_loss: 0.0407\n",
            "Epoch 153/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4631 - val_loss: 0.0420\n",
            "Epoch 154/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4588 - val_loss: 0.0456\n",
            "Epoch 155/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4372 - val_loss: 0.0518\n",
            "Epoch 156/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3882 - val_loss: 0.0510\n",
            "Epoch 157/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3278 - val_loss: 0.0515\n",
            "Epoch 158/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4376 - val_loss: 0.0489\n",
            "Epoch 159/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3917 - val_loss: 0.0440\n",
            "Epoch 160/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3660 - val_loss: 0.0446\n",
            "Epoch 161/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4641 - val_loss: 0.0443\n",
            "Epoch 162/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3714 - val_loss: 0.0411\n",
            "Epoch 163/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3291 - val_loss: 0.0401\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.08520937658692095\n",
            "MAE: 0.23913525977881395\n",
            "R^2: -7.769442264010957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron Model (MLP) with Case 2 (Inputs are Discharging Capacity and CVCC)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSbP4MPik6SX",
        "outputId": "75fe3837-fb92-4895-c59c-691b020e6d21"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 80ms/step - loss: 5.6789 - val_loss: 3.3037\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 5.8355 - val_loss: 2.9512\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 5.6792 - val_loss: 2.6427\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 4.4884 - val_loss: 2.3719\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 4.9690 - val_loss: 2.1479\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 4.6391 - val_loss: 1.8734\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 4.7594 - val_loss: 1.6348\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.5669 - val_loss: 1.4248\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.9544 - val_loss: 1.2505\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.9679 - val_loss: 1.1044\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 3.6740 - val_loss: 0.9774\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.2210 - val_loss: 0.8494\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.5780 - val_loss: 0.7241\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 3.4453 - val_loss: 0.6295\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 2.8330 - val_loss: 0.5431\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.7472 - val_loss: 0.4707\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 2.8935 - val_loss: 0.4105\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.3840 - val_loss: 0.3457\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.8914 - val_loss: 0.2931\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.8916 - val_loss: 0.2451\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.0089 - val_loss: 0.2097\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.3947 - val_loss: 0.1693\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 2.3030 - val_loss: 0.1507\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 2.0020 - val_loss: 0.1237\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0572 - val_loss: 0.1004\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 2.2998 - val_loss: 0.0785\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 1.8584 - val_loss: 0.0593\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.9149 - val_loss: 0.0423\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.5968 - val_loss: 0.0327\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.0533 - val_loss: 0.0340\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9886 - val_loss: 0.0417\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.3456 - val_loss: 0.0370\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 1.5702 - val_loss: 0.0251\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.8912 - val_loss: 0.0183\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8847 - val_loss: 0.0226\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6574 - val_loss: 0.0217\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4273 - val_loss: 0.0227\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.6674 - val_loss: 0.0160\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6904 - val_loss: 0.0148\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8526 - val_loss: 0.0137\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5905 - val_loss: 0.0134\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0526 - val_loss: 0.0172\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4084 - val_loss: 0.0184\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4761 - val_loss: 0.0229\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6536 - val_loss: 0.0228\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3076 - val_loss: 0.0209\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0591 - val_loss: 0.0306\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3402 - val_loss: 0.0551\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7950 - val_loss: 0.0596\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2377 - val_loss: 0.0572\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4293 - val_loss: 0.0337\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4193 - val_loss: 0.0181\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2186 - val_loss: 0.0184\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3664 - val_loss: 0.0307\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.3956 - val_loss: 0.0472\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9133 - val_loss: 0.0340\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0118 - val_loss: 0.0159\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2213 - val_loss: 0.0111\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2153 - val_loss: 0.0152\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3233 - val_loss: 0.0179\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9546 - val_loss: 0.0158\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2456 - val_loss: 0.0164\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1780 - val_loss: 0.0191\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0110 - val_loss: 0.0195\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9244 - val_loss: 0.0166\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2566 - val_loss: 0.0200\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9899 - val_loss: 0.0271\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0879 - val_loss: 0.0293\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7496 - val_loss: 0.0346\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9157 - val_loss: 0.0337\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9686 - val_loss: 0.0320\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7732 - val_loss: 0.0331\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8528 - val_loss: 0.0539\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9950 - val_loss: 0.0555\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6761 - val_loss: 0.0375\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7365 - val_loss: 0.0224\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6968 - val_loss: 0.0203\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7149 - val_loss: 0.0190\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7840 - val_loss: 0.0210\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8916 - val_loss: 0.0162\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7113 - val_loss: 0.0111\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6645 - val_loss: 0.0152\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7812 - val_loss: 0.0224\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7259 - val_loss: 0.0282\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6672 - val_loss: 0.0302\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0618 - val_loss: 0.0321\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7053 - val_loss: 0.0503\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7912 - val_loss: 0.0321\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8401 - val_loss: 0.0331\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6297 - val_loss: 0.0556\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6478 - val_loss: 0.0854\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8719 - val_loss: 0.0754\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8296 - val_loss: 0.0412\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6871 - val_loss: 0.0485\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6530 - val_loss: 0.0632\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9074 - val_loss: 0.0316\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5714 - val_loss: 0.0399\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6155 - val_loss: 0.0491\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5637 - val_loss: 0.0531\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6820 - val_loss: 0.0512\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6467 - val_loss: 0.0558\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7373 - val_loss: 0.0691\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6619 - val_loss: 0.0742\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7685 - val_loss: 0.0901\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5002 - val_loss: 0.1013\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6539 - val_loss: 0.1026\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.012105210288836531\n",
            "MAE: 0.10023408362458872\n",
            "R^2: -0.24582466124928293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 3 (Inputs are Discharging Capacity, CCCT, and CCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7nRmKNJmVJM",
        "outputId": "ca86ffd1-a733-4bdc-8025-4a8878d26cb4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 52ms/step - loss: 5.9162 - val_loss: 3.3181\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8631 - val_loss: 2.9942\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.7274 - val_loss: 2.6958\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.8213 - val_loss: 2.4195\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.1171 - val_loss: 2.1680\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.0630 - val_loss: 1.9479\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9809 - val_loss: 1.7721\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 4.5106 - val_loss: 1.6478\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8161 - val_loss: 1.5146\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.1912 - val_loss: 1.3848\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.5578 - val_loss: 1.2963\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8144 - val_loss: 1.1951\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.2018 - val_loss: 1.0731\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.5121 - val_loss: 0.9614\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.0711 - val_loss: 0.8564\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.0610 - val_loss: 0.7813\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.9355 - val_loss: 0.7155\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.6851 - val_loss: 0.6226\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.9422 - val_loss: 0.5434\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.7893 - val_loss: 0.4699\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9748 - val_loss: 0.4287\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3044 - val_loss: 0.3731\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0735 - val_loss: 0.3235\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.9122 - val_loss: 0.2791\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3197 - val_loss: 0.2557\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.9143 - val_loss: 0.2326\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2754 - val_loss: 0.2288\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6619 - val_loss: 0.2098\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.9726 - val_loss: 0.1914\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0048 - val_loss: 0.1815\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0758 - val_loss: 0.1548\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0205 - val_loss: 0.1268\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9246 - val_loss: 0.1122\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9561 - val_loss: 0.1064\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2618 - val_loss: 0.1316\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8776 - val_loss: 0.1850\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1055 - val_loss: 0.1832\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1032 - val_loss: 0.1426\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9436 - val_loss: 0.1090\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9521 - val_loss: 0.0831\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7664 - val_loss: 0.0860\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6336 - val_loss: 0.0851\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.8913 - val_loss: 0.0770\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5020 - val_loss: 0.0702\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5371 - val_loss: 0.0525\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1661 - val_loss: 0.0358\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6044 - val_loss: 0.0373\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9568 - val_loss: 0.0402\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3530 - val_loss: 0.0443\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5657 - val_loss: 0.0500\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1517 - val_loss: 0.0652\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3444 - val_loss: 0.0657\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2349 - val_loss: 0.0739\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2341 - val_loss: 0.0843\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6240 - val_loss: 0.0646\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.5307 - val_loss: 0.0576\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4350 - val_loss: 0.0678\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1321 - val_loss: 0.0722\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6258 - val_loss: 0.0610\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2048 - val_loss: 0.0552\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0647 - val_loss: 0.0558\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6953 - val_loss: 0.0502\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1498 - val_loss: 0.0448\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3998 - val_loss: 0.0353\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2615 - val_loss: 0.0273\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2099 - val_loss: 0.0230\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1133 - val_loss: 0.0341\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0856 - val_loss: 0.0341\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4733 - val_loss: 0.0458\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9469 - val_loss: 0.0711\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9182 - val_loss: 0.0801\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1957 - val_loss: 0.0486\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7552 - val_loss: 0.0336\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3216 - val_loss: 0.0515\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1092 - val_loss: 0.0579\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0591 - val_loss: 0.0602\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0997 - val_loss: 0.0636\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1552 - val_loss: 0.0491\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8835 - val_loss: 0.0341\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9843 - val_loss: 0.0271\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0116 - val_loss: 0.0247\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7931 - val_loss: 0.0218\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.9475 - val_loss: 0.0202\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.8231 - val_loss: 0.0258\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8293 - val_loss: 0.0293\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.8401 - val_loss: 0.0222\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.8634 - val_loss: 0.0201\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7387 - val_loss: 0.0172\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7990 - val_loss: 0.0179\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7790 - val_loss: 0.0158\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6450 - val_loss: 0.0272\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8347 - val_loss: 0.0418\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7768 - val_loss: 0.0507\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.9147 - val_loss: 0.0543\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7092 - val_loss: 0.0379\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7567 - val_loss: 0.0383\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6696 - val_loss: 0.0368\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7557 - val_loss: 0.0311\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6465 - val_loss: 0.0273\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7830 - val_loss: 0.0287\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6768 - val_loss: 0.0393\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7355 - val_loss: 0.0602\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7960 - val_loss: 0.0620\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5737 - val_loss: 0.0485\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8467 - val_loss: 0.0198\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5266 - val_loss: 0.0181\n",
            "Epoch 107/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7199 - val_loss: 0.0263\n",
            "Epoch 108/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.8624 - val_loss: 0.0142\n",
            "Epoch 109/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.8352 - val_loss: 0.0144\n",
            "Epoch 110/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5863 - val_loss: 0.0163\n",
            "Epoch 111/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6137 - val_loss: 0.0167\n",
            "Epoch 112/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7420 - val_loss: 0.0169\n",
            "Epoch 113/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6801 - val_loss: 0.0205\n",
            "Epoch 114/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5621 - val_loss: 0.0209\n",
            "Epoch 115/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6527 - val_loss: 0.0231\n",
            "Epoch 116/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5893 - val_loss: 0.0292\n",
            "Epoch 117/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7039 - val_loss: 0.0243\n",
            "Epoch 118/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6443 - val_loss: 0.0168\n",
            "Epoch 119/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4891 - val_loss: 0.0166\n",
            "Epoch 120/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7049 - val_loss: 0.0168\n",
            "Epoch 121/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5978 - val_loss: 0.0166\n",
            "Epoch 122/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6146 - val_loss: 0.0205\n",
            "Epoch 123/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5682 - val_loss: 0.0228\n",
            "Epoch 124/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6407 - val_loss: 0.0219\n",
            "Epoch 125/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5596 - val_loss: 0.0114\n",
            "Epoch 126/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5535 - val_loss: 0.0127\n",
            "Epoch 127/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5331 - val_loss: 0.0137\n",
            "Epoch 128/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.7108 - val_loss: 0.0143\n",
            "Epoch 129/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5135 - val_loss: 0.0179\n",
            "Epoch 130/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5768 - val_loss: 0.0188\n",
            "Epoch 131/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5762 - val_loss: 0.0238\n",
            "Epoch 132/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7396 - val_loss: 0.0262\n",
            "Epoch 133/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6827 - val_loss: 0.0289\n",
            "Epoch 134/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5429 - val_loss: 0.0312\n",
            "Epoch 135/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4442 - val_loss: 0.0394\n",
            "Epoch 136/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5748 - val_loss: 0.0442\n",
            "Epoch 137/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4202 - val_loss: 0.0386\n",
            "Epoch 138/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7796 - val_loss: 0.0276\n",
            "Epoch 139/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4068 - val_loss: 0.0239\n",
            "Epoch 140/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5372 - val_loss: 0.0184\n",
            "Epoch 141/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4073 - val_loss: 0.0146\n",
            "Epoch 142/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4629 - val_loss: 0.0159\n",
            "Epoch 143/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3918 - val_loss: 0.0324\n",
            "Epoch 144/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5929 - val_loss: 0.0329\n",
            "Epoch 145/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4384 - val_loss: 0.0166\n",
            "Epoch 146/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4315 - val_loss: 0.0135\n",
            "Epoch 147/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4602 - val_loss: 0.0168\n",
            "Epoch 148/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5247 - val_loss: 0.0216\n",
            "Epoch 149/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4125 - val_loss: 0.0162\n",
            "Epoch 150/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3784 - val_loss: 0.0158\n",
            "6/6 [==============================] - 0s 5ms/step\n",
            "MSE: 0.15070957252157782\n",
            "MAE: 0.328746380330177\n",
            "R^2: -14.510486613096656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 4 (Inputs are Discharging Capacity, CCCT, CCV, and CVCC)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gipLtnJn1f-",
        "outputId": "0d5b67dc-a1a6-45e5-f784-21ca5ebb46bd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 57ms/step - loss: 6.7433 - val_loss: 3.3535\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.6252 - val_loss: 3.1904\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 7.3321 - val_loss: 2.9017\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7203 - val_loss: 2.6351\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 4.8141 - val_loss: 2.3786\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.8100 - val_loss: 2.0804\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.8814 - val_loss: 1.7890\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2896 - val_loss: 1.5390\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.7619 - val_loss: 1.3435\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.0670 - val_loss: 1.1519\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.3079 - val_loss: 0.9904\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9338 - val_loss: 0.8497\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.3740 - val_loss: 0.7264\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.4106 - val_loss: 0.6168\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.1200 - val_loss: 0.5277\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.8737 - val_loss: 0.4448\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.9634 - val_loss: 0.3687\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.4708 - val_loss: 0.3437\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 2.7562 - val_loss: 0.3450\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.1187 - val_loss: 0.3383\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.7152 - val_loss: 0.2883\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.5038 - val_loss: 0.2426\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.1065 - val_loss: 0.1847\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.3908 - val_loss: 0.1444\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.9650 - val_loss: 0.1178\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.0879 - val_loss: 0.0748\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7981 - val_loss: 0.0601\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4952 - val_loss: 0.0658\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8669 - val_loss: 0.0750\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.4089 - val_loss: 0.0848\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9028 - val_loss: 0.0853\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.2110 - val_loss: 0.0703\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.8820 - val_loss: 0.0585\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.5681 - val_loss: 0.0316\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.7399 - val_loss: 0.0157\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2836 - val_loss: 0.0101\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.1957 - val_loss: 0.0090\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.7020 - val_loss: 0.0164\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.3800 - val_loss: 0.0488\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 2.2144 - val_loss: 0.0655\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.4991 - val_loss: 0.0542\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.2957 - val_loss: 0.0346\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.3949 - val_loss: 0.0307\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4585 - val_loss: 0.0375\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.4801 - val_loss: 0.0370\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.9390 - val_loss: 0.0291\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5312 - val_loss: 0.0269\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4812 - val_loss: 0.0259\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2294 - val_loss: 0.0358\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.7077 - val_loss: 0.0463\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.9977 - val_loss: 0.0385\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.2615 - val_loss: 0.0312\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.3341 - val_loss: 0.0378\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1873 - val_loss: 0.0365\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.3736 - val_loss: 0.0294\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.3315 - val_loss: 0.0205\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.0986 - val_loss: 0.0230\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.1692 - val_loss: 0.0275\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.1003 - val_loss: 0.0298\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.2433 - val_loss: 0.0345\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 1.2819 - val_loss: 0.0428\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.9505 - val_loss: 0.0509\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.04045939257821299\n",
            "MAE: 0.1601102478310702\n",
            "R^2: -3.1639350205743977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 5 (Inputs are CCDT and CCDV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_taR7ApWdn",
        "outputId": "44a7e873-a992-489f-aafd-17f7d7c6ce44"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 59ms/step - loss: 7.0484 - val_loss: 2.8311\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5054 - val_loss: 2.6480\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.3521 - val_loss: 2.4737\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 5.6010 - val_loss: 2.3621\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.1409 - val_loss: 2.2419\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.2671 - val_loss: 2.1177\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 4.2194 - val_loss: 1.9514\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.0180 - val_loss: 1.8703\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.8904 - val_loss: 1.8193\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.9895 - val_loss: 1.7521\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.5570 - val_loss: 1.6928\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5418 - val_loss: 1.5812\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.2985 - val_loss: 1.4418\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2190 - val_loss: 1.3064\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0355 - val_loss: 1.2234\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7584 - val_loss: 1.1784\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4318 - val_loss: 1.1335\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.8718 - val_loss: 1.0526\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4992 - val_loss: 0.9781\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.4462 - val_loss: 0.9258\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3396 - val_loss: 0.8414\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.8133 - val_loss: 0.7781\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3760 - val_loss: 0.7014\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.1144 - val_loss: 0.6432\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5537 - val_loss: 0.5989\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.5452 - val_loss: 0.5607\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.9848 - val_loss: 0.5459\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4652 - val_loss: 0.5222\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0268 - val_loss: 0.4824\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0097 - val_loss: 0.4356\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7289 - val_loss: 0.3942\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8614 - val_loss: 0.3702\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5031 - val_loss: 0.3447\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.5974 - val_loss: 0.3264\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4595 - val_loss: 0.3172\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8507 - val_loss: 0.3039\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.7882 - val_loss: 0.2801\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1860 - val_loss: 0.2631\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6619 - val_loss: 0.2498\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4323 - val_loss: 0.2405\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3966 - val_loss: 0.2253\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.4418 - val_loss: 0.2032\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3990 - val_loss: 0.1854\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5245 - val_loss: 0.1791\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4323 - val_loss: 0.1674\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3251 - val_loss: 0.1604\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6850 - val_loss: 0.1552\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3488 - val_loss: 0.1495\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2441 - val_loss: 0.1505\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0049 - val_loss: 0.1433\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1507 - val_loss: 0.1364\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1565 - val_loss: 0.1310\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2030 - val_loss: 0.1278\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3645 - val_loss: 0.1271\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2040 - val_loss: 0.1305\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1076 - val_loss: 0.1280\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.1210 - val_loss: 0.1389\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1820 - val_loss: 0.1406\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1210 - val_loss: 0.1361\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4223 - val_loss: 0.1306\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7141 - val_loss: 0.1321\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2641 - val_loss: 0.1358\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9976 - val_loss: 0.1414\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0158 - val_loss: 0.1558\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0346 - val_loss: 0.1664\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8703 - val_loss: 0.1720\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9772 - val_loss: 0.1677\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0488 - val_loss: 0.1645\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9120 - val_loss: 0.1615\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0182 - val_loss: 0.1540\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2937 - val_loss: 0.1563\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6407 - val_loss: 0.1502\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0634 - val_loss: 0.1240\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.8967 - val_loss: 0.1043\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7309 - val_loss: 0.0918\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7439 - val_loss: 0.0822\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7581 - val_loss: 0.0782\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8168 - val_loss: 0.0771\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8553 - val_loss: 0.0793\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8909 - val_loss: 0.0742\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6711 - val_loss: 0.0615\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6395 - val_loss: 0.0496\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7310 - val_loss: 0.0521\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6593 - val_loss: 0.0566\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8299 - val_loss: 0.0646\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8391 - val_loss: 0.0588\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7557 - val_loss: 0.0539\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6777 - val_loss: 0.0514\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8682 - val_loss: 0.0504\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8132 - val_loss: 0.0444\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5835 - val_loss: 0.0415\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6487 - val_loss: 0.0400\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6937 - val_loss: 0.0419\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4604 - val_loss: 0.0534\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7864 - val_loss: 0.0758\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6940 - val_loss: 0.0817\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7100 - val_loss: 0.0748\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4804 - val_loss: 0.0671\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6204 - val_loss: 0.0612\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6723 - val_loss: 0.0511\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6547 - val_loss: 0.0405\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6239 - val_loss: 0.0351\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8737 - val_loss: 0.0346\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5666 - val_loss: 0.0373\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4658 - val_loss: 0.0444\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5652 - val_loss: 0.0384\n",
            "Epoch 107/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5227 - val_loss: 0.0311\n",
            "Epoch 108/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7771 - val_loss: 0.0283\n",
            "Epoch 109/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4823 - val_loss: 0.0328\n",
            "Epoch 110/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4087 - val_loss: 0.0388\n",
            "Epoch 111/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5108 - val_loss: 0.0336\n",
            "Epoch 112/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6062 - val_loss: 0.0335\n",
            "Epoch 113/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6969 - val_loss: 0.0380\n",
            "Epoch 114/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6387 - val_loss: 0.0477\n",
            "Epoch 115/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4946 - val_loss: 0.0585\n",
            "Epoch 116/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3829 - val_loss: 0.0622\n",
            "Epoch 117/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5171 - val_loss: 0.0732\n",
            "Epoch 118/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5685 - val_loss: 0.0755\n",
            "Epoch 119/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4673 - val_loss: 0.0714\n",
            "Epoch 120/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5943 - val_loss: 0.0600\n",
            "Epoch 121/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4228 - val_loss: 0.0484\n",
            "Epoch 122/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5531 - val_loss: 0.0436\n",
            "Epoch 123/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4588 - val_loss: 0.0517\n",
            "Epoch 124/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4154 - val_loss: 0.0569\n",
            "Epoch 125/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4587 - val_loss: 0.0486\n",
            "Epoch 126/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4609 - val_loss: 0.0387\n",
            "Epoch 127/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5106 - val_loss: 0.0310\n",
            "Epoch 128/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3496 - val_loss: 0.0238\n",
            "Epoch 129/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4522 - val_loss: 0.0221\n",
            "Epoch 130/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3902 - val_loss: 0.0208\n",
            "Epoch 131/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4615 - val_loss: 0.0180\n",
            "Epoch 132/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4439 - val_loss: 0.0160\n",
            "Epoch 133/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5162 - val_loss: 0.0152\n",
            "Epoch 134/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4354 - val_loss: 0.0173\n",
            "Epoch 135/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3685 - val_loss: 0.0217\n",
            "Epoch 136/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3844 - val_loss: 0.0207\n",
            "Epoch 137/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5216 - val_loss: 0.0194\n",
            "Epoch 138/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3811 - val_loss: 0.0189\n",
            "Epoch 139/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4199 - val_loss: 0.0217\n",
            "Epoch 140/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3038 - val_loss: 0.0323\n",
            "Epoch 141/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4272 - val_loss: 0.0286\n",
            "Epoch 142/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4021 - val_loss: 0.0205\n",
            "Epoch 143/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4997 - val_loss: 0.0168\n",
            "Epoch 144/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4904 - val_loss: 0.0202\n",
            "Epoch 145/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3469 - val_loss: 0.0272\n",
            "Epoch 146/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3742 - val_loss: 0.0199\n",
            "Epoch 147/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3492 - val_loss: 0.0150\n",
            "Epoch 148/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3548 - val_loss: 0.0100\n",
            "Epoch 149/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3636 - val_loss: 0.0055\n",
            "Epoch 150/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3359 - val_loss: 0.0044\n",
            "Epoch 151/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3638 - val_loss: 0.0077\n",
            "Epoch 152/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3537 - val_loss: 0.0212\n",
            "Epoch 153/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3009 - val_loss: 0.0393\n",
            "Epoch 154/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4340 - val_loss: 0.0374\n",
            "Epoch 155/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2878 - val_loss: 0.0288\n",
            "Epoch 156/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3835 - val_loss: 0.0229\n",
            "Epoch 157/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.0173\n",
            "Epoch 158/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4034 - val_loss: 0.0161\n",
            "Epoch 159/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3186 - val_loss: 0.0201\n",
            "Epoch 160/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3988 - val_loss: 0.0185\n",
            "Epoch 161/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3359 - val_loss: 0.0162\n",
            "Epoch 162/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3680 - val_loss: 0.0149\n",
            "Epoch 163/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3970 - val_loss: 0.0215\n",
            "Epoch 164/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2734 - val_loss: 0.0335\n",
            "Epoch 165/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4206 - val_loss: 0.0441\n",
            "Epoch 166/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3067 - val_loss: 0.0413\n",
            "Epoch 167/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2543 - val_loss: 0.0383\n",
            "Epoch 168/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2749 - val_loss: 0.0294\n",
            "Epoch 169/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3089 - val_loss: 0.0235\n",
            "Epoch 170/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3326 - val_loss: 0.0239\n",
            "Epoch 171/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3259 - val_loss: 0.0221\n",
            "Epoch 172/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2737 - val_loss: 0.0139\n",
            "Epoch 173/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2425 - val_loss: 0.0119\n",
            "Epoch 174/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2536 - val_loss: 0.0137\n",
            "Epoch 175/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2995 - val_loss: 0.0143\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.1831418601739967\n",
            "MAE: 0.3343693134132536\n",
            "R^2: -17.848300894222827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 6 (Inputs are CCDV and RoCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68pdJaqwp_F-",
        "outputId": "c994c743-8b13-49ea-98d0-8e6c8f89fc01"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 82ms/step - loss: 5.9649 - val_loss: 2.9467\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 4.6577 - val_loss: 2.7250\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.0348 - val_loss: 2.5693\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 5.5280 - val_loss: 2.4485\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.1186 - val_loss: 2.2314\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 4.6439 - val_loss: 2.0513\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 4.2424 - val_loss: 1.8351\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.0113 - val_loss: 1.6884\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.5495 - val_loss: 1.5500\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.6717 - val_loss: 1.4122\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 3.7147 - val_loss: 1.3169\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 3.6244 - val_loss: 1.2312\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.5855 - val_loss: 1.1228\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.0615 - val_loss: 1.0089\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.0842 - val_loss: 0.9042\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.0831 - val_loss: 0.8109\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.4394 - val_loss: 0.7319\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.0212 - val_loss: 0.6515\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.5236 - val_loss: 0.5640\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.0564 - val_loss: 0.5006\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.1308 - val_loss: 0.4447\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.9411 - val_loss: 0.4001\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.8356 - val_loss: 0.3703\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.8873 - val_loss: 0.3476\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5920 - val_loss: 0.3411\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1350 - val_loss: 0.3420\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.2129 - val_loss: 0.3114\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.2649 - val_loss: 0.2982\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1878 - val_loss: 0.2600\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1312 - val_loss: 0.2201\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8233 - val_loss: 0.1889\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.3458 - val_loss: 0.1651\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0878 - val_loss: 0.1521\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.2914 - val_loss: 0.1433\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 2.2338 - val_loss: 0.1323\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.5555 - val_loss: 0.1227\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.9113 - val_loss: 0.1166\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6828 - val_loss: 0.1078\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.3040 - val_loss: 0.0940\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.9931 - val_loss: 0.0771\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.9309 - val_loss: 0.0738\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.9561 - val_loss: 0.0682\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.2850 - val_loss: 0.0641\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.5301 - val_loss: 0.0561\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.2472 - val_loss: 0.0507\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4931 - val_loss: 0.0477\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.7395 - val_loss: 0.0435\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6009 - val_loss: 0.0443\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4116 - val_loss: 0.0443\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2570 - val_loss: 0.0412\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3189 - val_loss: 0.0477\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.6775 - val_loss: 0.0677\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2160 - val_loss: 0.0585\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3883 - val_loss: 0.0615\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3065 - val_loss: 0.0584\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.3271 - val_loss: 0.0532\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2032 - val_loss: 0.0486\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1200 - val_loss: 0.0424\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1150 - val_loss: 0.0379\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5079 - val_loss: 0.0385\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2364 - val_loss: 0.0301\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4525 - val_loss: 0.0231\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7918 - val_loss: 0.0193\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0399 - val_loss: 0.0179\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0353 - val_loss: 0.0218\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0362 - val_loss: 0.0317\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1756 - val_loss: 0.0386\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0489 - val_loss: 0.0439\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1768 - val_loss: 0.0409\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1183 - val_loss: 0.0365\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1265 - val_loss: 0.0443\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7770 - val_loss: 0.0505\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1059 - val_loss: 0.0507\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9666 - val_loss: 0.0462\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1070 - val_loss: 0.0437\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9956 - val_loss: 0.0448\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7555 - val_loss: 0.0423\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7014 - val_loss: 0.0417\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7928 - val_loss: 0.0389\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9218 - val_loss: 0.0409\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8743 - val_loss: 0.0564\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8470 - val_loss: 0.0662\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7938 - val_loss: 0.0650\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6601 - val_loss: 0.0586\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7595 - val_loss: 0.0552\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8272 - val_loss: 0.0542\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7281 - val_loss: 0.0588\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5958 - val_loss: 0.0626\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9248 - val_loss: 0.0629\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.12610591210193506\n",
            "MAE: 0.28224611687554874\n",
            "R^2: -11.97836646182088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 7 (Inputs are Discharging Capacity, CCDT, and CCDV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1ND7KGQryA9",
        "outputId": "038c7cbd-3779-4dd8-8997-a80dbb53ee18"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 3s 75ms/step - loss: 7.3478 - val_loss: 2.6841\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.4225 - val_loss: 2.4343\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.9232 - val_loss: 2.3006\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.1004 - val_loss: 2.1249\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.9437 - val_loss: 2.0101\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.1166 - val_loss: 1.8466\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.4158 - val_loss: 1.7271\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.3922 - val_loss: 1.5869\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.4130 - val_loss: 1.4703\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.4030 - val_loss: 1.3665\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8890 - val_loss: 1.3034\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.7808 - val_loss: 1.2316\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5925 - val_loss: 1.1218\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7446 - val_loss: 1.0174\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2113 - val_loss: 0.9120\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5984 - val_loss: 0.7775\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.5534 - val_loss: 0.6866\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.1724 - val_loss: 0.6140\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.6093 - val_loss: 0.5549\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.6188 - val_loss: 0.5190\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.5403 - val_loss: 0.4819\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7644 - val_loss: 0.4561\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.6274 - val_loss: 0.4258\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9619 - val_loss: 0.4063\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4437 - val_loss: 0.3780\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9182 - val_loss: 0.3363\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2267 - val_loss: 0.3014\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7135 - val_loss: 0.2773\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0400 - val_loss: 0.2437\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8535 - val_loss: 0.2079\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8934 - val_loss: 0.1752\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9369 - val_loss: 0.1541\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1557 - val_loss: 0.1390\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8155 - val_loss: 0.1209\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9633 - val_loss: 0.1046\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6566 - val_loss: 0.1094\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4801 - val_loss: 0.1420\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4736 - val_loss: 0.1820\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9140 - val_loss: 0.1814\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4877 - val_loss: 0.1651\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.0774 - val_loss: 0.1365\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7795 - val_loss: 0.1095\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7784 - val_loss: 0.0951\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2830 - val_loss: 0.0846\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7834 - val_loss: 0.0850\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.4963 - val_loss: 0.0875\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4037 - val_loss: 0.0747\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8052 - val_loss: 0.0705\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5300 - val_loss: 0.0914\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5463 - val_loss: 0.1007\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5683 - val_loss: 0.0850\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.5690 - val_loss: 0.0623\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.2514 - val_loss: 0.0488\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3483 - val_loss: 0.0441\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0416 - val_loss: 0.0507\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1009 - val_loss: 0.0570\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3953 - val_loss: 0.0658\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0483 - val_loss: 0.0739\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0845 - val_loss: 0.0783\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1025 - val_loss: 0.0731\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5342 - val_loss: 0.0648\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8995 - val_loss: 0.0595\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8636 - val_loss: 0.0506\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9370 - val_loss: 0.0465\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1412 - val_loss: 0.0416\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9316 - val_loss: 0.0376\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0369 - val_loss: 0.0397\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3646 - val_loss: 0.0564\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.0966 - val_loss: 0.0787\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2243 - val_loss: 0.0755\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9924 - val_loss: 0.0494\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9345 - val_loss: 0.0391\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0456 - val_loss: 0.0423\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2220 - val_loss: 0.0488\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8788 - val_loss: 0.0783\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.0249 - val_loss: 0.0955\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0411 - val_loss: 0.0959\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8779 - val_loss: 0.0840\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9892 - val_loss: 0.0769\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1894 - val_loss: 0.0685\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8206 - val_loss: 0.0657\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8396 - val_loss: 0.0704\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7608 - val_loss: 0.0730\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0028 - val_loss: 0.0711\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9828 - val_loss: 0.0699\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8953 - val_loss: 0.0636\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8042 - val_loss: 0.0555\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8706 - val_loss: 0.0526\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8455 - val_loss: 0.0613\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6865 - val_loss: 0.0670\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6694 - val_loss: 0.0586\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.029123539438413677\n",
            "MAE: 0.13861625064254376\n",
            "R^2: -1.9972898272326587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Multilayer Perceptron (MLP) Model with Case 8 (Inputs are Discharging Capacity, CCDT, CCDV, and RoCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the KFold cross validator\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 10\n",
        "for train_index, val_index in kfold.split(X_train_scaled):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "# MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ybcF5X1si4C",
        "outputId": "780a1b6e-686e-45c5-8338-cd2335602772"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 2s 52ms/step - loss: 6.1083 - val_loss: 3.5040\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.3143 - val_loss: 3.0876\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.8586 - val_loss: 2.7043\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.5608 - val_loss: 2.4156\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.2446 - val_loss: 2.1723\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 3.4584 - val_loss: 1.9182\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.0899 - val_loss: 1.7210\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.1873 - val_loss: 1.5326\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 3.7911 - val_loss: 1.3492\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.1525 - val_loss: 1.1921\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.0817 - val_loss: 1.0129\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2559 - val_loss: 0.8735\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2115 - val_loss: 0.7696\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.9842 - val_loss: 0.6784\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7467 - val_loss: 0.6249\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.7388 - val_loss: 0.5616\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.6299 - val_loss: 0.4814\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4721 - val_loss: 0.4209\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5948 - val_loss: 0.3458\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.1021 - val_loss: 0.2678\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3544 - val_loss: 0.2307\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0724 - val_loss: 0.2031\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.6735 - val_loss: 0.1941\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3901 - val_loss: 0.1850\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9207 - val_loss: 0.1786\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.0010 - val_loss: 0.1640\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.3544 - val_loss: 0.1380\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9504 - val_loss: 0.1138\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0467 - val_loss: 0.1026\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8347 - val_loss: 0.0997\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1606 - val_loss: 0.0953\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6559 - val_loss: 0.0992\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.8910 - val_loss: 0.0901\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5706 - val_loss: 0.0724\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7281 - val_loss: 0.0554\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6459 - val_loss: 0.0339\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4082 - val_loss: 0.0251\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.3069 - val_loss: 0.0266\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4869 - val_loss: 0.0346\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4397 - val_loss: 0.0386\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4555 - val_loss: 0.0355\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1354 - val_loss: 0.0337\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0682 - val_loss: 0.0340\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1571 - val_loss: 0.0352\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4181 - val_loss: 0.0358\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2445 - val_loss: 0.0366\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3185 - val_loss: 0.0642\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.4734 - val_loss: 0.0414\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9855 - val_loss: 0.0203\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3836 - val_loss: 0.0235\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4635 - val_loss: 0.0217\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.2731 - val_loss: 0.0261\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9415 - val_loss: 0.0312\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4003 - val_loss: 0.0396\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2226 - val_loss: 0.0449\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0946 - val_loss: 0.0398\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0986 - val_loss: 0.0446\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2648 - val_loss: 0.0342\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2096 - val_loss: 0.0294\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2305 - val_loss: 0.0239\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1146 - val_loss: 0.0255\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4099 - val_loss: 0.0378\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3078 - val_loss: 0.0493\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3280 - val_loss: 0.0472\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9929 - val_loss: 0.0416\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3032 - val_loss: 0.0439\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.8736 - val_loss: 0.0548\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0041 - val_loss: 0.0581\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8466 - val_loss: 0.0467\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0686 - val_loss: 0.0348\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8515 - val_loss: 0.0256\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1734 - val_loss: 0.0215\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1324 - val_loss: 0.0207\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7466 - val_loss: 0.0214\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.19128565882784515\n",
            "MAE: 0.4111805117657126\n",
            "R^2: -18.68643133203683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 1 (Inputs are CCCT and CCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAvL8GL3tHi9",
        "outputId": "831e826a-98eb-4f8e-b86d-37337ce36888"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 72ms/step - loss: 2.7282 - val_loss: 1.8765\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 2.1432 - val_loss: 1.2897\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.5294 - val_loss: 0.8424\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.0645 - val_loss: 0.5449\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7220 - val_loss: 0.4033\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4944 - val_loss: 0.3623\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3307 - val_loss: 0.3636\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2676 - val_loss: 0.3653\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3062 - val_loss: 0.3537\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1964 - val_loss: 0.3402\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2391 - val_loss: 0.3342\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2136 - val_loss: 0.3039\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2296 - val_loss: 0.2811\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2078 - val_loss: 0.2623\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1512 - val_loss: 0.2457\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1625 - val_loss: 0.2327\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1893 - val_loss: 0.2159\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1740 - val_loss: 0.2085\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1539 - val_loss: 0.2102\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1660 - val_loss: 0.2138\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1399 - val_loss: 0.1957\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1118 - val_loss: 0.1714\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1590 - val_loss: 0.1591\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1065 - val_loss: 0.1522\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1235 - val_loss: 0.1449\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1157 - val_loss: 0.1406\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1272 - val_loss: 0.1378\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0954 - val_loss: 0.1358\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1101 - val_loss: 0.1300\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0969 - val_loss: 0.1212\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0880 - val_loss: 0.1120\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0676 - val_loss: 0.1092\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0821 - val_loss: 0.1076\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0809 - val_loss: 0.1036\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1034 - val_loss: 0.0996\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0963 - val_loss: 0.1056\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0846 - val_loss: 0.1282\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0726 - val_loss: 0.1322\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0721 - val_loss: 0.1084\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0743 - val_loss: 0.0943\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1007 - val_loss: 0.0835\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0825 - val_loss: 0.0761\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0830 - val_loss: 0.0742\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0860 - val_loss: 0.0744\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0801 - val_loss: 0.0797\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0792 - val_loss: 0.0830\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0711 - val_loss: 0.0806\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0762 - val_loss: 0.1076\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0710 - val_loss: 0.1129\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0721 - val_loss: 0.1170\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0759 - val_loss: 0.1145\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0702 - val_loss: 0.0917\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0715 - val_loss: 0.0605\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0700 - val_loss: 0.0560\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0552 - val_loss: 0.0597\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0879 - val_loss: 0.0742\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0636 - val_loss: 0.1381\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0660 - val_loss: 0.1599\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0621 - val_loss: 0.1304\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0682 - val_loss: 0.0953\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0486 - val_loss: 0.0911\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0887 - val_loss: 0.1518\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0785 - val_loss: 0.1491\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0710 - val_loss: 0.0932\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0671 - val_loss: 0.0500\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0681 - val_loss: 0.0398\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0766 - val_loss: 0.0413\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0417 - val_loss: 0.0455\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0684 - val_loss: 0.0473\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0624 - val_loss: 0.0459\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0579 - val_loss: 0.0408\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0699 - val_loss: 0.0374\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0578 - val_loss: 0.0373\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0586 - val_loss: 0.0381\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0510 - val_loss: 0.0369\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0640 - val_loss: 0.0342\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0780 - val_loss: 0.0351\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0474 - val_loss: 0.0401\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0722 - val_loss: 0.0420\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0649 - val_loss: 0.0338\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0710 - val_loss: 0.0617\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0757 - val_loss: 0.0565\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0514 - val_loss: 0.0446\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0684 - val_loss: 0.0450\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0702 - val_loss: 0.0401\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0593 - val_loss: 0.0378\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0574 - val_loss: 0.0457\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0712 - val_loss: 0.2864\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0962 - val_loss: 0.3995\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1018 - val_loss: 0.2120\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0721 - val_loss: 0.0326\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0759 - val_loss: 0.0359\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0642 - val_loss: 0.0506\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.0559\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0709 - val_loss: 0.0469\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0541 - val_loss: 0.0329\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0654 - val_loss: 0.0332\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0478 - val_loss: 0.0422\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0537 - val_loss: 0.0467\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0574 - val_loss: 0.0437\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0674 - val_loss: 0.0375\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0494 - val_loss: 0.0363\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0631 - val_loss: 0.0321\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0444 - val_loss: 0.0300\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.0289\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0510 - val_loss: 0.0289\n",
            "Epoch 107/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0426 - val_loss: 0.0301\n",
            "Epoch 108/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0488 - val_loss: 0.0352\n",
            "Epoch 109/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0631 - val_loss: 0.0451\n",
            "Epoch 110/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0547 - val_loss: 0.0398\n",
            "Epoch 111/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0394 - val_loss: 0.0309\n",
            "Epoch 112/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0468 - val_loss: 0.0266\n",
            "Epoch 113/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0404 - val_loss: 0.0254\n",
            "Epoch 114/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0603 - val_loss: 0.0258\n",
            "Epoch 115/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0448 - val_loss: 0.0244\n",
            "Epoch 116/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0533 - val_loss: 0.0242\n",
            "Epoch 117/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0589 - val_loss: 0.0274\n",
            "Epoch 118/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0441 - val_loss: 0.0296\n",
            "Epoch 119/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0583 - val_loss: 0.0305\n",
            "Epoch 120/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0505 - val_loss: 0.0361\n",
            "Epoch 121/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0440 - val_loss: 0.0299\n",
            "Epoch 122/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0642 - val_loss: 0.0271\n",
            "Epoch 123/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0485 - val_loss: 0.0256\n",
            "Epoch 124/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0581 - val_loss: 0.0241\n",
            "Epoch 125/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0572 - val_loss: 0.0270\n",
            "Epoch 126/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0528 - val_loss: 0.0259\n",
            "Epoch 127/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0598 - val_loss: 0.0228\n",
            "Epoch 128/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0542 - val_loss: 0.0235\n",
            "Epoch 129/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0608 - val_loss: 0.0268\n",
            "Epoch 130/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0577 - val_loss: 0.0490\n",
            "Epoch 131/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0509 - val_loss: 0.0602\n",
            "Epoch 132/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0568 - val_loss: 0.0541\n",
            "Epoch 133/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0533 - val_loss: 0.0362\n",
            "Epoch 134/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0498 - val_loss: 0.0281\n",
            "Epoch 135/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0648 - val_loss: 0.0236\n",
            "Epoch 136/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0491 - val_loss: 0.0226\n",
            "Epoch 137/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0418 - val_loss: 0.0225\n",
            "Epoch 138/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0544 - val_loss: 0.0226\n",
            "Epoch 139/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0547 - val_loss: 0.0253\n",
            "Epoch 140/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0232\n",
            "Epoch 141/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0609 - val_loss: 0.0253\n",
            "Epoch 142/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0419 - val_loss: 0.0281\n",
            "Epoch 143/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0390 - val_loss: 0.0257\n",
            "Epoch 144/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0535 - val_loss: 0.0235\n",
            "Epoch 145/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0476 - val_loss: 0.0224\n",
            "Epoch 146/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0421 - val_loss: 0.0238\n",
            "Epoch 147/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0421 - val_loss: 0.0269\n",
            "Epoch 148/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0376 - val_loss: 0.0256\n",
            "Epoch 149/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0412 - val_loss: 0.0231\n",
            "Epoch 150/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0426 - val_loss: 0.0220\n",
            "Epoch 151/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0399 - val_loss: 0.0226\n",
            "Epoch 152/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0440 - val_loss: 0.0220\n",
            "Epoch 153/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0498 - val_loss: 0.0220\n",
            "Epoch 154/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0404 - val_loss: 0.0214\n",
            "Epoch 155/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0475 - val_loss: 0.0214\n",
            "Epoch 156/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0498 - val_loss: 0.0215\n",
            "Epoch 157/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0461 - val_loss: 0.0209\n",
            "Epoch 158/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0634 - val_loss: 0.0257\n",
            "Epoch 159/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0503 - val_loss: 0.0371\n",
            "Epoch 160/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0430 - val_loss: 0.0423\n",
            "Epoch 161/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0446 - val_loss: 0.0354\n",
            "Epoch 162/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0403 - val_loss: 0.0241\n",
            "Epoch 163/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0381 - val_loss: 0.0259\n",
            "Epoch 164/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0441 - val_loss: 0.0356\n",
            "Epoch 165/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0472 - val_loss: 0.0334\n",
            "Epoch 166/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0439 - val_loss: 0.0283\n",
            "Epoch 167/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0494 - val_loss: 0.0291\n",
            "Epoch 168/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0438 - val_loss: 0.0287\n",
            "Epoch 169/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0490 - val_loss: 0.0245\n",
            "Epoch 170/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0428 - val_loss: 0.0231\n",
            "Epoch 171/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0462 - val_loss: 0.0239\n",
            "Epoch 172/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0398 - val_loss: 0.0224\n",
            "Epoch 173/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0501 - val_loss: 0.0228\n",
            "Epoch 174/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0501 - val_loss: 0.0224\n",
            "Epoch 175/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0440 - val_loss: 0.0216\n",
            "Epoch 176/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0437 - val_loss: 0.0209\n",
            "Epoch 177/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0390 - val_loss: 0.0202\n",
            "Epoch 178/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0422 - val_loss: 0.0284\n",
            "Epoch 179/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0510 - val_loss: 0.0397\n",
            "Epoch 180/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0420 - val_loss: 0.0289\n",
            "Epoch 181/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0499 - val_loss: 0.0197\n",
            "Epoch 182/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0468 - val_loss: 0.0224\n",
            "Epoch 183/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0471 - val_loss: 0.0225\n",
            "Epoch 184/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0375 - val_loss: 0.0267\n",
            "Epoch 185/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0418 - val_loss: 0.0250\n",
            "Epoch 186/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0428 - val_loss: 0.0230\n",
            "Epoch 187/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0495 - val_loss: 0.0258\n",
            "Epoch 188/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0487 - val_loss: 0.0211\n",
            "Epoch 189/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0513 - val_loss: 0.0236\n",
            "Epoch 190/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0476 - val_loss: 0.0331\n",
            "Epoch 191/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0409 - val_loss: 0.0344\n",
            "Epoch 192/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0547 - val_loss: 0.0274\n",
            "Epoch 193/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0285 - val_loss: 0.0218\n",
            "Epoch 194/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0464 - val_loss: 0.0198\n",
            "Epoch 195/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0372 - val_loss: 0.0200\n",
            "Epoch 196/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0436 - val_loss: 0.0207\n",
            "Epoch 197/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0427 - val_loss: 0.0196\n",
            "Epoch 198/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0416 - val_loss: 0.0196\n",
            "Epoch 199/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0450 - val_loss: 0.0202\n",
            "Epoch 200/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0343 - val_loss: 0.0209\n",
            "Epoch 201/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0395 - val_loss: 0.0273\n",
            "Epoch 202/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0547 - val_loss: 0.0582\n",
            "Epoch 203/10000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0567 - val_loss: 0.0619\n",
            "Epoch 204/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0534 - val_loss: 0.0418\n",
            "Epoch 205/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0475 - val_loss: 0.0227\n",
            "Epoch 206/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0292 - val_loss: 0.0186\n",
            "Epoch 207/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0399 - val_loss: 0.0210\n",
            "Epoch 208/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0473 - val_loss: 0.0236\n",
            "Epoch 209/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0421 - val_loss: 0.0192\n",
            "Epoch 210/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0371 - val_loss: 0.0200\n",
            "Epoch 211/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0576 - val_loss: 0.0258\n",
            "Epoch 212/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0410 - val_loss: 0.0840\n",
            "Epoch 213/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0651 - val_loss: 0.0860\n",
            "Epoch 214/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0652 - val_loss: 0.0553\n",
            "Epoch 215/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0462 - val_loss: 0.0303\n",
            "Epoch 216/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0419 - val_loss: 0.0191\n",
            "Epoch 217/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0214\n",
            "Epoch 218/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0431 - val_loss: 0.0285\n",
            "Epoch 219/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0529 - val_loss: 0.0270\n",
            "Epoch 220/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0432 - val_loss: 0.0226\n",
            "Epoch 221/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0416 - val_loss: 0.0185\n",
            "Epoch 222/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0453 - val_loss: 0.0208\n",
            "Epoch 223/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0391 - val_loss: 0.0212\n",
            "Epoch 224/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0404 - val_loss: 0.0193\n",
            "Epoch 225/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0471 - val_loss: 0.0196\n",
            "Epoch 226/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0379 - val_loss: 0.0224\n",
            "Epoch 227/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0451 - val_loss: 0.0200\n",
            "Epoch 228/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0411 - val_loss: 0.0181\n",
            "Epoch 229/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0366 - val_loss: 0.0184\n",
            "Epoch 230/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0466 - val_loss: 0.0213\n",
            "Epoch 231/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0424 - val_loss: 0.0259\n",
            "Epoch 232/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0436 - val_loss: 0.0248\n",
            "Epoch 233/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0478 - val_loss: 0.0188\n",
            "Epoch 234/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0455 - val_loss: 0.0186\n",
            "Epoch 235/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0426 - val_loss: 0.0295\n",
            "Epoch 236/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0484 - val_loss: 0.0291\n",
            "Epoch 237/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0398 - val_loss: 0.0261\n",
            "Epoch 238/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0376 - val_loss: 0.0204\n",
            "Epoch 239/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0448 - val_loss: 0.0180\n",
            "Epoch 240/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0328 - val_loss: 0.0174\n",
            "Epoch 241/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0353 - val_loss: 0.0173\n",
            "Epoch 242/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0507 - val_loss: 0.0177\n",
            "Epoch 243/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0500 - val_loss: 0.0172\n",
            "Epoch 244/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0515 - val_loss: 0.0171\n",
            "Epoch 245/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0402 - val_loss: 0.0170\n",
            "Epoch 246/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0451 - val_loss: 0.0168\n",
            "Epoch 247/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0388 - val_loss: 0.0171\n",
            "Epoch 248/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0370 - val_loss: 0.0181\n",
            "Epoch 249/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0430 - val_loss: 0.0169\n",
            "Epoch 250/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0318 - val_loss: 0.0168\n",
            "Epoch 251/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0396 - val_loss: 0.0168\n",
            "Epoch 252/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0425 - val_loss: 0.0209\n",
            "Epoch 253/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0401 - val_loss: 0.0775\n",
            "Epoch 254/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0493 - val_loss: 0.0927\n",
            "Epoch 255/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0590 - val_loss: 0.0611\n",
            "Epoch 256/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0549 - val_loss: 0.0238\n",
            "Epoch 257/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0420 - val_loss: 0.0157\n",
            "Epoch 258/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0407 - val_loss: 0.0217\n",
            "Epoch 259/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0407 - val_loss: 0.0206\n",
            "Epoch 260/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0327 - val_loss: 0.0171\n",
            "Epoch 261/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0331 - val_loss: 0.0158\n",
            "Epoch 262/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0405 - val_loss: 0.0155\n",
            "Epoch 263/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0432 - val_loss: 0.0156\n",
            "Epoch 264/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0383 - val_loss: 0.0171\n",
            "Epoch 265/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0327 - val_loss: 0.0166\n",
            "Epoch 266/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0332 - val_loss: 0.0185\n",
            "Epoch 267/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0435 - val_loss: 0.0178\n",
            "Epoch 268/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0454 - val_loss: 0.0163\n",
            "Epoch 269/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0384 - val_loss: 0.0155\n",
            "Epoch 270/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0419 - val_loss: 0.0156\n",
            "Epoch 271/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0367 - val_loss: 0.0160\n",
            "Epoch 272/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0365 - val_loss: 0.0165\n",
            "Epoch 273/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0337 - val_loss: 0.0172\n",
            "Epoch 274/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0456 - val_loss: 0.0192\n",
            "Epoch 275/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0170\n",
            "Epoch 276/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0352 - val_loss: 0.0152\n",
            "Epoch 277/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0321 - val_loss: 0.0159\n",
            "Epoch 278/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0370 - val_loss: 0.0151\n",
            "Epoch 279/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0401 - val_loss: 0.0154\n",
            "Epoch 280/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0367 - val_loss: 0.0150\n",
            "Epoch 281/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0150\n",
            "Epoch 282/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0350 - val_loss: 0.0154\n",
            "Epoch 283/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0152\n",
            "Epoch 284/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0160\n",
            "Epoch 285/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0384 - val_loss: 0.0194\n",
            "Epoch 286/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0433 - val_loss: 0.0220\n",
            "Epoch 287/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0474 - val_loss: 0.0186\n",
            "Epoch 288/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0304 - val_loss: 0.0161\n",
            "Epoch 289/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0410 - val_loss: 0.0146\n",
            "Epoch 290/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0333 - val_loss: 0.0148\n",
            "Epoch 291/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0428 - val_loss: 0.0149\n",
            "Epoch 292/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0399 - val_loss: 0.0146\n",
            "Epoch 293/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0371 - val_loss: 0.0145\n",
            "Epoch 294/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0346 - val_loss: 0.0147\n",
            "Epoch 295/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0388 - val_loss: 0.0151\n",
            "Epoch 296/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0317 - val_loss: 0.0155\n",
            "Epoch 297/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0382 - val_loss: 0.0202\n",
            "Epoch 298/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0360 - val_loss: 0.0222\n",
            "Epoch 299/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0159\n",
            "Epoch 300/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0325 - val_loss: 0.0150\n",
            "Epoch 301/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0428 - val_loss: 0.0153\n",
            "Epoch 302/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0399 - val_loss: 0.0186\n",
            "Epoch 303/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0390 - val_loss: 0.0240\n",
            "Epoch 304/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0417 - val_loss: 0.0198\n",
            "Epoch 305/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0332 - val_loss: 0.0206\n",
            "Epoch 306/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0322 - val_loss: 0.0215\n",
            "Epoch 307/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0340 - val_loss: 0.0186\n",
            "Epoch 308/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0339 - val_loss: 0.0174\n",
            "Epoch 309/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0333 - val_loss: 0.0182\n",
            "Epoch 310/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0301 - val_loss: 0.0184\n",
            "Epoch 311/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.0177\n",
            "Epoch 312/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0358 - val_loss: 0.0196\n",
            "Epoch 313/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0351 - val_loss: 0.0190\n",
            "Epoch 314/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0339 - val_loss: 0.0152\n",
            "Epoch 315/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0412 - val_loss: 0.0146\n",
            "Epoch 316/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0283 - val_loss: 0.0163\n",
            "Epoch 317/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0397 - val_loss: 0.0175\n",
            "Epoch 318/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0357 - val_loss: 0.0147\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.154917543730724\n",
            "MAE: 0.30581376800969956\n",
            "R^2: -14.943555860230335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 2 (Inputs are Discharging Capacity and CVCC)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8EpOG-9xwGU",
        "outputId": "a6980c09-a525-40b3-8bb1-1838850bd663"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 45ms/step - loss: 2.5293 - val_loss: 1.9650\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7175 - val_loss: 1.3276\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2260 - val_loss: 0.8175\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8031 - val_loss: 0.4565\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5273 - val_loss: 0.2242\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4498 - val_loss: 0.1019\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3727 - val_loss: 0.0586\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3050 - val_loss: 0.0502\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3069 - val_loss: 0.0457\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2808 - val_loss: 0.0472\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2806 - val_loss: 0.0548\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2940 - val_loss: 0.0600\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2154 - val_loss: 0.0561\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1892 - val_loss: 0.0514\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2037 - val_loss: 0.0473\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1883 - val_loss: 0.0446\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1518 - val_loss: 0.0484\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1859 - val_loss: 0.0511\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1705 - val_loss: 0.0495\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1677 - val_loss: 0.0465\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1356 - val_loss: 0.0450\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0999 - val_loss: 0.0412\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1132 - val_loss: 0.0429\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1087 - val_loss: 0.0471\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0883 - val_loss: 0.0486\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0923 - val_loss: 0.0498\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0933 - val_loss: 0.0407\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1407 - val_loss: 0.0383\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1298 - val_loss: 0.0431\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0937 - val_loss: 0.0453\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1063 - val_loss: 0.0408\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0981 - val_loss: 0.0379\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0740 - val_loss: 0.0409\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0934 - val_loss: 0.0415\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0910 - val_loss: 0.0437\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0985 - val_loss: 0.0444\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1150 - val_loss: 0.0466\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0816 - val_loss: 0.0429\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0785 - val_loss: 0.0419\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0981 - val_loss: 0.0450\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0727 - val_loss: 0.0493\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1378 - val_loss: 0.0434\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0798 - val_loss: 0.0372\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0673 - val_loss: 0.0320\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0926 - val_loss: 0.0289\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0767 - val_loss: 0.0290\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0898 - val_loss: 0.0288\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0806 - val_loss: 0.0312\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0936 - val_loss: 0.0372\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1025 - val_loss: 0.0492\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0776 - val_loss: 0.0422\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0561 - val_loss: 0.0315\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0754 - val_loss: 0.0266\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0951 - val_loss: 0.0262\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0855 - val_loss: 0.0338\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0635 - val_loss: 0.0366\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0830 - val_loss: 0.0350\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0917 - val_loss: 0.0296\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0752 - val_loss: 0.0294\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0773 - val_loss: 0.0308\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0694 - val_loss: 0.0352\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0640 - val_loss: 0.0383\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0624 - val_loss: 0.0303\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0684 - val_loss: 0.0246\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0633 - val_loss: 0.0227\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0619 - val_loss: 0.0237\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1104 - val_loss: 0.0282\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0884 - val_loss: 0.0343\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0756 - val_loss: 0.0358\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0793 - val_loss: 0.0286\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0819 - val_loss: 0.0244\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0537 - val_loss: 0.0239\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0524 - val_loss: 0.0272\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0869 - val_loss: 0.0443\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0683 - val_loss: 0.0504\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0890 - val_loss: 0.0436\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0680 - val_loss: 0.0383\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0718 - val_loss: 0.0276\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0753 - val_loss: 0.0245\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0253\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0604 - val_loss: 0.0261\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0795 - val_loss: 0.0287\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.0321\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0666 - val_loss: 0.0325\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0790 - val_loss: 0.0305\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0585 - val_loss: 0.0305\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0680 - val_loss: 0.0284\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0690 - val_loss: 0.0270\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0523 - val_loss: 0.0275\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0686 - val_loss: 0.0283\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "MSE: 0.0912835195278083\n",
            "MAE: 0.2200591333308477\n",
            "R^2: -8.394571187106934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 3 (Inputs are Discharging Capacity, CCCT, and CCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCtLBDb1yorj",
        "outputId": "6f4feada-0896-49e3-d1a0-aba52a89d9b3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 49ms/step - loss: 3.2231 - val_loss: 2.0602\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5673 - val_loss: 1.5706\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.1356 - val_loss: 1.2069\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7299 - val_loss: 0.9148\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3507 - val_loss: 0.6917\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0559 - val_loss: 0.5207\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7015 - val_loss: 0.4093\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5221 - val_loss: 0.3617\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3376 - val_loss: 0.3644\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3088 - val_loss: 0.3694\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2834 - val_loss: 0.3663\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3266 - val_loss: 0.3278\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3358 - val_loss: 0.2803\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2526 - val_loss: 0.2659\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2185 - val_loss: 0.2729\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1939 - val_loss: 0.2702\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2276 - val_loss: 0.2559\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1667 - val_loss: 0.2397\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1580 - val_loss: 0.2314\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1785 - val_loss: 0.2819\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1702 - val_loss: 0.2977\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1829 - val_loss: 0.2972\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1534 - val_loss: 0.2734\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1505 - val_loss: 0.2444\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1523 - val_loss: 0.2033\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1378 - val_loss: 0.1692\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0987 - val_loss: 0.1517\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2120 - val_loss: 0.1543\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1286 - val_loss: 0.1561\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1355 - val_loss: 0.1478\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1234 - val_loss: 0.1424\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1244 - val_loss: 0.1334\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1127 - val_loss: 0.1371\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1034 - val_loss: 0.1317\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1031 - val_loss: 0.1224\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1077 - val_loss: 0.1232\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0904 - val_loss: 0.1173\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1074 - val_loss: 0.1097\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1151 - val_loss: 0.0986\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0908 - val_loss: 0.0948\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0985 - val_loss: 0.0966\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0727 - val_loss: 0.0986\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1219 - val_loss: 0.0977\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1073 - val_loss: 0.1063\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0954 - val_loss: 0.2375\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1378 - val_loss: 0.3331\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1197 - val_loss: 0.3425\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1154 - val_loss: 0.3078\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1008 - val_loss: 0.2731\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1034 - val_loss: 0.2541\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1000 - val_loss: 0.2108\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0765 - val_loss: 0.1612\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0849 - val_loss: 0.1413\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1095 - val_loss: 0.1425\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0819 - val_loss: 0.1447\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0989 - val_loss: 0.1544\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0630 - val_loss: 0.1596\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0869 - val_loss: 0.1567\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0728 - val_loss: 0.1322\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0789 - val_loss: 0.1190\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0756 - val_loss: 0.1194\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0822 - val_loss: 0.1275\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0992 - val_loss: 0.1248\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0710 - val_loss: 0.1103\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0881 - val_loss: 0.0908\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0884 - val_loss: 0.0794\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0816 - val_loss: 0.0751\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0811 - val_loss: 0.0787\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0762 - val_loss: 0.0834\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0708 - val_loss: 0.0794\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0692 - val_loss: 0.0706\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0851 - val_loss: 0.0665\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1010 - val_loss: 0.0660\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0671 - val_loss: 0.0580\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0535 - val_loss: 0.0587\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1018 - val_loss: 0.0585\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0787 - val_loss: 0.0603\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0781 - val_loss: 0.0654\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0719 - val_loss: 0.0664\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0619 - val_loss: 0.0650\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0701 - val_loss: 0.0625\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0787 - val_loss: 0.0635\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0746 - val_loss: 0.0720\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0849 - val_loss: 0.0763\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0742 - val_loss: 0.0786\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0755 - val_loss: 0.0759\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0561 - val_loss: 0.0777\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0817 - val_loss: 0.0706\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0550 - val_loss: 0.0657\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0561 - val_loss: 0.0630\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0719 - val_loss: 0.0559\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0665 - val_loss: 0.0517\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0815 - val_loss: 0.0506\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0507 - val_loss: 0.0513\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0787 - val_loss: 0.0554\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0671 - val_loss: 0.0509\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0712 - val_loss: 0.0498\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0686 - val_loss: 0.0520\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0619 - val_loss: 0.0593\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0569 - val_loss: 0.0596\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0693 - val_loss: 0.0554\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0701 - val_loss: 0.0520\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0639 - val_loss: 0.0427\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0495 - val_loss: 0.0382\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0663 - val_loss: 0.0375\n",
            "Epoch 107/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0537 - val_loss: 0.0384\n",
            "Epoch 108/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0504 - val_loss: 0.0363\n",
            "Epoch 109/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0654 - val_loss: 0.0380\n",
            "Epoch 110/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0555 - val_loss: 0.0401\n",
            "Epoch 111/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0570 - val_loss: 0.0399\n",
            "Epoch 112/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0651 - val_loss: 0.0397\n",
            "Epoch 113/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0599 - val_loss: 0.0371\n",
            "Epoch 114/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0818 - val_loss: 0.0365\n",
            "Epoch 115/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0765 - val_loss: 0.0547\n",
            "Epoch 116/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0622 - val_loss: 0.1865\n",
            "Epoch 117/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0907 - val_loss: 0.2660\n",
            "Epoch 118/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0961 - val_loss: 0.2565\n",
            "Epoch 119/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0952 - val_loss: 0.1852\n",
            "Epoch 120/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0667 - val_loss: 0.1232\n",
            "Epoch 121/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0671 - val_loss: 0.0952\n",
            "Epoch 122/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0596 - val_loss: 0.0732\n",
            "Epoch 123/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0580 - val_loss: 0.0569\n",
            "Epoch 124/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0683 - val_loss: 0.0488\n",
            "Epoch 125/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0502 - val_loss: 0.0420\n",
            "Epoch 126/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0553 - val_loss: 0.0444\n",
            "Epoch 127/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0588 - val_loss: 0.0580\n",
            "Epoch 128/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0602 - val_loss: 0.0522\n",
            "Epoch 129/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0618 - val_loss: 0.0449\n",
            "Epoch 130/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0584 - val_loss: 0.0430\n",
            "Epoch 131/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0543 - val_loss: 0.0400\n",
            "Epoch 132/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0610 - val_loss: 0.0406\n",
            "Epoch 133/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0543 - val_loss: 0.0354\n",
            "Epoch 134/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0675 - val_loss: 0.0337\n",
            "Epoch 135/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0648 - val_loss: 0.0329\n",
            "Epoch 136/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0634 - val_loss: 0.0323\n",
            "Epoch 137/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0660 - val_loss: 0.0352\n",
            "Epoch 138/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0695 - val_loss: 0.0428\n",
            "Epoch 139/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0606 - val_loss: 0.0413\n",
            "Epoch 140/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0566 - val_loss: 0.0352\n",
            "Epoch 141/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0562 - val_loss: 0.0334\n",
            "Epoch 142/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0357\n",
            "Epoch 143/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0628 - val_loss: 0.0391\n",
            "Epoch 144/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0628 - val_loss: 0.0442\n",
            "Epoch 145/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0557 - val_loss: 0.0443\n",
            "Epoch 146/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0560 - val_loss: 0.0360\n",
            "Epoch 147/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0553 - val_loss: 0.0321\n",
            "Epoch 148/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0636 - val_loss: 0.0318\n",
            "Epoch 149/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0498 - val_loss: 0.0367\n",
            "Epoch 150/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0555\n",
            "Epoch 151/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0641 - val_loss: 0.0529\n",
            "Epoch 152/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0525 - val_loss: 0.0408\n",
            "Epoch 153/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0637 - val_loss: 0.0369\n",
            "Epoch 154/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0715 - val_loss: 0.0384\n",
            "Epoch 155/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0484 - val_loss: 0.0356\n",
            "Epoch 156/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0644 - val_loss: 0.0286\n",
            "Epoch 157/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0582 - val_loss: 0.0249\n",
            "Epoch 158/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0648 - val_loss: 0.0249\n",
            "Epoch 159/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0625 - val_loss: 0.0250\n",
            "Epoch 160/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0531 - val_loss: 0.0257\n",
            "Epoch 161/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0626 - val_loss: 0.0252\n",
            "Epoch 162/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0639 - val_loss: 0.0295\n",
            "Epoch 163/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0543 - val_loss: 0.0466\n",
            "Epoch 164/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0629 - val_loss: 0.0541\n",
            "Epoch 165/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0730 - val_loss: 0.0474\n",
            "Epoch 166/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0648 - val_loss: 0.0311\n",
            "Epoch 167/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0539 - val_loss: 0.0284\n",
            "Epoch 168/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.0289\n",
            "Epoch 169/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0569 - val_loss: 0.0285\n",
            "Epoch 170/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0669 - val_loss: 0.0279\n",
            "Epoch 171/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0441 - val_loss: 0.0294\n",
            "Epoch 172/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0558 - val_loss: 0.0311\n",
            "Epoch 173/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0498 - val_loss: 0.0312\n",
            "Epoch 174/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0589 - val_loss: 0.0292\n",
            "Epoch 175/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0525 - val_loss: 0.0248\n",
            "Epoch 176/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0525 - val_loss: 0.0228\n",
            "Epoch 177/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0582 - val_loss: 0.0237\n",
            "Epoch 178/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0435 - val_loss: 0.0237\n",
            "Epoch 179/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0395 - val_loss: 0.0230\n",
            "Epoch 180/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0604 - val_loss: 0.0213\n",
            "Epoch 181/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0582 - val_loss: 0.0199\n",
            "Epoch 182/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0595 - val_loss: 0.0258\n",
            "Epoch 183/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0653 - val_loss: 0.0380\n",
            "Epoch 184/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0590 - val_loss: 0.0400\n",
            "Epoch 185/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0558 - val_loss: 0.0326\n",
            "Epoch 186/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.0336\n",
            "Epoch 187/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0447 - val_loss: 0.0868\n",
            "Epoch 188/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0721 - val_loss: 0.1187\n",
            "Epoch 189/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0632 - val_loss: 0.1083\n",
            "Epoch 190/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0722 - val_loss: 0.0740\n",
            "Epoch 191/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0665 - val_loss: 0.0556\n",
            "Epoch 192/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0428 - val_loss: 0.0309\n",
            "Epoch 193/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.0206\n",
            "Epoch 194/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0476 - val_loss: 0.0184\n",
            "Epoch 195/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0537 - val_loss: 0.0181\n",
            "Epoch 196/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0472 - val_loss: 0.0183\n",
            "Epoch 197/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0523 - val_loss: 0.0199\n",
            "Epoch 198/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0474 - val_loss: 0.0189\n",
            "Epoch 199/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0553 - val_loss: 0.0197\n",
            "Epoch 200/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0602 - val_loss: 0.0307\n",
            "Epoch 201/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0476 - val_loss: 0.0518\n",
            "Epoch 202/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0594 - val_loss: 0.0566\n",
            "Epoch 203/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0452 - val_loss: 0.0452\n",
            "Epoch 204/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0578 - val_loss: 0.0360\n",
            "Epoch 205/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0546 - val_loss: 0.0312\n",
            "Epoch 206/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0499 - val_loss: 0.0283\n",
            "Epoch 207/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0493 - val_loss: 0.0228\n",
            "Epoch 208/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0573 - val_loss: 0.0202\n",
            "Epoch 209/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0538 - val_loss: 0.0211\n",
            "Epoch 210/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0553 - val_loss: 0.0239\n",
            "Epoch 211/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0678 - val_loss: 0.0216\n",
            "Epoch 212/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0476 - val_loss: 0.0201\n",
            "Epoch 213/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0525 - val_loss: 0.0203\n",
            "Epoch 214/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0500 - val_loss: 0.0269\n",
            "Epoch 215/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0443 - val_loss: 0.0324\n",
            "Epoch 216/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0725 - val_loss: 0.0299\n",
            "Epoch 217/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0493 - val_loss: 0.0272\n",
            "Epoch 218/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0458 - val_loss: 0.0224\n",
            "Epoch 219/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0410 - val_loss: 0.0207\n",
            "Epoch 220/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0561 - val_loss: 0.0230\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.18794763050845734\n",
            "MAE: 0.3195734024875935\n",
            "R^2: -18.34289347511278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 4 (Inputs are Discharging Capacity, CCCT, CCV, and CVCC)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A8s7Pi40XUK",
        "outputId": "cacdf522-f414-4998-de5c-812105a26a55"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 51ms/step - loss: 2.4409 - val_loss: 1.2175\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1516 - val_loss: 0.4494\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5526 - val_loss: 0.2208\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4825 - val_loss: 0.2156\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3687 - val_loss: 0.1746\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2516 - val_loss: 0.1617\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2821 - val_loss: 0.2163\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1612 - val_loss: 0.2716\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1802 - val_loss: 0.2195\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1346 - val_loss: 0.1582\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1886 - val_loss: 0.1621\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1411 - val_loss: 0.1633\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1258 - val_loss: 0.1634\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1130 - val_loss: 0.1611\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1235 - val_loss: 0.1563\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0854 - val_loss: 0.1594\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1101 - val_loss: 0.1537\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0798 - val_loss: 0.1482\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1196 - val_loss: 0.1413\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0842 - val_loss: 0.1368\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1040 - val_loss: 0.1331\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1126 - val_loss: 0.1317\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1124 - val_loss: 0.1423\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1025 - val_loss: 0.1234\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1032 - val_loss: 0.1169\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0955 - val_loss: 0.1265\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0767 - val_loss: 0.1475\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0954 - val_loss: 0.1657\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0720 - val_loss: 0.1453\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0789 - val_loss: 0.1312\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0768 - val_loss: 0.1334\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0983 - val_loss: 0.1434\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0703 - val_loss: 0.1145\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0674 - val_loss: 0.0988\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0889 - val_loss: 0.1027\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0733 - val_loss: 0.1172\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0626 - val_loss: 0.1344\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0887 - val_loss: 0.1265\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0656 - val_loss: 0.1172\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0702 - val_loss: 0.0995\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0817 - val_loss: 0.0980\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0851 - val_loss: 0.1137\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0677 - val_loss: 0.1316\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0639 - val_loss: 0.1396\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0689 - val_loss: 0.1224\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0545 - val_loss: 0.0937\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0707 - val_loss: 0.0958\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0747 - val_loss: 0.1015\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0735 - val_loss: 0.1210\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0695 - val_loss: 0.1135\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0560 - val_loss: 0.0899\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0765 - val_loss: 0.0894\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0613 - val_loss: 0.1050\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0684 - val_loss: 0.1070\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0715 - val_loss: 0.0848\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0903 - val_loss: 0.1201\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1191 - val_loss: 0.1251\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1174 - val_loss: 0.1264\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0895 - val_loss: 0.1194\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0781 - val_loss: 0.1058\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0923 - val_loss: 0.1020\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0749 - val_loss: 0.1192\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0645 - val_loss: 0.1243\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0746 - val_loss: 0.1132\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0729 - val_loss: 0.0862\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0777 - val_loss: 0.0901\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0623 - val_loss: 0.1041\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0472 - val_loss: 0.1206\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0507 - val_loss: 0.1165\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0630 - val_loss: 0.1126\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0588 - val_loss: 0.1045\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0712 - val_loss: 0.0923\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0659 - val_loss: 0.0877\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0465 - val_loss: 0.0892\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0474 - val_loss: 0.0841\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0615 - val_loss: 0.0753\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0566 - val_loss: 0.0763\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0648 - val_loss: 0.0858\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0486 - val_loss: 0.1075\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0539 - val_loss: 0.1348\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0530 - val_loss: 0.1092\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0512 - val_loss: 0.0713\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0648 - val_loss: 0.0642\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0527 - val_loss: 0.0849\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0548 - val_loss: 0.1094\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0448 - val_loss: 0.1172\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0554 - val_loss: 0.1046\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0563 - val_loss: 0.1051\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0517 - val_loss: 0.1209\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0589 - val_loss: 0.0859\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0490 - val_loss: 0.0635\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0748 - val_loss: 0.0709\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0347 - val_loss: 0.0858\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0596 - val_loss: 0.1183\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0536 - val_loss: 0.1001\n",
            "Epoch 96/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0494 - val_loss: 0.0788\n",
            "Epoch 97/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0602 - val_loss: 0.0579\n",
            "Epoch 98/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0621 - val_loss: 0.0897\n",
            "Epoch 99/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0531 - val_loss: 0.1433\n",
            "Epoch 100/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0696 - val_loss: 0.0918\n",
            "Epoch 101/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0438 - val_loss: 0.0600\n",
            "Epoch 102/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0428 - val_loss: 0.0726\n",
            "Epoch 103/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0487 - val_loss: 0.0846\n",
            "Epoch 104/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0544 - val_loss: 0.0804\n",
            "Epoch 105/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0521 - val_loss: 0.0698\n",
            "Epoch 106/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0411 - val_loss: 0.0686\n",
            "Epoch 107/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0561 - val_loss: 0.0781\n",
            "Epoch 108/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0515 - val_loss: 0.0679\n",
            "Epoch 109/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0493 - val_loss: 0.0807\n",
            "Epoch 110/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0504 - val_loss: 0.0899\n",
            "Epoch 111/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0496 - val_loss: 0.0803\n",
            "Epoch 112/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0417 - val_loss: 0.0509\n",
            "Epoch 113/10000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0490 - val_loss: 0.0518\n",
            "Epoch 114/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0449 - val_loss: 0.0844\n",
            "Epoch 115/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0400 - val_loss: 0.0843\n",
            "Epoch 116/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0441 - val_loss: 0.0648\n",
            "Epoch 117/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0538 - val_loss: 0.0872\n",
            "Epoch 118/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0539 - val_loss: 0.1098\n",
            "Epoch 119/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0517 - val_loss: 0.1528\n",
            "Epoch 120/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0481 - val_loss: 0.1410\n",
            "Epoch 121/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0496 - val_loss: 0.0826\n",
            "Epoch 122/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0426 - val_loss: 0.0606\n",
            "Epoch 123/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0472 - val_loss: 0.0728\n",
            "Epoch 124/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0491 - val_loss: 0.0722\n",
            "Epoch 125/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0386 - val_loss: 0.0564\n",
            "Epoch 126/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0402 - val_loss: 0.0669\n",
            "Epoch 127/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0519 - val_loss: 0.0828\n",
            "Epoch 128/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0544 - val_loss: 0.1579\n",
            "Epoch 129/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0549 - val_loss: 0.0862\n",
            "Epoch 130/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0544 - val_loss: 0.0759\n",
            "Epoch 131/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0439 - val_loss: 0.0765\n",
            "Epoch 132/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0370 - val_loss: 0.0796\n",
            "Epoch 133/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0583 - val_loss: 0.0786\n",
            "Epoch 134/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0515 - val_loss: 0.0696\n",
            "Epoch 135/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0531 - val_loss: 0.0636\n",
            "Epoch 136/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.0660\n",
            "Epoch 137/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0510 - val_loss: 0.0631\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 0.1293542112303242\n",
            "MAE: 0.30544936818021273\n",
            "R^2: -12.312669713454083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 5 (Inputs are CCDT and CCDV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF-7xylz1Wlx",
        "outputId": "5be78e0c-7486-4bcd-9151-cedd2ff0cef4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 45ms/step - loss: 2.2278 - val_loss: 1.5452\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.6479 - val_loss: 0.8358\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2350 - val_loss: 0.3869\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9605 - val_loss: 0.1858\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8295 - val_loss: 0.3093\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6137 - val_loss: 0.8613\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4179 - val_loss: 1.8097\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3512 - val_loss: 3.0304\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2809 - val_loss: 4.0681\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2638 - val_loss: 4.8143\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2260 - val_loss: 5.1321\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2439 - val_loss: 4.9671\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2562 - val_loss: 4.3855\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2185 - val_loss: 3.4525\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1977 - val_loss: 2.6551\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1934 - val_loss: 2.0492\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1703 - val_loss: 1.7992\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1806 - val_loss: 1.6929\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1489 - val_loss: 1.7408\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1313 - val_loss: 1.6732\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1400 - val_loss: 1.5344\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1134 - val_loss: 1.4201\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1222 - val_loss: 1.4288\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0943 - val_loss: 1.2935\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0882 - val_loss: 1.1043\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0985 - val_loss: 0.9455\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1005 - val_loss: 0.8874\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0845 - val_loss: 0.8108\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0944 - val_loss: 0.7536\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "MSE: 0.7298059626096361\n",
            "MAE: 0.73121539392051\n",
            "R^2: -74.10900219423151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 6 (Inputs are CCDV and RoCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08L8Stqg2NIa",
        "outputId": "52d976db-00d8-44b4-81f8-3f990dc9968f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 67ms/step - loss: 2.6784 - val_loss: 1.8838\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.7860 - val_loss: 0.8977\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.1518 - val_loss: 0.2957\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7459 - val_loss: 0.1195\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5527 - val_loss: 0.3504\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4170 - val_loss: 0.8738\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3417 - val_loss: 1.5211\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2447 - val_loss: 2.0198\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2013 - val_loss: 2.5607\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1561 - val_loss: 3.1068\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1611 - val_loss: 3.4449\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1192 - val_loss: 3.0644\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1392 - val_loss: 2.8077\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0955 - val_loss: 2.7238\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1318 - val_loss: 2.6458\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1192 - val_loss: 2.5696\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1043 - val_loss: 2.5176\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1113 - val_loss: 2.2679\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0886 - val_loss: 2.1005\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1035 - val_loss: 1.9632\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0971 - val_loss: 1.9314\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0797 - val_loss: 1.7767\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1017 - val_loss: 1.7551\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0866 - val_loss: 1.7065\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0950 - val_loss: 1.7266\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0739 - val_loss: 1.7414\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0865 - val_loss: 1.7472\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0895 - val_loss: 1.8110\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0893 - val_loss: 1.8395\n",
            "6/6 [==============================] - 0s 4ms/step\n",
            "MSE: 0.2780142825750193\n",
            "MAE: 0.4211950511824027\n",
            "R^2: -27.61222904412471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 7 (Inputs are Discharging Capacity, CCDT, and CCDV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLfiNPSQ3Ik2",
        "outputId": "2810e572-add5-4cef-f492-a496b6ff696c"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 50ms/step - loss: 2.7812 - val_loss: 3.0869\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1964 - val_loss: 2.0998\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7504 - val_loss: 1.2881\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3820 - val_loss: 0.6845\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0820 - val_loss: 0.2959\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8299 - val_loss: 0.2048\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5930 - val_loss: 0.5251\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4080 - val_loss: 1.2781\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3469 - val_loss: 2.3682\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2813 - val_loss: 3.5064\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2424 - val_loss: 4.2441\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2996 - val_loss: 4.1487\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2499 - val_loss: 3.7132\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2333 - val_loss: 3.1232\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1929 - val_loss: 2.6432\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1797 - val_loss: 2.2454\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1604 - val_loss: 1.9082\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1685 - val_loss: 1.5361\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1538 - val_loss: 1.2836\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1390 - val_loss: 1.1476\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1215 - val_loss: 1.1232\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1263 - val_loss: 1.1820\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1272 - val_loss: 1.3007\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1338 - val_loss: 1.2775\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1132 - val_loss: 1.1556\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0983 - val_loss: 0.9804\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1031 - val_loss: 0.8565\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0874 - val_loss: 0.7653\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0858 - val_loss: 0.6572\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1064 - val_loss: 0.5769\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0874 - val_loss: 0.5522\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "MSE: 0.5280608258589625\n",
            "MAE: 0.6247687380880932\n",
            "R^2: -53.34611905102135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convolutional Neural Network (CNN) with Case 8 (Inputs are Discharging Capacity, CCDT, CCDV, and RoCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),  # Reduced filter size and kernel size\n",
        "    MaxPooling1D(pool_size=2),  # Standard pooling size\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),  # Slightly less dropout to keep more information\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAGfcEO-3kFg",
        "outputId": "84dd4fd9-081e-4823-e607-f0b37ff9c232"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 1s 72ms/step - loss: 2.3763 - val_loss: 1.4429\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.4022 - val_loss: 0.6912\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.8026 - val_loss: 0.1801\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5536 - val_loss: 0.0599\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4266 - val_loss: 0.2920\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3236 - val_loss: 0.7069\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2214 - val_loss: 1.1173\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1345 - val_loss: 1.5355\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1405 - val_loss: 1.8892\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1388 - val_loss: 2.0520\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1353 - val_loss: 2.0499\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1325 - val_loss: 2.0024\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1256 - val_loss: 1.7931\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1383 - val_loss: 1.3294\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1059 - val_loss: 1.1721\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1021 - val_loss: 1.1571\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1354 - val_loss: 1.0831\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1219 - val_loss: 0.9849\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1162 - val_loss: 0.8413\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0968 - val_loss: 0.8882\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1072 - val_loss: 0.9412\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0875 - val_loss: 0.9156\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0905 - val_loss: 0.8727\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0855 - val_loss: 0.8203\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1127 - val_loss: 0.7522\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0873 - val_loss: 0.6403\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0965 - val_loss: 0.6545\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0914 - val_loss: 0.7371\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0848 - val_loss: 0.8805\n",
            "6/6 [==============================] - 0s 3ms/step\n",
            "MSE: 1.3184019748995726\n",
            "MAE: 0.9388608037005898\n",
            "R^2: -134.68518469145167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with Case 1 (Inputs are CCCT and CCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4a98d6-6b69-48be-dd82-a95aa2713a59",
        "id": "Y03VoBmu5fe1"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 11s 431ms/step - loss: 2.8989 - val_loss: 2.9589\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.3237 - val_loss: 2.7653\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.4998 - val_loss: 2.6660\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.8724 - val_loss: 2.4294\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.8580 - val_loss: 2.0207\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4868 - val_loss: 1.5548\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3929 - val_loss: 0.9611\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2432 - val_loss: 0.3340\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0765 - val_loss: 0.0389\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0947 - val_loss: 0.0494\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0492 - val_loss: 0.0440\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0464 - val_loss: 0.0397\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0553 - val_loss: 0.0267\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0358 - val_loss: 0.0188\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0429 - val_loss: 0.0130\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0340 - val_loss: 0.0172\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0297 - val_loss: 0.0123\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0305 - val_loss: 0.0170\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0365 - val_loss: 0.0280\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0265 - val_loss: 0.0217\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0277 - val_loss: 0.0100\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0222 - val_loss: 0.0094\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0227 - val_loss: 0.0118\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0273 - val_loss: 0.0115\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0220 - val_loss: 0.0092\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0194 - val_loss: 0.0103\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0224 - val_loss: 0.0154\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0263 - val_loss: 0.0101\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0191 - val_loss: 0.0155\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0232 - val_loss: 0.0096\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0204 - val_loss: 0.0114\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0206 - val_loss: 0.0278\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0157 - val_loss: 0.0258\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0181 - val_loss: 0.0273\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0174 - val_loss: 0.0164\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0209 - val_loss: 0.0140\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0166 - val_loss: 0.0155\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0215 - val_loss: 0.0210\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0174 - val_loss: 0.0147\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0200 - val_loss: 0.0186\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0193 - val_loss: 0.0217\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0212 - val_loss: 0.0158\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0170 - val_loss: 0.0134\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0142 - val_loss: 0.0126\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0148 - val_loss: 0.0133\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0140 - val_loss: 0.0156\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0134 - val_loss: 0.0278\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0142 - val_loss: 0.0191\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0157 - val_loss: 0.0163\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0140 - val_loss: 0.0194\n",
            "6/6 [==============================] - 2s 6ms/step\n",
            "MSE: 0.20236726077164352\n",
            "MAE: 0.4142233077200839\n",
            "R^2: -19.826909907651803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with Case 2 (Inputs are Discharging Capacity and CVCC)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jKJ_PoO8ZRn",
        "outputId": "1efb1c1a-2ee2-4c58-ca2d-caaff7293918"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 11s 411ms/step - loss: 2.8008 - val_loss: 2.3044\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 2.1094 - val_loss: 1.5041\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.3230 - val_loss: 0.6045\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5341 - val_loss: 0.0684\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2976 - val_loss: 0.3925\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3757 - val_loss: 0.0612\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1801 - val_loss: 0.0651\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1354 - val_loss: 0.1275\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1138 - val_loss: 0.0461\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0410 - val_loss: 0.0072\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0607 - val_loss: 0.0173\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0408 - val_loss: 0.0110\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0386 - val_loss: 0.0249\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0280 - val_loss: 0.0087\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0277 - val_loss: 0.0014\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0359 - val_loss: 0.0022\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0315 - val_loss: 0.0073\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0244 - val_loss: 0.0116\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0241 - val_loss: 0.0082\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0205 - val_loss: 0.0075\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0219 - val_loss: 0.0079\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0157 - val_loss: 0.0059\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0255 - val_loss: 0.0065\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0206 - val_loss: 0.0247\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0231 - val_loss: 0.0268\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0278 - val_loss: 0.0089\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0182 - val_loss: 0.0087\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0245 - val_loss: 0.0126\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0262 - val_loss: 0.0259\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0226 - val_loss: 0.0116\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0212 - val_loss: 0.0060\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0218 - val_loss: 0.0401\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0265 - val_loss: 0.0176\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0195 - val_loss: 0.0029\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0218 - val_loss: 0.0076\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0190 - val_loss: 0.0087\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0128 - val_loss: 0.0171\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0161 - val_loss: 0.0154\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0178 - val_loss: 0.0099\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0205 - val_loss: 0.0069\n",
            "6/6 [==============================] - 2s 8ms/step\n",
            "MSE: 0.02502121702543248\n",
            "MAE: 0.08923721772200839\n",
            "R^2: -1.5750935738391254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) with Case 3 (Inputs are Discharging Capacity, CCCT, and CCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "id": "q8nrKjwn-SY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c467c196-8de6-41af-cda6-8e102664783e"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 12s 468ms/step - loss: 3.0303 - val_loss: 2.9764\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.6545 - val_loss: 2.8707\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.1318 - val_loss: 2.7647\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.3485 - val_loss: 2.6873\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.6833 - val_loss: 2.5112\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.7505 - val_loss: 2.1682\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4067 - val_loss: 1.7052\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3759 - val_loss: 1.1200\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2156 - val_loss: 0.4879\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1265 - val_loss: 0.1184\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0581 - val_loss: 0.0460\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0357 - val_loss: 0.0364\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0290 - val_loss: 0.0879\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0425 - val_loss: 0.0752\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0286 - val_loss: 0.0170\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0294 - val_loss: 0.0124\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0191 - val_loss: 0.0070\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0223 - val_loss: 0.0045\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0188 - val_loss: 0.0053\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0175 - val_loss: 0.0059\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0203 - val_loss: 0.0118\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0250 - val_loss: 0.0086\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0159 - val_loss: 0.0040\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0157 - val_loss: 0.0034\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0143 - val_loss: 0.0029\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0167 - val_loss: 0.0032\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0164 - val_loss: 0.0042\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0135 - val_loss: 0.0043\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0128 - val_loss: 0.0049\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0146 - val_loss: 0.0071\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0155 - val_loss: 0.0041\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0138 - val_loss: 0.0033\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0169 - val_loss: 0.0048\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0124 - val_loss: 0.0063\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0172 - val_loss: 0.0050\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0149 - val_loss: 0.0050\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0169 - val_loss: 0.0113\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0126 - val_loss: 0.0109\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0162 - val_loss: 0.0050\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0156 - val_loss: 0.0134\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0118 - val_loss: 0.0095\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0126 - val_loss: 0.0038\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0125 - val_loss: 0.0071\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0134 - val_loss: 0.0189\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0129 - val_loss: 0.0106\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0121 - val_loss: 0.0092\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0132 - val_loss: 0.0074\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0115 - val_loss: 0.0028\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0127 - val_loss: 0.0032\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0131 - val_loss: 0.0066\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0166 - val_loss: 0.0044\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0156 - val_loss: 0.0054\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0181 - val_loss: 0.0137\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0097 - val_loss: 0.0049\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0110 - val_loss: 0.0323\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0194 - val_loss: 0.0220\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0114 - val_loss: 0.0134\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0122 - val_loss: 0.0038\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0096 - val_loss: 0.0051\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0178 - val_loss: 0.0051\n",
            "Epoch 61/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0133 - val_loss: 0.0037\n",
            "Epoch 62/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0180 - val_loss: 0.0119\n",
            "Epoch 63/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0163 - val_loss: 0.0037\n",
            "Epoch 64/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0197 - val_loss: 0.0153\n",
            "Epoch 65/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0171 - val_loss: 0.0333\n",
            "Epoch 66/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0234\n",
            "Epoch 67/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0208 - val_loss: 0.0300\n",
            "Epoch 68/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0198 - val_loss: 0.0078\n",
            "Epoch 69/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0114 - val_loss: 0.0131\n",
            "Epoch 70/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0183 - val_loss: 0.0028\n",
            "Epoch 71/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0209 - val_loss: 0.0066\n",
            "Epoch 72/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0104 - val_loss: 0.0046\n",
            "Epoch 73/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0143 - val_loss: 0.0157\n",
            "Epoch 74/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0208 - val_loss: 0.0057\n",
            "Epoch 75/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0117 - val_loss: 0.0110\n",
            "Epoch 76/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0159 - val_loss: 0.0046\n",
            "Epoch 77/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0143 - val_loss: 0.0035\n",
            "Epoch 78/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0133 - val_loss: 0.0096\n",
            "Epoch 79/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0146 - val_loss: 0.0274\n",
            "Epoch 80/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0125 - val_loss: 0.0046\n",
            "Epoch 81/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0031\n",
            "Epoch 82/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0113 - val_loss: 0.0075\n",
            "Epoch 83/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0116\n",
            "Epoch 84/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0112 - val_loss: 0.0144\n",
            "Epoch 85/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0103 - val_loss: 0.0087\n",
            "Epoch 86/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0080 - val_loss: 0.0083\n",
            "Epoch 87/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0103 - val_loss: 0.0036\n",
            "Epoch 88/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0085 - val_loss: 0.0096\n",
            "Epoch 89/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0043\n",
            "Epoch 90/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0156 - val_loss: 0.0032\n",
            "Epoch 91/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0113 - val_loss: 0.0067\n",
            "Epoch 92/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0133 - val_loss: 0.0033\n",
            "Epoch 93/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0220 - val_loss: 0.0051\n",
            "Epoch 94/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0098 - val_loss: 0.0247\n",
            "Epoch 95/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0098 - val_loss: 0.0039\n",
            "6/6 [==============================] - 2s 6ms/step\n",
            "MSE: 0.07610617858329351\n",
            "MAE: 0.24032514690978268\n",
            "R^2: -6.832573899186846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with Case 4 (Inputs are Discharging Capacity, CCCT, CCV, and CVCC)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzw7TsRcqc2O",
        "outputId": "4a262d5c-7cf5-4d30-a63f-cbcf7dde5912"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 11s 636ms/step - loss: 2.9330 - val_loss: 2.8654\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 2.3298 - val_loss: 2.6846\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1.5654 - val_loss: 2.3622\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.7783 - val_loss: 1.6363\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4294 - val_loss: 0.4123\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.1901 - val_loss: 0.1279\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1587 - val_loss: 0.0639\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0751 - val_loss: 0.0191\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0598 - val_loss: 0.0258\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0504 - val_loss: 0.0521\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0452 - val_loss: 0.0300\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0465 - val_loss: 0.0108\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0399 - val_loss: 0.0061\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0383 - val_loss: 0.0168\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0350 - val_loss: 0.0052\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0273 - val_loss: 0.0061\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0212 - val_loss: 0.0056\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0251 - val_loss: 0.0066\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0303 - val_loss: 0.0061\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0234 - val_loss: 0.0053\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0262 - val_loss: 0.0060\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0157 - val_loss: 0.0045\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0298 - val_loss: 0.0103\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0191 - val_loss: 0.0067\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0211 - val_loss: 0.0054\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0240 - val_loss: 0.0084\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0169 - val_loss: 0.0045\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0236 - val_loss: 0.0031\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0156 - val_loss: 0.0035\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0155 - val_loss: 0.0052\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0195 - val_loss: 0.0120\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0186 - val_loss: 0.0083\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0158 - val_loss: 0.0250\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0202 - val_loss: 0.0165\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0205 - val_loss: 0.0118\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0182 - val_loss: 0.0057\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0205\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0200 - val_loss: 0.0133\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0197 - val_loss: 0.0121\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0181 - val_loss: 0.0057\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0171 - val_loss: 0.0105\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0143 - val_loss: 0.0049\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0154 - val_loss: 0.0060\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0170 - val_loss: 0.0310\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0128 - val_loss: 0.0117\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0172 - val_loss: 0.0213\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0152 - val_loss: 0.0056\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0159 - val_loss: 0.0036\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0178 - val_loss: 0.0038\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0177 - val_loss: 0.0050\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0207 - val_loss: 0.0246\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0195 - val_loss: 0.0079\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0204 - val_loss: 0.0040\n",
            "6/6 [==============================] - 2s 8ms/step\n",
            "MSE: 0.1502917323670378\n",
            "MAE: 0.35982666921664247\n",
            "R^2: -14.467484008716772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with with Case 5 (Inputs are CCDT and CCDV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQWW3FCtyXAj",
        "outputId": "71800aa9-1d35-4be8-a097-3c21d1ca7f85"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 11s 585ms/step - loss: 2.9368 - val_loss: 2.7507\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.3494 - val_loss: 2.2842\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.7416 - val_loss: 1.7777\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.3582 - val_loss: 0.9481\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.1255 - val_loss: 0.2216\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6345 - val_loss: 0.5868\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2335 - val_loss: 3.7560\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1069 - val_loss: 5.3163\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1560 - val_loss: 3.2295\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0666 - val_loss: 1.6063\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0493 - val_loss: 1.0022\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0846 - val_loss: 0.7867\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0456 - val_loss: 0.8712\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0416 - val_loss: 1.0561\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0394 - val_loss: 0.9446\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0288 - val_loss: 0.8000\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0293 - val_loss: 0.9155\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0268 - val_loss: 1.0311\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0263 - val_loss: 1.0954\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0277 - val_loss: 1.1831\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0243 - val_loss: 1.1365\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0259 - val_loss: 1.0263\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0215 - val_loss: 1.0415\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0237 - val_loss: 0.9729\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0253 - val_loss: 0.9444\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0298 - val_loss: 0.7165\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0234 - val_loss: 0.5835\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0254 - val_loss: 0.6897\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0194 - val_loss: 0.8291\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0231 - val_loss: 0.7956\n",
            "6/6 [==============================] - 2s 5ms/step\n",
            "MSE: 0.682007343493957\n",
            "MAE: 0.7381102003069027\n",
            "R^2: -69.18974040140742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with Case 6 (Inputs are CCDV and RoCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN51mkS1I5Gg",
        "outputId": "5a029e90-8256-4e22-d3b6-20756c11a677"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 11s 432ms/step - loss: 2.9757 - val_loss: 2.9421\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 2.3998 - val_loss: 2.7969\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.7193 - val_loss: 2.6994\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.0196 - val_loss: 2.3529\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.8311 - val_loss: 1.5874\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3790 - val_loss: 0.6229\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1780 - val_loss: 0.0851\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.1688 - val_loss: 0.0180\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0786 - val_loss: 0.0727\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0804 - val_loss: 0.0688\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0359 - val_loss: 0.0776\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0283 - val_loss: 0.0737\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0231 - val_loss: 0.0218\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0276 - val_loss: 0.0294\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0310 - val_loss: 0.0373\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0226 - val_loss: 0.0518\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0224 - val_loss: 0.0764\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0221 - val_loss: 0.0954\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0184 - val_loss: 0.1028\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0157 - val_loss: 0.1189\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0181 - val_loss: 0.1004\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0213 - val_loss: 0.0944\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0159 - val_loss: 0.0749\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0192 - val_loss: 0.0645\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0139 - val_loss: 0.1010\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0154 - val_loss: 0.1241\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0181 - val_loss: 0.1232\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0169 - val_loss: 0.0999\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0138 - val_loss: 0.0550\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0189 - val_loss: 0.0350\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0189 - val_loss: 0.0709\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0152 - val_loss: 0.0748\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0165 - val_loss: 0.0626\n",
            "6/6 [==============================] - 2s 7ms/step\n",
            "MSE: 0.3989622378645717\n",
            "MAE: 0.5772530912962818\n",
            "R^2: -40.059757160704194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with Case 7 (Inputs are Discharging Capacity, CCDT, and CCDV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02C3uKSHMetX",
        "outputId": "0d67f3c3-c5c5-4a9b-8737-dcc0e4d96669"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 12s 443ms/step - loss: 2.8694 - val_loss: 2.6368\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.2094 - val_loss: 2.1976\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.5268 - val_loss: 1.6744\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.2521 - val_loss: 1.0244\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.0393 - val_loss: 0.3812\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5903 - val_loss: 0.4264\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2375 - val_loss: 3.1841\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2138 - val_loss: 3.5671\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1170 - val_loss: 1.2852\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0876 - val_loss: 0.6230\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0763 - val_loss: 0.5874\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0345 - val_loss: 0.7304\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0302 - val_loss: 0.6817\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0410 - val_loss: 0.4390\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0236 - val_loss: 0.2898\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0325 - val_loss: 0.2645\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0271 - val_loss: 0.2752\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0256 - val_loss: 0.3196\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.2737\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0256 - val_loss: 0.2593\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0236 - val_loss: 0.2862\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0248 - val_loss: 0.2849\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0263 - val_loss: 0.2815\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0223 - val_loss: 0.2631\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0227 - val_loss: 0.2821\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0222 - val_loss: 0.2815\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0196 - val_loss: 0.2288\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.0269 - val_loss: 0.2256\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0244 - val_loss: 0.2104\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0213 - val_loss: 0.1760\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.0200 - val_loss: 0.1627\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0171 - val_loss: 0.1763\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0189 - val_loss: 0.2052\n",
            "Epoch 34/10000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0176 - val_loss: 0.1860\n",
            "Epoch 35/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0185 - val_loss: 0.1022\n",
            "Epoch 36/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0215 - val_loss: 0.1531\n",
            "Epoch 37/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0181 - val_loss: 0.3887\n",
            "Epoch 38/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0236 - val_loss: 0.3506\n",
            "Epoch 39/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0145 - val_loss: 0.2237\n",
            "Epoch 40/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0186 - val_loss: 0.2025\n",
            "Epoch 41/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0197 - val_loss: 0.3206\n",
            "Epoch 42/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0167 - val_loss: 0.3243\n",
            "Epoch 43/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0158 - val_loss: 0.1847\n",
            "Epoch 44/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0135 - val_loss: 0.2028\n",
            "Epoch 45/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0186 - val_loss: 0.2101\n",
            "Epoch 46/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0166 - val_loss: 0.1854\n",
            "Epoch 47/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0202 - val_loss: 0.1363\n",
            "Epoch 48/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0180 - val_loss: 0.1450\n",
            "Epoch 49/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0149 - val_loss: 0.2521\n",
            "Epoch 50/10000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0170 - val_loss: 0.2533\n",
            "Epoch 51/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0184 - val_loss: 0.1874\n",
            "Epoch 52/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0189 - val_loss: 0.2143\n",
            "Epoch 53/10000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0179 - val_loss: 0.1876\n",
            "Epoch 54/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0166 - val_loss: 0.1801\n",
            "Epoch 55/10000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0168 - val_loss: 0.1686\n",
            "Epoch 56/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.2101\n",
            "Epoch 57/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0216 - val_loss: 0.1202\n",
            "Epoch 58/10000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0163 - val_loss: 0.1100\n",
            "Epoch 59/10000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0176 - val_loss: 0.1084\n",
            "Epoch 60/10000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0190 - val_loss: 0.1346\n",
            "6/6 [==============================] - 2s 6ms/step\n",
            "MSE: 0.13964528824186329\n",
            "MAE: 0.30626271860321047\n",
            "R^2: -13.371790309121424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Long Short-Term Memory (LSTM) Model with Case 8 (Inputs are Discharging Capacity, CCDT, CCDV, and RoCV)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Flatten inputs for scaling\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train_scaled = X_train_scaled_flat.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled_flat.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# LSTM model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(50, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(50, return_sequences=False)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate the model\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm9nmyE2NqHz",
        "outputId": "5edfd16d-bac3-4f92-8a32-1273e58e77f2"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "5/5 [==============================] - 12s 449ms/step - loss: 2.8286 - val_loss: 2.7357\n",
            "Epoch 2/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 2.0705 - val_loss: 2.3482\n",
            "Epoch 3/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 1.2631 - val_loss: 1.5847\n",
            "Epoch 4/10000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6975 - val_loss: 0.7126\n",
            "Epoch 5/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3816 - val_loss: 0.1552\n",
            "Epoch 6/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2881 - val_loss: 0.1227\n",
            "Epoch 7/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1914 - val_loss: 0.0513\n",
            "Epoch 8/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0642 - val_loss: 0.0087\n",
            "Epoch 9/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0714 - val_loss: 0.0116\n",
            "Epoch 10/10000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0489 - val_loss: 0.0644\n",
            "Epoch 11/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0239 - val_loss: 0.1876\n",
            "Epoch 12/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0389 - val_loss: 0.1350\n",
            "Epoch 13/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0185 - val_loss: 0.0773\n",
            "Epoch 14/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0291 - val_loss: 0.0526\n",
            "Epoch 15/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0176 - val_loss: 0.0504\n",
            "Epoch 16/10000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0206 - val_loss: 0.0622\n",
            "Epoch 17/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0219 - val_loss: 0.0781\n",
            "Epoch 18/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0177 - val_loss: 0.0687\n",
            "Epoch 19/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0206 - val_loss: 0.0574\n",
            "Epoch 20/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0211 - val_loss: 0.0606\n",
            "Epoch 21/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0213 - val_loss: 0.0819\n",
            "Epoch 22/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0207 - val_loss: 0.0560\n",
            "Epoch 23/10000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0139 - val_loss: 0.0550\n",
            "Epoch 24/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0180 - val_loss: 0.0536\n",
            "Epoch 25/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0202 - val_loss: 0.0651\n",
            "Epoch 26/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0186 - val_loss: 0.0804\n",
            "Epoch 27/10000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0206 - val_loss: 0.0588\n",
            "Epoch 28/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0178 - val_loss: 0.0205\n",
            "Epoch 29/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0205 - val_loss: 0.0302\n",
            "Epoch 30/10000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0146 - val_loss: 0.0509\n",
            "Epoch 31/10000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0157 - val_loss: 0.0545\n",
            "Epoch 32/10000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0121 - val_loss: 0.0604\n",
            "Epoch 33/10000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0132 - val_loss: 0.0225\n",
            "6/6 [==============================] - 2s 15ms/step\n",
            "MSE: 0.6685662073903694\n",
            "MAE: 0.7406692964895224\n",
            "R^2: -67.80642706495924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 1 (Inputs are CCCT and CCV)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Combine and reshape data\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOtX8dpoVrj6",
        "outputId": "fa2d9bbf-05f2-48db-b810-b9fadc8cd220"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 89ms/step - loss: 0.9831 - mae: 0.9730 - val_loss: 0.6405 - val_mae: 0.7964\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6498 - mae: 0.7924 - val_loss: 0.6321 - val_mae: 0.7914\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6361 - mae: 0.7836 - val_loss: 0.6307 - val_mae: 0.7907\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6297 - mae: 0.7795 - val_loss: 0.6286 - val_mae: 0.7893\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6266 - mae: 0.7776 - val_loss: 0.6260 - val_mae: 0.7877\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6240 - mae: 0.7759 - val_loss: 0.6235 - val_mae: 0.7861\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6236 - mae: 0.7757 - val_loss: 0.6215 - val_mae: 0.7849\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6207 - mae: 0.7737 - val_loss: 0.6198 - val_mae: 0.7838\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6196 - mae: 0.7731 - val_loss: 0.6185 - val_mae: 0.7830\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6184 - mae: 0.7723 - val_loss: 0.6174 - val_mae: 0.7822\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6172 - mae: 0.7716 - val_loss: 0.6163 - val_mae: 0.7816\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6164 - mae: 0.7711 - val_loss: 0.6153 - val_mae: 0.7809\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6148 - mae: 0.7700 - val_loss: 0.6144 - val_mae: 0.7804\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6135 - mae: 0.7692 - val_loss: 0.6136 - val_mae: 0.7798\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6128 - mae: 0.7687 - val_loss: 0.6127 - val_mae: 0.7793\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6119 - mae: 0.7681 - val_loss: 0.6119 - val_mae: 0.7787\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6108 - mae: 0.7674 - val_loss: 0.6111 - val_mae: 0.7782\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6100 - mae: 0.7669 - val_loss: 0.6103 - val_mae: 0.7777\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6092 - mae: 0.7663 - val_loss: 0.6096 - val_mae: 0.7772\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6083 - mae: 0.7658 - val_loss: 0.6089 - val_mae: 0.7768\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6079 - mae: 0.7655 - val_loss: 0.6082 - val_mae: 0.7764\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6071 - mae: 0.7650 - val_loss: 0.6076 - val_mae: 0.7760\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6063 - mae: 0.7645 - val_loss: 0.6069 - val_mae: 0.7756\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6058 - mae: 0.7641 - val_loss: 0.6064 - val_mae: 0.7752\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6053 - mae: 0.7638 - val_loss: 0.6058 - val_mae: 0.7748\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6045 - mae: 0.7633 - val_loss: 0.6052 - val_mae: 0.7745\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6040 - mae: 0.7630 - val_loss: 0.6047 - val_mae: 0.7741\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6035 - mae: 0.7627 - val_loss: 0.6042 - val_mae: 0.7738\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6029 - mae: 0.7623 - val_loss: 0.6037 - val_mae: 0.7735\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6024 - mae: 0.7619 - val_loss: 0.6032 - val_mae: 0.7731\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6019 - mae: 0.7616 - val_loss: 0.6027 - val_mae: 0.7728\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6015 - mae: 0.7613 - val_loss: 0.6023 - val_mae: 0.7726\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6010 - mae: 0.7610 - val_loss: 0.6019 - val_mae: 0.7723\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6006 - mae: 0.7608 - val_loss: 0.6015 - val_mae: 0.7720\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6003 - mae: 0.7605 - val_loss: 0.6011 - val_mae: 0.7718\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6000 - mae: 0.7603 - val_loss: 0.6007 - val_mae: 0.7715\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5995 - mae: 0.7600 - val_loss: 0.6003 - val_mae: 0.7713\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5991 - mae: 0.7597 - val_loss: 0.6000 - val_mae: 0.7711\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5988 - mae: 0.7595 - val_loss: 0.5997 - val_mae: 0.7709\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5985 - mae: 0.7593 - val_loss: 0.5994 - val_mae: 0.7707\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5981 - mae: 0.7591 - val_loss: 0.5991 - val_mae: 0.7705\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5979 - mae: 0.7589 - val_loss: 0.5988 - val_mae: 0.7703\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5975 - mae: 0.7587 - val_loss: 0.5985 - val_mae: 0.7701\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5972 - mae: 0.7585 - val_loss: 0.5982 - val_mae: 0.7699\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5969 - mae: 0.7583 - val_loss: 0.5979 - val_mae: 0.7697\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5967 - mae: 0.7582 - val_loss: 0.5977 - val_mae: 0.7696\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5964 - mae: 0.7580 - val_loss: 0.5974 - val_mae: 0.7694\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5962 - mae: 0.7578 - val_loss: 0.5972 - val_mae: 0.7692\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5959 - mae: 0.7576 - val_loss: 0.5969 - val_mae: 0.7691\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5957 - mae: 0.7575 - val_loss: 0.5967 - val_mae: 0.7689\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5955 - mae: 0.7573 - val_loss: 0.5965 - val_mae: 0.7688\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5952 - mae: 0.7572 - val_loss: 0.5963 - val_mae: 0.7687\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5950 - mae: 0.7571 - val_loss: 0.5961 - val_mae: 0.7685\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5948 - mae: 0.7569 - val_loss: 0.5959 - val_mae: 0.7684\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5947 - mae: 0.7568 - val_loss: 0.5957 - val_mae: 0.7683\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5945 - mae: 0.7567 - val_loss: 0.5955 - val_mae: 0.7682\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5943 - mae: 0.7566 - val_loss: 0.5953 - val_mae: 0.7680\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5941 - mae: 0.7565 - val_loss: 0.5952 - val_mae: 0.7679\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5939 - mae: 0.7563 - val_loss: 0.5950 - val_mae: 0.7678\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5938 - mae: 0.7563 - val_loss: 0.5948 - val_mae: 0.7677\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5936 - mae: 0.7562 - val_loss: 0.5947 - val_mae: 0.7676\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5935 - mae: 0.7560 - val_loss: 0.5945 - val_mae: 0.7675\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5933 - mae: 0.7559 - val_loss: 0.5944 - val_mae: 0.7674\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5932 - mae: 0.7558 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5930 - mae: 0.7558 - val_loss: 0.5941 - val_mae: 0.7672\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5929 - mae: 0.7557 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5928 - mae: 0.7556 - val_loss: 0.5938 - val_mae: 0.7671\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5926 - mae: 0.7555 - val_loss: 0.5937 - val_mae: 0.7670\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5927 - mae: 0.7555 - val_loss: 0.5936 - val_mae: 0.7669\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5935 - val_mae: 0.7668\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5923 - mae: 0.7553 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5933 - val_mae: 0.7667\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5921 - mae: 0.7551 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5920 - mae: 0.7550 - val_loss: 0.5930 - val_mae: 0.7666\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5929 - val_mae: 0.7665\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5918 - mae: 0.7549 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5917 - mae: 0.7548 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5926 - val_mae: 0.7662\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5914 - mae: 0.7547 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7660\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5909 - mae: 0.7543 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7658\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5905 - mae: 0.7540 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7655\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5903 - mae: 0.7540 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5902 - mae: 0.7538 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5900 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7653\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5896 - mae: 0.7534 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7647\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5890 - mae: 0.7530 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5884 - mae: 0.7526 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "6/6 [==============================] - 0s 5ms/step\n",
            "MSE: 0.15112781303128717\n",
            "MAE: 0.37604679049494016\n",
            "R^2: -14.553530420589194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 2 (Inputs are Discharging Capacity and CVCC)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aArGLj20XtxE",
        "outputId": "b9da4739-836a-4eb9-f0ad-317dcea27224"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 87ms/step - loss: 0.8770 - mae: 0.9055 - val_loss: 0.6579 - val_mae: 0.8078\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6603 - mae: 0.7992 - val_loss: 0.6511 - val_mae: 0.8035\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6550 - mae: 0.7957 - val_loss: 0.6484 - val_mae: 0.8018\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6500 - mae: 0.7925 - val_loss: 0.6456 - val_mae: 0.8001\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6471 - mae: 0.7907 - val_loss: 0.6429 - val_mae: 0.7984\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6432 - mae: 0.7882 - val_loss: 0.6406 - val_mae: 0.7970\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6398 - mae: 0.7861 - val_loss: 0.6384 - val_mae: 0.7956\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6379 - mae: 0.7849 - val_loss: 0.6363 - val_mae: 0.7943\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6354 - mae: 0.7833 - val_loss: 0.6341 - val_mae: 0.7929\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6333 - mae: 0.7819 - val_loss: 0.6321 - val_mae: 0.7916\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6315 - mae: 0.7807 - val_loss: 0.6301 - val_mae: 0.7904\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6292 - mae: 0.7793 - val_loss: 0.6282 - val_mae: 0.7892\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6273 - mae: 0.7781 - val_loss: 0.6264 - val_mae: 0.7880\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6253 - mae: 0.7768 - val_loss: 0.6248 - val_mae: 0.7870\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6236 - mae: 0.7757 - val_loss: 0.6232 - val_mae: 0.7860\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6219 - mae: 0.7746 - val_loss: 0.6217 - val_mae: 0.7851\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6204 - mae: 0.7736 - val_loss: 0.6204 - val_mae: 0.7842\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6190 - mae: 0.7728 - val_loss: 0.6191 - val_mae: 0.7833\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6179 - mae: 0.7720 - val_loss: 0.6178 - val_mae: 0.7825\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6165 - mae: 0.7711 - val_loss: 0.6166 - val_mae: 0.7818\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6154 - mae: 0.7704 - val_loss: 0.6155 - val_mae: 0.7811\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6140 - mae: 0.7695 - val_loss: 0.6144 - val_mae: 0.7804\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6130 - mae: 0.7688 - val_loss: 0.6134 - val_mae: 0.7797\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6121 - mae: 0.7682 - val_loss: 0.6125 - val_mae: 0.7791\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6112 - mae: 0.7677 - val_loss: 0.6116 - val_mae: 0.7785\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6102 - mae: 0.7670 - val_loss: 0.6107 - val_mae: 0.7780\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6093 - mae: 0.7664 - val_loss: 0.6099 - val_mae: 0.7775\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6086 - mae: 0.7660 - val_loss: 0.6091 - val_mae: 0.7770\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6077 - mae: 0.7654 - val_loss: 0.6083 - val_mae: 0.7765\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6070 - mae: 0.7649 - val_loss: 0.6076 - val_mae: 0.7760\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6063 - mae: 0.7645 - val_loss: 0.6069 - val_mae: 0.7756\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6056 - mae: 0.7640 - val_loss: 0.6063 - val_mae: 0.7751\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6049 - mae: 0.7636 - val_loss: 0.6057 - val_mae: 0.7747\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6044 - mae: 0.7632 - val_loss: 0.6051 - val_mae: 0.7744\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.6038 - mae: 0.7628 - val_loss: 0.6045 - val_mae: 0.7740\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6032 - mae: 0.7625 - val_loss: 0.6040 - val_mae: 0.7737\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6027 - mae: 0.7621 - val_loss: 0.6035 - val_mae: 0.7733\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6022 - mae: 0.7618 - val_loss: 0.6030 - val_mae: 0.7730\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6017 - mae: 0.7615 - val_loss: 0.6026 - val_mae: 0.7727\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6012 - mae: 0.7612 - val_loss: 0.6021 - val_mae: 0.7725\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6008 - mae: 0.7609 - val_loss: 0.6017 - val_mae: 0.7722\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6004 - mae: 0.7606 - val_loss: 0.6013 - val_mae: 0.7719\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5999 - mae: 0.7603 - val_loss: 0.6009 - val_mae: 0.7717\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5996 - mae: 0.7601 - val_loss: 0.6005 - val_mae: 0.7714\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5992 - mae: 0.7598 - val_loss: 0.6002 - val_mae: 0.7712\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5989 - mae: 0.7596 - val_loss: 0.5998 - val_mae: 0.7710\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5985 - mae: 0.7594 - val_loss: 0.5995 - val_mae: 0.7707\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5982 - mae: 0.7592 - val_loss: 0.5992 - val_mae: 0.7705\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5979 - mae: 0.7590 - val_loss: 0.5989 - val_mae: 0.7703\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5976 - mae: 0.7588 - val_loss: 0.5986 - val_mae: 0.7702\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5973 - mae: 0.7586 - val_loss: 0.5983 - val_mae: 0.7700\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5970 - mae: 0.7584 - val_loss: 0.5980 - val_mae: 0.7698\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5967 - mae: 0.7582 - val_loss: 0.5978 - val_mae: 0.7696\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5965 - mae: 0.7580 - val_loss: 0.5975 - val_mae: 0.7695\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5962 - mae: 0.7579 - val_loss: 0.5973 - val_mae: 0.7693\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5960 - mae: 0.7577 - val_loss: 0.5970 - val_mae: 0.7691\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5958 - mae: 0.7576 - val_loss: 0.5968 - val_mae: 0.7690\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5956 - mae: 0.7574 - val_loss: 0.5966 - val_mae: 0.7688\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5953 - mae: 0.7573 - val_loss: 0.5964 - val_mae: 0.7687\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5951 - mae: 0.7571 - val_loss: 0.5962 - val_mae: 0.7686\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5949 - mae: 0.7570 - val_loss: 0.5960 - val_mae: 0.7685\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5947 - mae: 0.7569 - val_loss: 0.5958 - val_mae: 0.7683\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5945 - mae: 0.7567 - val_loss: 0.5956 - val_mae: 0.7682\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5944 - mae: 0.7566 - val_loss: 0.5954 - val_mae: 0.7681\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5942 - mae: 0.7565 - val_loss: 0.5952 - val_mae: 0.7680\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5940 - mae: 0.7564 - val_loss: 0.5951 - val_mae: 0.7679\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5939 - mae: 0.7563 - val_loss: 0.5949 - val_mae: 0.7678\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5937 - mae: 0.7562 - val_loss: 0.5948 - val_mae: 0.7677\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5936 - mae: 0.7561 - val_loss: 0.5946 - val_mae: 0.7676\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5934 - mae: 0.7560 - val_loss: 0.5945 - val_mae: 0.7675\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5932 - mae: 0.7559 - val_loss: 0.5943 - val_mae: 0.7674\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5931 - mae: 0.7558 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5930 - mae: 0.7557 - val_loss: 0.5941 - val_mae: 0.7672\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5929 - mae: 0.7556 - val_loss: 0.5939 - val_mae: 0.7671\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5927 - mae: 0.7555 - val_loss: 0.5938 - val_mae: 0.7671\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5926 - mae: 0.7555 - val_loss: 0.5937 - val_mae: 0.7670\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5936 - val_mae: 0.7669\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5935 - val_mae: 0.7668\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5923 - mae: 0.7552 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5932 - val_mae: 0.7667\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5921 - mae: 0.7551 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5920 - mae: 0.7550 - val_loss: 0.5930 - val_mae: 0.7666\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5930 - val_mae: 0.7665\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5918 - mae: 0.7549 - val_loss: 0.5929 - val_mae: 0.7664\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5917 - mae: 0.7548 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5926 - val_mae: 0.7663\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5914 - mae: 0.7547 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5912 - mae: 0.7546 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5923 - val_mae: 0.7660\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5911 - mae: 0.7545 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5909 - mae: 0.7544 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5909 - mae: 0.7543 - val_loss: 0.5920 - val_mae: 0.7658\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7658\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5905 - mae: 0.7540 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7656\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5903 - mae: 0.7540 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7653\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5899 - mae: 0.7536 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7651\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5896 - mae: 0.7534 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7649\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5893 - mae: 0.7532 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7647\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7645\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5887 - mae: 0.7528 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5878 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7637\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "6/6 [==============================] - 0s 4ms/step\n",
            "MSE: 0.1511342683759418\n",
            "MAE: 0.3760553735637878\n",
            "R^2: -14.55419478142025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 3 (Inputs are Discharging Capacity, CCCT, and CCV)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt4eZllKsU-8",
        "outputId": "07d21e47-1061-40fe-9c43-6d7def6a2b1b"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 84ms/step - loss: 1.6064 - mae: 1.2413 - val_loss: 0.9530 - val_mae: 0.9713\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9025 - mae: 0.9319 - val_loss: 0.7652 - val_mae: 0.8712\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7719 - mae: 0.8640 - val_loss: 0.7220 - val_mae: 0.8464\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7249 - mae: 0.8381 - val_loss: 0.7084 - val_mae: 0.8384\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.7147 - mae: 0.8317 - val_loss: 0.7051 - val_mae: 0.8365\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.7065 - mae: 0.8273 - val_loss: 0.7032 - val_mae: 0.8353\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7038 - mae: 0.8256 - val_loss: 0.6991 - val_mae: 0.8329\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6967 - mae: 0.8216 - val_loss: 0.6942 - val_mae: 0.8299\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6927 - mae: 0.8191 - val_loss: 0.6895 - val_mae: 0.8271\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6894 - mae: 0.8169 - val_loss: 0.6856 - val_mae: 0.8247\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6847 - mae: 0.8142 - val_loss: 0.6822 - val_mae: 0.8226\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6805 - mae: 0.8115 - val_loss: 0.6789 - val_mae: 0.8207\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6794 - mae: 0.8107 - val_loss: 0.6759 - val_mae: 0.8188\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6763 - mae: 0.8087 - val_loss: 0.6729 - val_mae: 0.8170\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6713 - mae: 0.8059 - val_loss: 0.6702 - val_mae: 0.8153\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6687 - mae: 0.8042 - val_loss: 0.6675 - val_mae: 0.8137\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6653 - mae: 0.8021 - val_loss: 0.6648 - val_mae: 0.8120\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6634 - mae: 0.8009 - val_loss: 0.6622 - val_mae: 0.8104\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6603 - mae: 0.7990 - val_loss: 0.6597 - val_mae: 0.8088\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6575 - mae: 0.7972 - val_loss: 0.6573 - val_mae: 0.8074\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6559 - mae: 0.7961 - val_loss: 0.6550 - val_mae: 0.8059\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6528 - mae: 0.7943 - val_loss: 0.6528 - val_mae: 0.8046\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6506 - mae: 0.7929 - val_loss: 0.6507 - val_mae: 0.8033\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6487 - mae: 0.7917 - val_loss: 0.6487 - val_mae: 0.8020\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6466 - mae: 0.7904 - val_loss: 0.6467 - val_mae: 0.8008\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6446 - mae: 0.7891 - val_loss: 0.6448 - val_mae: 0.7996\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6426 - mae: 0.7878 - val_loss: 0.6429 - val_mae: 0.7984\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6410 - mae: 0.7868 - val_loss: 0.6411 - val_mae: 0.7973\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6390 - mae: 0.7856 - val_loss: 0.6394 - val_mae: 0.7962\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6376 - mae: 0.7846 - val_loss: 0.6378 - val_mae: 0.7952\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6359 - mae: 0.7836 - val_loss: 0.6362 - val_mae: 0.7942\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6343 - mae: 0.7826 - val_loss: 0.6347 - val_mae: 0.7933\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6328 - mae: 0.7816 - val_loss: 0.6332 - val_mae: 0.7923\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6313 - mae: 0.7807 - val_loss: 0.6318 - val_mae: 0.7914\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6299 - mae: 0.7798 - val_loss: 0.6304 - val_mae: 0.7906\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6285 - mae: 0.7788 - val_loss: 0.6291 - val_mae: 0.7897\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6273 - mae: 0.7781 - val_loss: 0.6279 - val_mae: 0.7889\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6260 - mae: 0.7772 - val_loss: 0.6266 - val_mae: 0.7882\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6248 - mae: 0.7765 - val_loss: 0.6255 - val_mae: 0.7874\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6237 - mae: 0.7758 - val_loss: 0.6243 - val_mae: 0.7867\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6225 - mae: 0.7750 - val_loss: 0.6233 - val_mae: 0.7860\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6215 - mae: 0.7743 - val_loss: 0.6222 - val_mae: 0.7854\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6205 - mae: 0.7737 - val_loss: 0.6212 - val_mae: 0.7847\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6194 - mae: 0.7730 - val_loss: 0.6202 - val_mae: 0.7841\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6186 - mae: 0.7725 - val_loss: 0.6193 - val_mae: 0.7835\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6176 - mae: 0.7718 - val_loss: 0.6184 - val_mae: 0.7829\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6168 - mae: 0.7713 - val_loss: 0.6176 - val_mae: 0.7824\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6159 - mae: 0.7707 - val_loss: 0.6167 - val_mae: 0.7819\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6151 - mae: 0.7702 - val_loss: 0.6159 - val_mae: 0.7813\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6143 - mae: 0.7697 - val_loss: 0.6152 - val_mae: 0.7809\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6136 - mae: 0.7692 - val_loss: 0.6144 - val_mae: 0.7804\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6128 - mae: 0.7687 - val_loss: 0.6137 - val_mae: 0.7799\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6121 - mae: 0.7683 - val_loss: 0.6130 - val_mae: 0.7795\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6114 - mae: 0.7678 - val_loss: 0.6123 - val_mae: 0.7790\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6108 - mae: 0.7674 - val_loss: 0.6117 - val_mae: 0.7786\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6101 - mae: 0.7670 - val_loss: 0.6111 - val_mae: 0.7782\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6095 - mae: 0.7666 - val_loss: 0.6105 - val_mae: 0.7778\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6089 - mae: 0.7662 - val_loss: 0.6099 - val_mae: 0.7775\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6084 - mae: 0.7658 - val_loss: 0.6093 - val_mae: 0.7771\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6078 - mae: 0.7655 - val_loss: 0.6088 - val_mae: 0.7768\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.6073 - mae: 0.7651 - val_loss: 0.6083 - val_mae: 0.7764\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6068 - mae: 0.7648 - val_loss: 0.6077 - val_mae: 0.7761\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6063 - mae: 0.7644 - val_loss: 0.6072 - val_mae: 0.7758\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6058 - mae: 0.7641 - val_loss: 0.6067 - val_mae: 0.7754\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6053 - mae: 0.7638 - val_loss: 0.6063 - val_mae: 0.7751\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6048 - mae: 0.7635 - val_loss: 0.6058 - val_mae: 0.7748\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6044 - mae: 0.7632 - val_loss: 0.6054 - val_mae: 0.7746\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.6040 - mae: 0.7629 - val_loss: 0.6050 - val_mae: 0.7743\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6036 - mae: 0.7627 - val_loss: 0.6046 - val_mae: 0.7740\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6031 - mae: 0.7624 - val_loss: 0.6042 - val_mae: 0.7738\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6028 - mae: 0.7622 - val_loss: 0.6038 - val_mae: 0.7735\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6024 - mae: 0.7619 - val_loss: 0.6034 - val_mae: 0.7733\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6020 - mae: 0.7617 - val_loss: 0.6030 - val_mae: 0.7730\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6017 - mae: 0.7614 - val_loss: 0.6027 - val_mae: 0.7728\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6013 - mae: 0.7612 - val_loss: 0.6024 - val_mae: 0.7726\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6010 - mae: 0.7610 - val_loss: 0.6020 - val_mae: 0.7724\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6006 - mae: 0.7608 - val_loss: 0.6017 - val_mae: 0.7722\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6003 - mae: 0.7606 - val_loss: 0.6014 - val_mae: 0.7720\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6000 - mae: 0.7604 - val_loss: 0.6011 - val_mae: 0.7718\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5997 - mae: 0.7602 - val_loss: 0.6008 - val_mae: 0.7716\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5995 - mae: 0.7600 - val_loss: 0.6005 - val_mae: 0.7714\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5991 - mae: 0.7598 - val_loss: 0.6002 - val_mae: 0.7712\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5989 - mae: 0.7596 - val_loss: 0.5999 - val_mae: 0.7710\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5986 - mae: 0.7594 - val_loss: 0.5997 - val_mae: 0.7709\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5983 - mae: 0.7592 - val_loss: 0.5994 - val_mae: 0.7707\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5981 - mae: 0.7591 - val_loss: 0.5992 - val_mae: 0.7705\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5979 - mae: 0.7589 - val_loss: 0.5989 - val_mae: 0.7704\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5976 - mae: 0.7588 - val_loss: 0.5987 - val_mae: 0.7702\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5974 - mae: 0.7586 - val_loss: 0.5985 - val_mae: 0.7701\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5973 - mae: 0.7585 - val_loss: 0.5982 - val_mae: 0.7699\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5969 - mae: 0.7583 - val_loss: 0.5980 - val_mae: 0.7698\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5967 - mae: 0.7582 - val_loss: 0.5978 - val_mae: 0.7697\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5965 - mae: 0.7581 - val_loss: 0.5976 - val_mae: 0.7695\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5963 - mae: 0.7579 - val_loss: 0.5974 - val_mae: 0.7694\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5961 - mae: 0.7578 - val_loss: 0.5972 - val_mae: 0.7693\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5959 - mae: 0.7577 - val_loss: 0.5970 - val_mae: 0.7691\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5958 - mae: 0.7576 - val_loss: 0.5968 - val_mae: 0.7690\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5956 - mae: 0.7574 - val_loss: 0.5967 - val_mae: 0.7689\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5954 - mae: 0.7573 - val_loss: 0.5965 - val_mae: 0.7688\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5952 - mae: 0.7572 - val_loss: 0.5963 - val_mae: 0.7687\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5950 - mae: 0.7571 - val_loss: 0.5961 - val_mae: 0.7686\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5949 - mae: 0.7570 - val_loss: 0.5960 - val_mae: 0.7685\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5947 - mae: 0.7569 - val_loss: 0.5958 - val_mae: 0.7684\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5946 - mae: 0.7568 - val_loss: 0.5957 - val_mae: 0.7683\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5944 - mae: 0.7567 - val_loss: 0.5955 - val_mae: 0.7682\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5943 - mae: 0.7566 - val_loss: 0.5954 - val_mae: 0.7681\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5941 - mae: 0.7565 - val_loss: 0.5952 - val_mae: 0.7680\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5940 - mae: 0.7564 - val_loss: 0.5951 - val_mae: 0.7679\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5938 - mae: 0.7563 - val_loss: 0.5950 - val_mae: 0.7678\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5937 - mae: 0.7562 - val_loss: 0.5948 - val_mae: 0.7677\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5936 - mae: 0.7561 - val_loss: 0.5947 - val_mae: 0.7676\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5935 - mae: 0.7560 - val_loss: 0.5946 - val_mae: 0.7675\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5933 - mae: 0.7560 - val_loss: 0.5944 - val_mae: 0.7675\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5932 - mae: 0.7559 - val_loss: 0.5943 - val_mae: 0.7674\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5931 - mae: 0.7558 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5930 - mae: 0.7557 - val_loss: 0.5941 - val_mae: 0.7672\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5929 - mae: 0.7556 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5928 - mae: 0.7556 - val_loss: 0.5939 - val_mae: 0.7671\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5927 - mae: 0.7555 - val_loss: 0.5938 - val_mae: 0.7670\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5926 - mae: 0.7554 - val_loss: 0.5937 - val_mae: 0.7670\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5936 - val_mae: 0.7669\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5935 - val_mae: 0.7668\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5923 - mae: 0.7552 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5933 - val_mae: 0.7667\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5921 - mae: 0.7551 - val_loss: 0.5932 - val_mae: 0.7666\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5920 - mae: 0.7550 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5930 - val_mae: 0.7665\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5918 - mae: 0.7549 - val_loss: 0.5929 - val_mae: 0.7665\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5917 - mae: 0.7549 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5915 - mae: 0.7548 - val_loss: 0.5926 - val_mae: 0.7663\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5926 - val_mae: 0.7662\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5914 - mae: 0.7547 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5912 - mae: 0.7546 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5911 - mae: 0.7545 - val_loss: 0.5923 - val_mae: 0.7660\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5911 - mae: 0.7545 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5909 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5909 - mae: 0.7543 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7658\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7656\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7656\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7655\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5900 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7653\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7651\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7651\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7647\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7645\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5878 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7637\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5924 - mae: 0.7545 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "6/6 [==============================] - 0s 5ms/step\n",
            "MSE: 0.15112803717272966\n",
            "MAE: 0.37604708851816404\n",
            "R^2: -14.553553488419494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 4 (Inputs are Discharging Capacity, CCCT, CCV, and CVCC)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccvB0005, X_train_ccvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccctB0005, X_train_ccctB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_cvccB0005, X_train_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccvB0005, X_test_ccvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccctB0005, X_test_ccctB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_cvccB0005, X_test_cvccB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1zuaGBkt0kW",
        "outputId": "59bca26a-5ea7-4cc3-cdcf-667105249d52"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 89ms/step - loss: 0.7413 - mae: 0.8459 - val_loss: 0.6043 - val_mae: 0.7739\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6020 - mae: 0.7617 - val_loss: 0.6000 - val_mae: 0.7710\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5998 - mae: 0.7602 - val_loss: 0.5996 - val_mae: 0.7708\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5993 - mae: 0.7599 - val_loss: 0.5994 - val_mae: 0.7707\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5989 - mae: 0.7596 - val_loss: 0.5989 - val_mae: 0.7704\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5983 - mae: 0.7592 - val_loss: 0.5986 - val_mae: 0.7701\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5979 - mae: 0.7589 - val_loss: 0.5982 - val_mae: 0.7699\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5974 - mae: 0.7586 - val_loss: 0.5980 - val_mae: 0.7698\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5971 - mae: 0.7585 - val_loss: 0.5977 - val_mae: 0.7696\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5969 - mae: 0.7583 - val_loss: 0.5974 - val_mae: 0.7694\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5965 - mae: 0.7581 - val_loss: 0.5971 - val_mae: 0.7692\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5963 - mae: 0.7579 - val_loss: 0.5969 - val_mae: 0.7691\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5959 - mae: 0.7577 - val_loss: 0.5966 - val_mae: 0.7689\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5957 - mae: 0.7575 - val_loss: 0.5964 - val_mae: 0.7687\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5955 - mae: 0.7574 - val_loss: 0.5962 - val_mae: 0.7686\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5952 - mae: 0.7572 - val_loss: 0.5960 - val_mae: 0.7684\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5950 - mae: 0.7570 - val_loss: 0.5957 - val_mae: 0.7683\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5947 - mae: 0.7569 - val_loss: 0.5955 - val_mae: 0.7682\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5944 - mae: 0.7567 - val_loss: 0.5953 - val_mae: 0.7680\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5942 - mae: 0.7566 - val_loss: 0.5951 - val_mae: 0.7679\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5940 - mae: 0.7564 - val_loss: 0.5949 - val_mae: 0.7678\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5938 - mae: 0.7563 - val_loss: 0.5947 - val_mae: 0.7676\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5936 - mae: 0.7561 - val_loss: 0.5945 - val_mae: 0.7675\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5934 - mae: 0.7560 - val_loss: 0.5943 - val_mae: 0.7674\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5932 - mae: 0.7559 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5930 - mae: 0.7558 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5929 - mae: 0.7556 - val_loss: 0.5938 - val_mae: 0.7671\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5927 - mae: 0.7555 - val_loss: 0.5937 - val_mae: 0.7670\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5935 - val_mae: 0.7669\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5932 - val_mae: 0.7667\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5921 - mae: 0.7551 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5929 - val_mae: 0.7665\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5918 - mae: 0.7549 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5914 - mae: 0.7547 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5909 - mae: 0.7544 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7655\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5903 - mae: 0.7540 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5902 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5896 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7649\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5878 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "6/6 [==============================] - 0s 4ms/step\n",
            "MSE: 0.1511227026545947\n",
            "MAE: 0.37603999556543577\n",
            "R^2: -14.553004479018597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 5 (CCDT and CCDV)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUygnGv3u16B",
        "outputId": "e01eeff7-a41e-42a6-e81e-2bee73d6b085"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 90ms/step - loss: 1.2770 - mae: 1.1060 - val_loss: 0.7384 - val_mae: 0.8560\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7596 - mae: 0.8579 - val_loss: 0.7241 - val_mae: 0.8478\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.7302 - mae: 0.8414 - val_loss: 0.7194 - val_mae: 0.8450\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7202 - mae: 0.8357 - val_loss: 0.7142 - val_mae: 0.8419\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7150 - mae: 0.8324 - val_loss: 0.7083 - val_mae: 0.8384\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7070 - mae: 0.8278 - val_loss: 0.7026 - val_mae: 0.8350\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.7011 - mae: 0.8242 - val_loss: 0.6976 - val_mae: 0.8320\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6973 - mae: 0.8218 - val_loss: 0.6931 - val_mae: 0.8293\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6937 - mae: 0.8196 - val_loss: 0.6889 - val_mae: 0.8267\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6883 - mae: 0.8163 - val_loss: 0.6849 - val_mae: 0.8243\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6841 - mae: 0.8137 - val_loss: 0.6810 - val_mae: 0.8219\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6798 - mae: 0.8112 - val_loss: 0.6773 - val_mae: 0.8197\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6759 - mae: 0.8087 - val_loss: 0.6737 - val_mae: 0.8175\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6717 - mae: 0.8062 - val_loss: 0.6703 - val_mae: 0.8154\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6685 - mae: 0.8041 - val_loss: 0.6670 - val_mae: 0.8134\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6656 - mae: 0.8023 - val_loss: 0.6639 - val_mae: 0.8115\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6623 - mae: 0.8003 - val_loss: 0.6609 - val_mae: 0.8096\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6592 - mae: 0.7983 - val_loss: 0.6581 - val_mae: 0.8079\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6561 - mae: 0.7964 - val_loss: 0.6554 - val_mae: 0.8062\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6534 - mae: 0.7947 - val_loss: 0.6527 - val_mae: 0.8045\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6507 - mae: 0.7930 - val_loss: 0.6502 - val_mae: 0.8030\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6486 - mae: 0.7917 - val_loss: 0.6478 - val_mae: 0.8015\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6457 - mae: 0.7898 - val_loss: 0.6455 - val_mae: 0.8001\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6435 - mae: 0.7884 - val_loss: 0.6434 - val_mae: 0.7987\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6414 - mae: 0.7871 - val_loss: 0.6414 - val_mae: 0.7975\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6394 - mae: 0.7859 - val_loss: 0.6395 - val_mae: 0.7963\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6376 - mae: 0.7847 - val_loss: 0.6377 - val_mae: 0.7951\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6357 - mae: 0.7835 - val_loss: 0.6359 - val_mae: 0.7940\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6340 - mae: 0.7824 - val_loss: 0.6343 - val_mae: 0.7930\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6324 - mae: 0.7813 - val_loss: 0.6327 - val_mae: 0.7920\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6308 - mae: 0.7803 - val_loss: 0.6311 - val_mae: 0.7910\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6293 - mae: 0.7794 - val_loss: 0.6297 - val_mae: 0.7901\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6279 - mae: 0.7785 - val_loss: 0.6283 - val_mae: 0.7892\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6265 - mae: 0.7775 - val_loss: 0.6269 - val_mae: 0.7883\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6252 - mae: 0.7768 - val_loss: 0.6257 - val_mae: 0.7875\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6239 - mae: 0.7759 - val_loss: 0.6244 - val_mae: 0.7868\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6227 - mae: 0.7752 - val_loss: 0.6233 - val_mae: 0.7860\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6216 - mae: 0.7744 - val_loss: 0.6221 - val_mae: 0.7853\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6204 - mae: 0.7737 - val_loss: 0.6210 - val_mae: 0.7846\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6194 - mae: 0.7730 - val_loss: 0.6200 - val_mae: 0.7839\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6183 - mae: 0.7723 - val_loss: 0.6190 - val_mae: 0.7833\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6174 - mae: 0.7717 - val_loss: 0.6180 - val_mae: 0.7827\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6164 - mae: 0.7710 - val_loss: 0.6171 - val_mae: 0.7821\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6155 - mae: 0.7705 - val_loss: 0.6163 - val_mae: 0.7816\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6146 - mae: 0.7699 - val_loss: 0.6154 - val_mae: 0.7810\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6138 - mae: 0.7694 - val_loss: 0.6146 - val_mae: 0.7805\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6131 - mae: 0.7689 - val_loss: 0.6139 - val_mae: 0.7800\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6124 - mae: 0.7684 - val_loss: 0.6131 - val_mae: 0.7795\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6116 - mae: 0.7679 - val_loss: 0.6124 - val_mae: 0.7791\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6109 - mae: 0.7675 - val_loss: 0.6117 - val_mae: 0.7786\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6102 - mae: 0.7670 - val_loss: 0.6111 - val_mae: 0.7782\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6096 - mae: 0.7666 - val_loss: 0.6104 - val_mae: 0.7778\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6090 - mae: 0.7662 - val_loss: 0.6098 - val_mae: 0.7774\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6083 - mae: 0.7658 - val_loss: 0.6092 - val_mae: 0.7770\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6077 - mae: 0.7654 - val_loss: 0.6087 - val_mae: 0.7767\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6072 - mae: 0.7651 - val_loss: 0.6081 - val_mae: 0.7763\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6067 - mae: 0.7647 - val_loss: 0.6076 - val_mae: 0.7760\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6061 - mae: 0.7644 - val_loss: 0.6071 - val_mae: 0.7757\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6057 - mae: 0.7641 - val_loss: 0.6066 - val_mae: 0.7754\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6052 - mae: 0.7637 - val_loss: 0.6061 - val_mae: 0.7751\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6047 - mae: 0.7634 - val_loss: 0.6057 - val_mae: 0.7748\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6043 - mae: 0.7631 - val_loss: 0.6053 - val_mae: 0.7745\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6038 - mae: 0.7629 - val_loss: 0.6049 - val_mae: 0.7742\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6034 - mae: 0.7626 - val_loss: 0.6045 - val_mae: 0.7740\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6031 - mae: 0.7624 - val_loss: 0.6041 - val_mae: 0.7737\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6027 - mae: 0.7621 - val_loss: 0.6037 - val_mae: 0.7735\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6023 - mae: 0.7619 - val_loss: 0.6033 - val_mae: 0.7732\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6020 - mae: 0.7616 - val_loss: 0.6030 - val_mae: 0.7730\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6016 - mae: 0.7614 - val_loss: 0.6026 - val_mae: 0.7728\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6013 - mae: 0.7612 - val_loss: 0.6023 - val_mae: 0.7726\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6009 - mae: 0.7610 - val_loss: 0.6020 - val_mae: 0.7724\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6006 - mae: 0.7608 - val_loss: 0.6017 - val_mae: 0.7722\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6003 - mae: 0.7606 - val_loss: 0.6014 - val_mae: 0.7720\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6000 - mae: 0.7604 - val_loss: 0.6011 - val_mae: 0.7718\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5997 - mae: 0.7602 - val_loss: 0.6008 - val_mae: 0.7716\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5995 - mae: 0.7600 - val_loss: 0.6006 - val_mae: 0.7714\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5992 - mae: 0.7598 - val_loss: 0.6003 - val_mae: 0.7713\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5989 - mae: 0.7597 - val_loss: 0.6000 - val_mae: 0.7711\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5987 - mae: 0.7595 - val_loss: 0.5998 - val_mae: 0.7709\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5984 - mae: 0.7593 - val_loss: 0.5995 - val_mae: 0.7708\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5982 - mae: 0.7592 - val_loss: 0.5993 - val_mae: 0.7706\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5980 - mae: 0.7590 - val_loss: 0.5991 - val_mae: 0.7705\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5978 - mae: 0.7589 - val_loss: 0.5988 - val_mae: 0.7703\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5975 - mae: 0.7587 - val_loss: 0.5986 - val_mae: 0.7702\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5973 - mae: 0.7586 - val_loss: 0.5984 - val_mae: 0.7701\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5972 - mae: 0.7585 - val_loss: 0.5982 - val_mae: 0.7699\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5969 - mae: 0.7583 - val_loss: 0.5980 - val_mae: 0.7698\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5967 - mae: 0.7582 - val_loss: 0.5978 - val_mae: 0.7697\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5965 - mae: 0.7581 - val_loss: 0.5976 - val_mae: 0.7695\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5964 - mae: 0.7579 - val_loss: 0.5975 - val_mae: 0.7694\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.5962 - mae: 0.7578 - val_loss: 0.5973 - val_mae: 0.7693\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5960 - mae: 0.7577 - val_loss: 0.5971 - val_mae: 0.7692\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5958 - mae: 0.7576 - val_loss: 0.5969 - val_mae: 0.7691\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.5957 - mae: 0.7575 - val_loss: 0.5968 - val_mae: 0.7690\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5955 - mae: 0.7574 - val_loss: 0.5966 - val_mae: 0.7689\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5954 - mae: 0.7573 - val_loss: 0.5965 - val_mae: 0.7688\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5952 - mae: 0.7572 - val_loss: 0.5963 - val_mae: 0.7687\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5951 - mae: 0.7571 - val_loss: 0.5962 - val_mae: 0.7686\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5949 - mae: 0.7570 - val_loss: 0.5960 - val_mae: 0.7685\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5948 - mae: 0.7569 - val_loss: 0.5959 - val_mae: 0.7684\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5946 - mae: 0.7568 - val_loss: 0.5957 - val_mae: 0.7683\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5945 - mae: 0.7567 - val_loss: 0.5956 - val_mae: 0.7682\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5944 - mae: 0.7566 - val_loss: 0.5955 - val_mae: 0.7681\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5942 - mae: 0.7565 - val_loss: 0.5954 - val_mae: 0.7681\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5941 - mae: 0.7565 - val_loss: 0.5952 - val_mae: 0.7680\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5940 - mae: 0.7564 - val_loss: 0.5951 - val_mae: 0.7679\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5939 - mae: 0.7563 - val_loss: 0.5950 - val_mae: 0.7678\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5938 - mae: 0.7562 - val_loss: 0.5949 - val_mae: 0.7678\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5937 - mae: 0.7562 - val_loss: 0.5948 - val_mae: 0.7677\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5935 - mae: 0.7561 - val_loss: 0.5947 - val_mae: 0.7676\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5934 - mae: 0.7560 - val_loss: 0.5945 - val_mae: 0.7675\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5933 - mae: 0.7559 - val_loss: 0.5944 - val_mae: 0.7675\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5932 - mae: 0.7559 - val_loss: 0.5943 - val_mae: 0.7674\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5931 - mae: 0.7558 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5930 - mae: 0.7557 - val_loss: 0.5941 - val_mae: 0.7673\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5929 - mae: 0.7557 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5928 - mae: 0.7556 - val_loss: 0.5939 - val_mae: 0.7671\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5927 - mae: 0.7556 - val_loss: 0.5939 - val_mae: 0.7671\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5926 - mae: 0.7555 - val_loss: 0.5938 - val_mae: 0.7670\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5937 - val_mae: 0.7670\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5928 - mae: 0.7557 - val_loss: 0.5936 - val_mae: 0.7669\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5935 - val_mae: 0.7668\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5923 - mae: 0.7553 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5933 - val_mae: 0.7667\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5921 - mae: 0.7551 - val_loss: 0.5932 - val_mae: 0.7667\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5920 - mae: 0.7551 - val_loss: 0.5932 - val_mae: 0.7666\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5920 - mae: 0.7550 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5930 - val_mae: 0.7665\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5918 - mae: 0.7549 - val_loss: 0.5929 - val_mae: 0.7665\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5917 - mae: 0.7549 - val_loss: 0.5929 - val_mae: 0.7664\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5917 - mae: 0.7549 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5915 - mae: 0.7548 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5926 - val_mae: 0.7663\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5914 - mae: 0.7547 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5911 - mae: 0.7545 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5909 - mae: 0.7544 - val_loss: 0.5921 - val_mae: 0.7659\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5909 - mae: 0.7543 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7658\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7655\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5903 - mae: 0.7540 - val_loss: 0.5915 - val_mae: 0.7655\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5900 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7653\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7651\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7651\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5896 - mae: 0.7534 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7649\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7647\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5890 - mae: 0.7530 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7645\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5878 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7637\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "6/6 [==============================] - 0s 4ms/step\n",
            "MSE: 0.15114341369975\n",
            "MAE: 0.376067532911322\n",
            "R^2: -14.55513598522122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 6 (Input are CCDV and RoV)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPmukUZPvc3T",
        "outputId": "1ef00e45-7a34-4d61-9c2c-b83970ba2e3f"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 98ms/step - loss: 0.7831 - mae: 0.8705 - val_loss: 0.6268 - val_mae: 0.7884\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6242 - mae: 0.7766 - val_loss: 0.6156 - val_mae: 0.7811\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6171 - mae: 0.7717 - val_loss: 0.6127 - val_mae: 0.7793\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6143 - mae: 0.7697 - val_loss: 0.6111 - val_mae: 0.7782\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6116 - mae: 0.7679 - val_loss: 0.6098 - val_mae: 0.7774\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6100 - mae: 0.7669 - val_loss: 0.6088 - val_mae: 0.7767\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6089 - mae: 0.7662 - val_loss: 0.6078 - val_mae: 0.7761\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6079 - mae: 0.7655 - val_loss: 0.6068 - val_mae: 0.7755\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6066 - mae: 0.7647 - val_loss: 0.6060 - val_mae: 0.7749\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6057 - mae: 0.7641 - val_loss: 0.6052 - val_mae: 0.7744\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6051 - mae: 0.7637 - val_loss: 0.6044 - val_mae: 0.7739\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6040 - mae: 0.7630 - val_loss: 0.6036 - val_mae: 0.7734\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6032 - mae: 0.7625 - val_loss: 0.6029 - val_mae: 0.7730\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6022 - mae: 0.7618 - val_loss: 0.6022 - val_mae: 0.7725\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6016 - mae: 0.7614 - val_loss: 0.6016 - val_mae: 0.7721\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6011 - mae: 0.7611 - val_loss: 0.6010 - val_mae: 0.7717\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6004 - mae: 0.7606 - val_loss: 0.6005 - val_mae: 0.7714\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5996 - mae: 0.7601 - val_loss: 0.5999 - val_mae: 0.7710\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5993 - mae: 0.7599 - val_loss: 0.5994 - val_mae: 0.7707\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5986 - mae: 0.7594 - val_loss: 0.5990 - val_mae: 0.7704\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5982 - mae: 0.7591 - val_loss: 0.5985 - val_mae: 0.7701\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5976 - mae: 0.7588 - val_loss: 0.5981 - val_mae: 0.7698\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5972 - mae: 0.7585 - val_loss: 0.5977 - val_mae: 0.7696\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5968 - mae: 0.7582 - val_loss: 0.5973 - val_mae: 0.7693\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5964 - mae: 0.7580 - val_loss: 0.5969 - val_mae: 0.7691\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5960 - mae: 0.7577 - val_loss: 0.5966 - val_mae: 0.7689\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5956 - mae: 0.7575 - val_loss: 0.5963 - val_mae: 0.7687\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5953 - mae: 0.7573 - val_loss: 0.5960 - val_mae: 0.7685\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5950 - mae: 0.7571 - val_loss: 0.5957 - val_mae: 0.7683\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5946 - mae: 0.7568 - val_loss: 0.5954 - val_mae: 0.7681\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5946 - mae: 0.7568 - val_loss: 0.5952 - val_mae: 0.7679\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5941 - mae: 0.7565 - val_loss: 0.5949 - val_mae: 0.7678\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5939 - mae: 0.7563 - val_loss: 0.5947 - val_mae: 0.7676\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5937 - mae: 0.7562 - val_loss: 0.5944 - val_mae: 0.7675\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5934 - mae: 0.7560 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5932 - mae: 0.7558 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5930 - mae: 0.7557 - val_loss: 0.5938 - val_mae: 0.7670\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5928 - mae: 0.7556 - val_loss: 0.5936 - val_mae: 0.7669\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5933 - val_mae: 0.7667\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5920 - mae: 0.7551 - val_loss: 0.5929 - val_mae: 0.7665\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5917 - mae: 0.7549 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5923 - val_mae: 0.7660\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5921 - val_mae: 0.7660\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5911 - mae: 0.7544 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5915 - val_mae: 0.7655\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5904 - val_mae: 0.7649\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "6/6 [==============================] - 0s 5ms/step\n",
            "MSE: 0.1511240474816136\n",
            "MAE: 0.37604178370477903\n",
            "R^2: -14.553142883773678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 7 (Discharging Capacity, CCDT, and CCDV)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Multi-head self-attention and normalization\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "\n",
        "    # Feed-forward network and normalization\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape[1]))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)  # Apply Dense to each timestep\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1])\n",
        "\n",
        "# If model outputs at each timestep and you need targets for each timestep:\n",
        "y_train = np.repeat(y_train[:, np.newaxis], X_train.shape[1], axis=1)\n",
        "y_test = np.repeat(y_test[:, np.newaxis], X_test.shape[1], axis=1)\n",
        "\n",
        "# Train the model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model = build_model((X_train.shape[1], X_train.shape[2]), head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELCuYrIAxOfu",
        "outputId": "ba59308d-e143-4af0-ef92-53f02696a702"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 3s 129ms/step - loss: 0.9356 - mae: 0.9445 - val_loss: 0.6145 - val_mae: 0.7804\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6194 - mae: 0.7735 - val_loss: 0.6124 - val_mae: 0.7791\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6133 - mae: 0.7690 - val_loss: 0.6115 - val_mae: 0.7785\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6117 - mae: 0.7681 - val_loss: 0.6104 - val_mae: 0.7778\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6100 - mae: 0.7669 - val_loss: 0.6093 - val_mae: 0.7771\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6091 - mae: 0.7665 - val_loss: 0.6082 - val_mae: 0.7764\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6076 - mae: 0.7653 - val_loss: 0.6072 - val_mae: 0.7757\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6069 - mae: 0.7649 - val_loss: 0.6064 - val_mae: 0.7752\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.6059 - mae: 0.7642 - val_loss: 0.6056 - val_mae: 0.7747\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6054 - mae: 0.7640 - val_loss: 0.6050 - val_mae: 0.7743\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6047 - mae: 0.7635 - val_loss: 0.6044 - val_mae: 0.7739\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.6039 - mae: 0.7629 - val_loss: 0.6038 - val_mae: 0.7735\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6031 - mae: 0.7624 - val_loss: 0.6033 - val_mae: 0.7732\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6026 - mae: 0.7621 - val_loss: 0.6027 - val_mae: 0.7728\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6021 - mae: 0.7617 - val_loss: 0.6022 - val_mae: 0.7725\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6013 - mae: 0.7612 - val_loss: 0.6018 - val_mae: 0.7722\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6010 - mae: 0.7610 - val_loss: 0.6013 - val_mae: 0.7719\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6005 - mae: 0.7607 - val_loss: 0.6008 - val_mae: 0.7716\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5999 - mae: 0.7603 - val_loss: 0.6004 - val_mae: 0.7713\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5996 - mae: 0.7601 - val_loss: 0.6000 - val_mae: 0.7711\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5992 - mae: 0.7598 - val_loss: 0.5996 - val_mae: 0.7708\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5986 - mae: 0.7594 - val_loss: 0.5992 - val_mae: 0.7705\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5983 - mae: 0.7592 - val_loss: 0.5988 - val_mae: 0.7703\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5979 - mae: 0.7590 - val_loss: 0.5985 - val_mae: 0.7701\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5975 - mae: 0.7587 - val_loss: 0.5981 - val_mae: 0.7698\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5971 - mae: 0.7584 - val_loss: 0.5978 - val_mae: 0.7696\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5967 - mae: 0.7582 - val_loss: 0.5975 - val_mae: 0.7694\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5964 - mae: 0.7580 - val_loss: 0.5972 - val_mae: 0.7692\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5962 - mae: 0.7578 - val_loss: 0.5969 - val_mae: 0.7690\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5958 - mae: 0.7576 - val_loss: 0.5966 - val_mae: 0.7689\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5955 - mae: 0.7574 - val_loss: 0.5963 - val_mae: 0.7687\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5952 - mae: 0.7572 - val_loss: 0.5961 - val_mae: 0.7685\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5950 - mae: 0.7571 - val_loss: 0.5958 - val_mae: 0.7684\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5947 - mae: 0.7569 - val_loss: 0.5956 - val_mae: 0.7682\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5944 - mae: 0.7567 - val_loss: 0.5954 - val_mae: 0.7681\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5942 - mae: 0.7566 - val_loss: 0.5951 - val_mae: 0.7679\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5941 - mae: 0.7564 - val_loss: 0.5949 - val_mae: 0.7678\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5938 - mae: 0.7563 - val_loss: 0.5947 - val_mae: 0.7676\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5936 - mae: 0.7561 - val_loss: 0.5945 - val_mae: 0.7675\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5934 - mae: 0.7560 - val_loss: 0.5943 - val_mae: 0.7674\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5932 - mae: 0.7559 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5930 - mae: 0.7557 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5928 - mae: 0.7556 - val_loss: 0.5938 - val_mae: 0.7671\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5927 - mae: 0.7555 - val_loss: 0.5937 - val_mae: 0.7670\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5935 - val_mae: 0.7669\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5924 - mae: 0.7553 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5932 - val_mae: 0.7667\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5921 - mae: 0.7551 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5919 - mae: 0.7550 - val_loss: 0.5930 - val_mae: 0.7665\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5918 - mae: 0.7550 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5917 - mae: 0.7549 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5926 - val_mae: 0.7663\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5915 - mae: 0.7547 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5912 - mae: 0.7546 - val_loss: 0.5923 - val_mae: 0.7660\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5911 - mae: 0.7545 - val_loss: 0.5921 - val_mae: 0.7660\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5909 - mae: 0.7544 - val_loss: 0.5920 - val_mae: 0.7658\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5909 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5918 - val_mae: 0.7657\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5906 - mae: 0.7542 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5915 - val_mae: 0.7656\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5903 - mae: 0.7539 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7654\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7651\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7651\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5896 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7649\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5893 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5887 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5884 - mae: 0.7526 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5878 - mae: 0.7522 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7637\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "6/6 [==============================] - 1s 10ms/step\n",
            "MSE: 0.15112498886433176\n",
            "MAE: 0.3760430354023193\n",
            "R^2: -14.553239767493826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer Model with Case 8 (Discharging Capacity, CCDT, RoCV, and CCDV)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    ff = layers.Dropout(dropout)(ff)\n",
        "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
        "    ff = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "    return ff\n",
        "\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, dropout=0):\n",
        "    inputs = layers.Input(shape=(None, input_shape))\n",
        "    x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Combine training sets from B0005 and B0006\n",
        "X_train = np.concatenate([\n",
        "    np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_train = np.concatenate([y_train_B0005, y_train_B0006], axis=0)\n",
        "\n",
        "# Combine testing sets from B0005 and B0006\n",
        "X_test = np.concatenate([\n",
        "    np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006], axis=0),\n",
        "    np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006], axis=0),\n",
        "    np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006], axis=0)\n",
        "], axis=1)\n",
        "y_test = np.concatenate([y_test_B0005, y_test_B0006], axis=0)\n",
        "\n",
        "# Reshape data if necessary:\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])  # Add a sequence dimension\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "model = build_model(X_train.shape[2], head_size=128, num_heads=4, ff_dim=512, dropout=0.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# Prediction and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test.flatten(), y_pred.flatten())\n",
        "mae = mean_absolute_error(y_test.flatten(), y_pred.flatten())\n",
        "r2 = r2_score(y_test.flatten(), y_pred.flatten())\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdikv00oyIJQ",
        "outputId": "13d7f55f-2bc2-4d7d-a434-ca7df0d6adbc"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 6s 136ms/step - loss: 1.0948 - mae: 0.9786 - val_loss: 0.6157 - val_mae: 0.7811\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6248 - mae: 0.7757 - val_loss: 0.6138 - val_mae: 0.7800\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6136 - mae: 0.7692 - val_loss: 0.6135 - val_mae: 0.7798\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6136 - mae: 0.7691 - val_loss: 0.6120 - val_mae: 0.7788\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6110 - mae: 0.7675 - val_loss: 0.6100 - val_mae: 0.7775\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6094 - mae: 0.7664 - val_loss: 0.6082 - val_mae: 0.7764\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6079 - mae: 0.7654 - val_loss: 0.6068 - val_mae: 0.7755\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.6065 - mae: 0.7645 - val_loss: 0.6057 - val_mae: 0.7748\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6052 - mae: 0.7638 - val_loss: 0.6048 - val_mae: 0.7742\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.6043 - mae: 0.7632 - val_loss: 0.6040 - val_mae: 0.7737\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6037 - mae: 0.7627 - val_loss: 0.6032 - val_mae: 0.7732\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6030 - mae: 0.7622 - val_loss: 0.6026 - val_mae: 0.7727\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6021 - mae: 0.7617 - val_loss: 0.6019 - val_mae: 0.7723\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6014 - mae: 0.7612 - val_loss: 0.6013 - val_mae: 0.7719\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6005 - mae: 0.7607 - val_loss: 0.6008 - val_mae: 0.7716\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5999 - mae: 0.7603 - val_loss: 0.6002 - val_mae: 0.7712\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5993 - mae: 0.7599 - val_loss: 0.5997 - val_mae: 0.7709\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5989 - mae: 0.7596 - val_loss: 0.5993 - val_mae: 0.7706\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5984 - mae: 0.7593 - val_loss: 0.5988 - val_mae: 0.7703\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5979 - mae: 0.7589 - val_loss: 0.5984 - val_mae: 0.7700\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5974 - mae: 0.7586 - val_loss: 0.5980 - val_mae: 0.7698\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5970 - mae: 0.7584 - val_loss: 0.5976 - val_mae: 0.7695\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5966 - mae: 0.7581 - val_loss: 0.5972 - val_mae: 0.7693\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5962 - mae: 0.7578 - val_loss: 0.5968 - val_mae: 0.7690\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5958 - mae: 0.7576 - val_loss: 0.5965 - val_mae: 0.7688\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5954 - mae: 0.7573 - val_loss: 0.5962 - val_mae: 0.7686\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5952 - mae: 0.7572 - val_loss: 0.5959 - val_mae: 0.7684\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5949 - mae: 0.7569 - val_loss: 0.5956 - val_mae: 0.7682\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5946 - mae: 0.7567 - val_loss: 0.5954 - val_mae: 0.7681\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5944 - mae: 0.7566 - val_loss: 0.5951 - val_mae: 0.7679\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5941 - mae: 0.7564 - val_loss: 0.5949 - val_mae: 0.7677\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5938 - mae: 0.7562 - val_loss: 0.5946 - val_mae: 0.7676\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5935 - mae: 0.7561 - val_loss: 0.5944 - val_mae: 0.7674\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5933 - mae: 0.7559 - val_loss: 0.5942 - val_mae: 0.7673\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5931 - mae: 0.7558 - val_loss: 0.5940 - val_mae: 0.7672\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5929 - mae: 0.7556 - val_loss: 0.5938 - val_mae: 0.7670\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5927 - mae: 0.7555 - val_loss: 0.5936 - val_mae: 0.7669\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5925 - mae: 0.7554 - val_loss: 0.5934 - val_mae: 0.7668\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5923 - mae: 0.7553 - val_loss: 0.5933 - val_mae: 0.7667\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5922 - mae: 0.7552 - val_loss: 0.5931 - val_mae: 0.7666\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5920 - mae: 0.7551 - val_loss: 0.5930 - val_mae: 0.7665\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5918 - mae: 0.7550 - val_loss: 0.5928 - val_mae: 0.7664\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5917 - mae: 0.7549 - val_loss: 0.5927 - val_mae: 0.7663\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5916 - mae: 0.7548 - val_loss: 0.5925 - val_mae: 0.7662\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5914 - mae: 0.7547 - val_loss: 0.5924 - val_mae: 0.7661\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5913 - mae: 0.7546 - val_loss: 0.5923 - val_mae: 0.7661\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5912 - mae: 0.7545 - val_loss: 0.5922 - val_mae: 0.7660\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5910 - mae: 0.7544 - val_loss: 0.5920 - val_mae: 0.7659\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5909 - mae: 0.7543 - val_loss: 0.5919 - val_mae: 0.7658\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5908 - mae: 0.7543 - val_loss: 0.5918 - val_mae: 0.7658\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5907 - mae: 0.7542 - val_loss: 0.5917 - val_mae: 0.7657\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5906 - mae: 0.7541 - val_loss: 0.5916 - val_mae: 0.7656\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5905 - mae: 0.7541 - val_loss: 0.5915 - val_mae: 0.7656\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5904 - mae: 0.7540 - val_loss: 0.5914 - val_mae: 0.7655\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5903 - mae: 0.7540 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5902 - mae: 0.7539 - val_loss: 0.5913 - val_mae: 0.7654\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5912 - val_mae: 0.7653\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5901 - mae: 0.7538 - val_loss: 0.5911 - val_mae: 0.7653\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5900 - mae: 0.7537 - val_loss: 0.5910 - val_mae: 0.7652\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5899 - mae: 0.7537 - val_loss: 0.5909 - val_mae: 0.7652\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5898 - mae: 0.7536 - val_loss: 0.5909 - val_mae: 0.7651\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5897 - mae: 0.7536 - val_loss: 0.5908 - val_mae: 0.7651\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5897 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5896 - mae: 0.7535 - val_loss: 0.5907 - val_mae: 0.7650\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5906 - val_mae: 0.7650\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5895 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5894 - mae: 0.7534 - val_loss: 0.5905 - val_mae: 0.7649\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5894 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5893 - mae: 0.7533 - val_loss: 0.5904 - val_mae: 0.7648\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5893 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7648\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5892 - mae: 0.7532 - val_loss: 0.5903 - val_mae: 0.7647\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5891 - mae: 0.7532 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5891 - mae: 0.7531 - val_loss: 0.5902 - val_mae: 0.7647\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5890 - mae: 0.7531 - val_loss: 0.5901 - val_mae: 0.7646\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5890 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5900 - val_mae: 0.7646\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5889 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5888 - mae: 0.7530 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5899 - val_mae: 0.7645\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5888 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7645\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5887 - mae: 0.7529 - val_loss: 0.5898 - val_mae: 0.7644\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7644\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5886 - mae: 0.7528 - val_loss: 0.5897 - val_mae: 0.7643\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5885 - mae: 0.7528 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5885 - mae: 0.7527 - val_loss: 0.5896 - val_mae: 0.7643\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7643\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5884 - mae: 0.7527 - val_loss: 0.5895 - val_mae: 0.7642\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5884 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7642\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5883 - mae: 0.7526 - val_loss: 0.5894 - val_mae: 0.7641\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5882 - mae: 0.7526 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5882 - mae: 0.7525 - val_loss: 0.5893 - val_mae: 0.7641\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7641\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5881 - mae: 0.7525 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5881 - mae: 0.7524 - val_loss: 0.5892 - val_mae: 0.7640\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7640\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5880 - mae: 0.7524 - val_loss: 0.5891 - val_mae: 0.7639\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5879 - mae: 0.7524 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5879 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5890 - val_mae: 0.7639\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7639\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5878 - mae: 0.7523 - val_loss: 0.5889 - val_mae: 0.7638\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5877 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5888 - val_mae: 0.7638\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5876 - mae: 0.7522 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5876 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5887 - val_mae: 0.7637\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7637\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5875 - mae: 0.7521 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5875 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5886 - val_mae: 0.7636\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5874 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5885 - val_mae: 0.7636\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5873 - mae: 0.7520 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5873 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5884 - val_mae: 0.7635\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7635\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5872 - mae: 0.7519 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5872 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5883 - val_mae: 0.7634\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5871 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5882 - val_mae: 0.7634\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7634\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7518 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5870 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5881 - val_mae: 0.7633\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7633\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7517 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5869 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5880 - val_mae: 0.7632\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5868 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5881 - mae: 0.7523 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5879 - val_mae: 0.7632\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7632\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5867 - mae: 0.7516 - val_loss: 0.5878 - val_mae: 0.7631\n",
            "6/6 [==============================] - 0s 5ms/step\n",
            "MSE: 0.15112594835025606\n",
            "MAE: 0.3760443170785271\n",
            "R^2: -14.553338514330774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba Model with Case 1 (Inputs are CCCT and CCV)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "# Assuming bucketing into 1000 categories for each feature\n",
        "num_buckets = 1000\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccv_encoded_train = np.floor(np.concatenate([X_train_ccvB0005, X_train_ccvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccct_encoded_train = np.floor(np.concatenate([X_train_ccctB0005, X_train_ccctB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccv_encoded_test = np.floor(np.concatenate([X_test_ccvB0005, X_test_ccvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccct_encoded_test = np.floor(np.concatenate([X_test_ccctB0005, X_test_ccctB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([ccv_encoded_train, ccct_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([ccv_encoded_test, ccct_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "# Model adaptation\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        volt_embeddings = self.embedding(features[:, :features.shape[1]//2])\n",
        "        time_embeddings = self.embedding(features[:, features.shape[1]//2:])\n",
        "        combined_embeddings = (volt_embeddings + time_embeddings) / 2\n",
        "        outputs = self.mamba(inputs_embeds=combined_embeddings)\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Building and compiling the model\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Training function\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):  # number of epochs\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)  # Directly using test as validation for demonstration\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tyovx_OvhpA",
        "outputId": "4c0800ee-7e44-4ac9-fec3-3af944f585fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 3.47023868560791, Test Loss: 0.46546128392219543\n",
            "Epoch 1, Train Loss: 1.464688777923584, Test Loss: 0.22463059425354004\n",
            "Epoch 2, Train Loss: 0.16540637612342834, Test Loss: 0.16351191699504852\n",
            "Epoch 3, Train Loss: 0.7807360291481018, Test Loss: 0.12750554084777832\n",
            "Epoch 4, Train Loss: 0.31307122111320496, Test Loss: 0.1263696253299713\n",
            "Epoch 5, Train Loss: 0.0947418361902237, Test Loss: 0.1362079232931137\n",
            "Epoch 6, Train Loss: 0.24101115763187408, Test Loss: 0.11316194385290146\n",
            "Epoch 7, Train Loss: 0.19575975835323334, Test Loss: 0.11062703281641006\n",
            "Epoch 8, Train Loss: 0.0911204069852829, Test Loss: 0.155417799949646\n",
            "Epoch 9, Train Loss: 0.0999346524477005, Test Loss: 0.20099937915802002\n",
            "Epoch 10, Train Loss: 0.12404144555330276, Test Loss: 0.21187099814414978\n",
            "Epoch 11, Train Loss: 0.11124246567487717, Test Loss: 0.19787561893463135\n",
            "Epoch 12, Train Loss: 0.09610212594270706, Test Loss: 0.18037913739681244\n",
            "Epoch 13, Train Loss: 0.08479943126440048, Test Loss: 0.1697029024362564\n",
            "Epoch 14, Train Loss: 0.06511269509792328, Test Loss: 0.16784930229187012\n",
            "Epoch 15, Train Loss: 0.04824458062648773, Test Loss: 0.17359451949596405\n",
            "Epoch 16, Train Loss: 0.047610845416784286, Test Loss: 0.18336158990859985\n",
            "Epoch 17, Train Loss: 0.055382415652275085, Test Loss: 0.1926446110010147\n",
            "Epoch 18, Train Loss: 0.05597635731101036, Test Loss: 0.19859254360198975\n",
            "Epoch 19, Train Loss: 0.04722652584314346, Test Loss: 0.20112259685993195\n",
            "Epoch 20, Train Loss: 0.03846096247434616, Test Loss: 0.20208729803562164\n",
            "Epoch 21, Train Loss: 0.0355706512928009, Test Loss: 0.20369860529899597\n",
            "Epoch 22, Train Loss: 0.03571976348757744, Test Loss: 0.20726294815540314\n",
            "Epoch 23, Train Loss: 0.03468705341219902, Test Loss: 0.21274980902671814\n",
            "Epoch 24, Train Loss: 0.032776374369859695, Test Loss: 0.2190292328596115\n",
            "Epoch 25, Train Loss: 0.03216061368584633, Test Loss: 0.22448518872261047\n",
            "Epoch 26, Train Loss: 0.03246311843395233, Test Loss: 0.2278301864862442\n",
            "Epoch 27, Train Loss: 0.03132765740156174, Test Loss: 0.22877547144889832\n",
            "Epoch 28, Train Loss: 0.028062088415026665, Test Loss: 0.22820700705051422\n",
            "Epoch 29, Train Loss: 0.02483457140624523, Test Loss: 0.2278185486793518\n",
            "Epoch 30, Train Loss: 0.023995930328965187, Test Loss: 0.22937646508216858\n",
            "Epoch 31, Train Loss: 0.025162510573863983, Test Loss: 0.2338968962430954\n",
            "Epoch 32, Train Loss: 0.02589327283203602, Test Loss: 0.24110406637191772\n",
            "Epoch 33, Train Loss: 0.024906333535909653, Test Loss: 0.24945726990699768\n",
            "Epoch 34, Train Loss: 0.023277778178453445, Test Loss: 0.25676429271698\n",
            "Epoch 35, Train Loss: 0.02246043272316456, Test Loss: 0.2611417770385742\n",
            "Epoch 36, Train Loss: 0.022461852058768272, Test Loss: 0.2618773579597473\n",
            "Epoch 37, Train Loss: 0.022376416251063347, Test Loss: 0.25974249839782715\n",
            "Epoch 38, Train Loss: 0.021843599155545235, Test Loss: 0.25660860538482666\n",
            "Epoch 39, Train Loss: 0.021312659606337547, Test Loss: 0.2546021342277527\n",
            "Epoch 40, Train Loss: 0.02114248462021351, Test Loss: 0.2552177906036377\n",
            "Epoch 41, Train Loss: 0.021082445979118347, Test Loss: 0.258761465549469\n",
            "Epoch 42, Train Loss: 0.02078697644174099, Test Loss: 0.26430535316467285\n",
            "Epoch 43, Train Loss: 0.02037675492465496, Test Loss: 0.2701285481452942\n",
            "Epoch 44, Train Loss: 0.02017764002084732, Test Loss: 0.2744612693786621\n",
            "Epoch 45, Train Loss: 0.0201815664768219, Test Loss: 0.27623263001441956\n",
            "Epoch 46, Train Loss: 0.020094791427254677, Test Loss: 0.2754902243614197\n",
            "Epoch 47, Train Loss: 0.019815189763903618, Test Loss: 0.2733003795146942\n",
            "Epoch 48, Train Loss: 0.01957005448639393, Test Loss: 0.27120447158813477\n",
            "Epoch 49, Train Loss: 0.019543854519724846, Test Loss: 0.2705090343952179\n",
            "Test Loss: 0.2705090343952179\n",
            "MSE: 0.26366922\n",
            "MAE: 0.44983867\n",
            "R^2: -26.135888523656078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba model with Case 2 (Inputs are Discharging Capacity and CVCC)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "# Assuming bucketing into 1000 categories for each feature\n",
        "num_buckets = 1000\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "\n",
        "# Encoding and reshaping\n",
        "dcinput_encoded_train = np.floor(np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_test = np.floor(np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "cvcc_encoded_train = np.floor(np.concatenate([X_train_cvccB0005, X_train_cvccB0006]) * num_buckets).astype(int) % num_buckets\n",
        "cvcc_encoded_test = np.floor(np.concatenate([X_test_cvccB0005, X_test_cvccB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([dcinput_encoded_train, cvcc_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([dcinput_encoded_test, cvcc_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "# Model adaptation\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        volt_embeddings = self.embedding(features[:, :features.shape[1]//2])\n",
        "        time_embeddings = self.embedding(features[:, features.shape[1]//2:])\n",
        "        combined_embeddings = (volt_embeddings + time_embeddings) / 2\n",
        "        outputs = self.mamba(inputs_embeds=combined_embeddings)\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Building and compiling the model\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Training function\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):  # number of epochs\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)  # Directly using test as validation for demonstration\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDiDtnyRxMuC",
        "outputId": "52b86c28-57a3-4b36-dd66-0be02155b4ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 3.5249924659729004, Test Loss: 18.851703643798828\n",
            "Epoch 1, Train Loss: 15.458888053894043, Test Loss: 0.24435439705848694\n",
            "Epoch 2, Train Loss: 0.16891461610794067, Test Loss: 3.648308038711548\n",
            "Epoch 3, Train Loss: 4.349555492401123, Test Loss: 0.8122110962867737\n",
            "Epoch 4, Train Loss: 1.135394811630249, Test Loss: 0.5162286758422852\n",
            "Epoch 5, Train Loss: 0.22861434519290924, Test Loss: 1.805713415145874\n",
            "Epoch 6, Train Loss: 1.047043800354004, Test Loss: 1.3872369527816772\n",
            "Epoch 7, Train Loss: 0.5983670949935913, Test Loss: 0.533351719379425\n",
            "Epoch 8, Train Loss: 0.13417048752307892, Test Loss: 0.36086857318878174\n",
            "Epoch 9, Train Loss: 0.46654626727104187, Test Loss: 0.2023242563009262\n",
            "Epoch 10, Train Loss: 0.31373757123947144, Test Loss: 0.15207701921463013\n",
            "Epoch 11, Train Loss: 0.11403529345989227, Test Loss: 0.256428599357605\n",
            "Epoch 12, Train Loss: 0.07690814882516861, Test Loss: 0.3894669711589813\n",
            "Epoch 13, Train Loss: 0.12579505145549774, Test Loss: 0.3627028167247772\n",
            "Epoch 14, Train Loss: 0.0920630618929863, Test Loss: 0.2691749930381775\n",
            "Epoch 15, Train Loss: 0.03583730012178421, Test Loss: 0.22202099859714508\n",
            "Epoch 16, Train Loss: 0.04347938671708107, Test Loss: 0.23036743700504303\n",
            "Epoch 17, Train Loss: 0.07058127969503403, Test Loss: 0.2513349652290344\n",
            "Epoch 18, Train Loss: 0.05406992882490158, Test Loss: 0.2874879837036133\n",
            "Epoch 19, Train Loss: 0.03155481815338135, Test Loss: 0.3344208598136902\n",
            "Epoch 20, Train Loss: 0.037025097757577896, Test Loss: 0.35561293363571167\n",
            "Epoch 21, Train Loss: 0.05073036625981331, Test Loss: 0.3271205425262451\n",
            "Epoch 22, Train Loss: 0.04555908590555191, Test Loss: 0.268144428730011\n",
            "Epoch 23, Train Loss: 0.030212391167879105, Test Loss: 0.21645809710025787\n",
            "Epoch 24, Train Loss: 0.027325427159667015, Test Loss: 0.1922052502632141\n",
            "Epoch 25, Train Loss: 0.03599924594163895, Test Loss: 0.19430631399154663\n",
            "Epoch 26, Train Loss: 0.03780415281653404, Test Loss: 0.21932940185070038\n",
            "Epoch 27, Train Loss: 0.02896089106798172, Test Loss: 0.2635321617126465\n",
            "Epoch 28, Train Loss: 0.023098278790712357, Test Loss: 0.3099818527698517\n",
            "Epoch 29, Train Loss: 0.026794958859682083, Test Loss: 0.3329882323741913\n",
            "Epoch 30, Train Loss: 0.03136569634079933, Test Loss: 0.3202346861362457\n",
            "Epoch 31, Train Loss: 0.028744950890541077, Test Loss: 0.28353169560432434\n",
            "Epoch 32, Train Loss: 0.022976314648985863, Test Loss: 0.2457425594329834\n",
            "Epoch 33, Train Loss: 0.02185475267469883, Test Loss: 0.22205446660518646\n",
            "Epoch 34, Train Loss: 0.024860767647624016, Test Loss: 0.21565619111061096\n",
            "Epoch 35, Train Loss: 0.025702863931655884, Test Loss: 0.22499597072601318\n",
            "Epoch 36, Train Loss: 0.022979872301220894, Test Loss: 0.24655437469482422\n",
            "Epoch 37, Train Loss: 0.02106938324868679, Test Loss: 0.2712787687778473\n",
            "Epoch 38, Train Loss: 0.022040799260139465, Test Loss: 0.28649523854255676\n",
            "Epoch 39, Train Loss: 0.023033609613776207, Test Loss: 0.28524935245513916\n",
            "Epoch 40, Train Loss: 0.02182929776608944, Test Loss: 0.27158382534980774\n",
            "Epoch 41, Train Loss: 0.020246943458914757, Test Loss: 0.25554803013801575\n",
            "Epoch 42, Train Loss: 0.020491614937782288, Test Loss: 0.24515096843242645\n",
            "Epoch 43, Train Loss: 0.02151762880384922, Test Loss: 0.24348829686641693\n",
            "Epoch 44, Train Loss: 0.021206878125667572, Test Loss: 0.24998007714748383\n",
            "Epoch 45, Train Loss: 0.019925866276025772, Test Loss: 0.2609390914440155\n",
            "Epoch 46, Train Loss: 0.019504092633724213, Test Loss: 0.2700121998786926\n",
            "Epoch 47, Train Loss: 0.020093517377972603, Test Loss: 0.27153515815734863\n",
            "Epoch 48, Train Loss: 0.0203115064650774, Test Loss: 0.26485028862953186\n",
            "Epoch 49, Train Loss: 0.019736213609576225, Test Loss: 0.2546417713165283\n",
            "Test Loss: 0.2546417713165283\n",
            "Mean Squared Error (MSE): 0.19463910162448883\n",
            "Mean Absolute Error (MAE): 0.37952712178230286\n",
            "R^2 Score: -19.03155731158787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba model with Case 3 (Inputs are Discharging Capacity, CCCT, and CCV)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "num_buckets = 1000  # Assuming bucketing into 1000 categories for each feature\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccv_encoded_train = np.floor(np.concatenate([X_train_ccvB0005, X_train_ccvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccv_encoded_test = np.floor(np.concatenate([X_test_ccvB0005, X_test_ccvB0006 ]) * num_buckets).astype(int) % num_buckets\n",
        "ccct_encoded_train = np.floor(np.concatenate([X_train_ccctB0005, X_train_ccctB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccct_encoded_test = np.floor(np.concatenate([X_test_ccctB0005, X_test_ccctB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_train = np.floor(np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_test = np.floor(np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([dcinput_encoded_train, ccv_encoded_train, ccct_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([dcinput_encoded_test, ccv_encoded_test, ccct_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        embeddings = self.embedding(features)\n",
        "        # Aggregate embeddings: average across the sequence length (here across all features)\n",
        "        pooled_embeddings = embeddings.mean(dim=1)\n",
        "        outputs = self.mamba(inputs_embeds=pooled_embeddings.unsqueeze(1))\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training and evaluation code setup\n",
        "for epoch in range(50):\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPD0lhNS9O_c",
        "outputId": "6336eb02-e60c-425c-ef39-078af333b177"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 3.7678608894348145, Test Loss: 7.2793288230896\n",
            "Epoch 1, Train Loss: 11.126029014587402, Test Loss: 0.3485347032546997\n",
            "Epoch 2, Train Loss: 0.08733738958835602, Test Loss: 0.32789701223373413\n",
            "Epoch 3, Train Loss: 1.6042956113815308, Test Loss: 0.4157648980617523\n",
            "Epoch 4, Train Loss: 1.5305238962173462, Test Loss: 0.2247483730316162\n",
            "Epoch 5, Train Loss: 0.5010473728179932, Test Loss: 0.16264133155345917\n",
            "Epoch 6, Train Loss: 0.10663770139217377, Test Loss: 0.3307138979434967\n",
            "Epoch 7, Train Loss: 0.448649525642395, Test Loss: 0.37511196732521057\n",
            "Epoch 8, Train Loss: 0.3706232011318207, Test Loss: 0.23298300802707672\n",
            "Epoch 9, Train Loss: 0.09525060653686523, Test Loss: 0.11024738848209381\n",
            "Epoch 10, Train Loss: 0.11203030496835709, Test Loss: 0.08696716278791428\n",
            "Epoch 11, Train Loss: 0.2501625418663025, Test Loss: 0.09667778015136719\n",
            "Epoch 12, Train Loss: 0.2180679589509964, Test Loss: 0.10144173353910446\n",
            "Epoch 13, Train Loss: 0.09354674816131592, Test Loss: 0.11676690727472305\n",
            "Epoch 14, Train Loss: 0.03314119577407837, Test Loss: 0.15242712199687958\n",
            "Epoch 15, Train Loss: 0.07302059978246689, Test Loss: 0.17875413596630096\n",
            "Epoch 16, Train Loss: 0.11722846329212189, Test Loss: 0.16640543937683105\n",
            "Epoch 17, Train Loss: 0.09126797318458557, Test Loss: 0.13522611558437347\n",
            "Epoch 18, Train Loss: 0.04266196861863136, Test Loss: 0.11129581183195114\n",
            "Epoch 19, Train Loss: 0.024890275672078133, Test Loss: 0.10054322332143784\n",
            "Epoch 20, Train Loss: 0.04027259349822998, Test Loss: 0.09620749205350876\n",
            "Epoch 21, Train Loss: 0.0560799203813076, Test Loss: 0.09353756159543991\n",
            "Epoch 22, Train Loss: 0.05261629447340965, Test Loss: 0.09249535948038101\n",
            "Epoch 23, Train Loss: 0.037847090512514114, Test Loss: 0.09427845478057861\n",
            "Epoch 24, Train Loss: 0.025830058380961418, Test Loss: 0.09882741421461105\n",
            "Epoch 25, Train Loss: 0.023354824632406235, Test Loss: 0.10427271574735641\n",
            "Epoch 26, Train Loss: 0.028222177177667618, Test Loss: 0.10799342393875122\n",
            "Epoch 27, Train Loss: 0.03322679549455643, Test Loss: 0.1086379811167717\n",
            "Epoch 28, Train Loss: 0.03298231586813927, Test Loss: 0.10695824772119522\n",
            "Epoch 29, Train Loss: 0.028088703751564026, Test Loss: 0.10454964637756348\n",
            "Epoch 30, Train Loss: 0.023090785369277, Test Loss: 0.10221780836582184\n",
            "Epoch 31, Train Loss: 0.02145591750741005, Test Loss: 0.09974567592144012\n",
            "Epoch 32, Train Loss: 0.02299717627465725, Test Loss: 0.09683702141046524\n",
            "Epoch 33, Train Loss: 0.02518319897353649, Test Loss: 0.09389065206050873\n",
            "Epoch 34, Train Loss: 0.025841116905212402, Test Loss: 0.09184900671243668\n",
            "Epoch 35, Train Loss: 0.024607671424746513, Test Loss: 0.09147460758686066\n",
            "Epoch 36, Train Loss: 0.02255757711827755, Test Loss: 0.09286153316497803\n",
            "Epoch 37, Train Loss: 0.021022213622927666, Test Loss: 0.09555675834417343\n",
            "Epoch 38, Train Loss: 0.020699206739664078, Test Loss: 0.09889702498912811\n",
            "Epoch 39, Train Loss: 0.021370211616158485, Test Loss: 0.10207786411046982\n",
            "Epoch 40, Train Loss: 0.022128747776150703, Test Loss: 0.10415153205394745\n",
            "Epoch 41, Train Loss: 0.022081751376390457, Test Loss: 0.10436251014471054\n",
            "Epoch 42, Train Loss: 0.02111942693591118, Test Loss: 0.1026313304901123\n",
            "Epoch 43, Train Loss: 0.019984448328614235, Test Loss: 0.09965521097183228\n",
            "Epoch 44, Train Loss: 0.0195144210010767, Test Loss: 0.09649680554866791\n",
            "Epoch 45, Train Loss: 0.01985463686287403, Test Loss: 0.09404624998569489\n",
            "Epoch 46, Train Loss: 0.020409468561410904, Test Loss: 0.09276793152093887\n",
            "Epoch 47, Train Loss: 0.02049311064183712, Test Loss: 0.09277165681123734\n",
            "Epoch 48, Train Loss: 0.019987238571047783, Test Loss: 0.09393059462308884\n",
            "Epoch 49, Train Loss: 0.019366366788744926, Test Loss: 0.09586118906736374\n",
            "Test Loss: 0.09586118906736374\n",
            "MSE: 0.080763064\n",
            "MAE: 0.23155124\n",
            "R^2: -7.311844301638642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba model with Case 4 (Discharging Capacity, CCCT, CCV, and CVC)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "num_buckets = 1000  # Assuming bucketing into 1000 categories for each feature\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccvB0005 = ccvB0005[0:103, :]\n",
        "X_train_ccvB0006 = ccvB0006[0:60, :]\n",
        "X_train_ccctB0005 = ccctB0005[0:103, :]\n",
        "X_train_ccctB0006 = ccctB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_cvccB0005 = cvccB0005[0:103, :]\n",
        "X_train_cvccB0006 = cvccB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccvB0005 = ccvB0005[104:, :]\n",
        "X_test_ccvB0006 = ccvB0006[61:, :]\n",
        "X_test_ccctB0005 = ccctB0005[104:, :]\n",
        "X_test_ccctB0006 = ccctB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_cvccB0005 = cvccB0005[104:, :]\n",
        "X_test_cvccB0006 = cvccB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccv_encoded_train = np.floor(np.concatenate([X_train_ccvB0005, X_train_ccvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccv_encoded_test = np.floor(np.concatenate([X_test_ccvB0005, X_test_ccvB0006 ]) * num_buckets).astype(int) % num_buckets\n",
        "ccct_encoded_train = np.floor(np.concatenate([X_train_ccctB0005, X_train_ccctB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccct_encoded_test = np.floor(np.concatenate([X_test_ccctB0005, X_test_ccctB0006]) * num_buckets).astype(int) % num_buckets\n",
        "cvcc_encoded_train = np.floor(np.concatenate([X_train_cvccB0005, X_train_cvccB0006]) * num_buckets).astype(int) % num_buckets\n",
        "cvcc_encoded_test = np.floor(np.concatenate([X_test_cvccB0005, X_test_cvccB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_train = np.floor(np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_test = np.floor(np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([dcinput_encoded_train, ccv_encoded_train, ccct_encoded_train, cvcc_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([dcinput_encoded_test, ccv_encoded_test, ccct_encoded_test, cvcc_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        embeddings = self.embedding(features)\n",
        "        # Aggregate embeddings: average across the sequence length (here across all features)\n",
        "        pooled_embeddings = embeddings.mean(dim=1)\n",
        "        outputs = self.mamba(inputs_embeds=pooled_embeddings.unsqueeze(1))\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training and evaluation code setup\n",
        "for epoch in range(50):\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x-ggOJc9-IM",
        "outputId": "d74ff212-a545-45fd-9eaa-b0ad0c8a805f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 2.15959095954895, Test Loss: 37.701175689697266\n",
            "Epoch 1, Train Loss: 32.655555725097656, Test Loss: 2.099595546722412\n",
            "Epoch 2, Train Loss: 1.388293981552124, Test Loss: 4.543839454650879\n",
            "Epoch 3, Train Loss: 5.376101016998291, Test Loss: 2.1483025550842285\n",
            "Epoch 4, Train Loss: 3.265002489089966, Test Loss: 0.12268330156803131\n",
            "Epoch 5, Train Loss: 0.6496732234954834, Test Loss: 1.1485528945922852\n",
            "Epoch 6, Train Loss: 0.5741653442382812, Test Loss: 2.006399393081665\n",
            "Epoch 7, Train Loss: 0.918693482875824, Test Loss: 1.2794015407562256\n",
            "Epoch 8, Train Loss: 0.5839595794677734, Test Loss: 0.33368074893951416\n",
            "Epoch 9, Train Loss: 0.21846389770507812, Test Loss: 0.07200238108634949\n",
            "Epoch 10, Train Loss: 0.23989838361740112, Test Loss: 0.14988477528095245\n",
            "Epoch 11, Train Loss: 0.36860936880111694, Test Loss: 0.12053872644901276\n",
            "Epoch 12, Train Loss: 0.3147869408130646, Test Loss: 0.16232098639011383\n",
            "Epoch 13, Train Loss: 0.18704017996788025, Test Loss: 0.3864569067955017\n",
            "Epoch 14, Train Loss: 0.14920766651630402, Test Loss: 0.48696479201316833\n",
            "Epoch 15, Train Loss: 0.12386307865381241, Test Loss: 0.37003734707832336\n",
            "Epoch 16, Train Loss: 0.10766982287168503, Test Loss: 0.17620055377483368\n",
            "Epoch 17, Train Loss: 0.08073171228170395, Test Loss: 0.06714025884866714\n",
            "Epoch 18, Train Loss: 0.06851650774478912, Test Loss: 0.04146818444132805\n",
            "Epoch 19, Train Loss: 0.06461703032255173, Test Loss: 0.0683320090174675\n",
            "Epoch 20, Train Loss: 0.05722963809967041, Test Loss: 0.12420988082885742\n",
            "Epoch 21, Train Loss: 0.056429702788591385, Test Loss: 0.177254319190979\n",
            "Epoch 22, Train Loss: 0.0599052794277668, Test Loss: 0.20319847762584686\n",
            "Epoch 23, Train Loss: 0.049240000545978546, Test Loss: 0.2131839096546173\n",
            "Epoch 24, Train Loss: 0.03186383843421936, Test Loss: 0.22939059138298035\n",
            "Epoch 25, Train Loss: 0.03317197039723396, Test Loss: 0.24238689243793488\n",
            "Epoch 26, Train Loss: 0.04911445826292038, Test Loss: 0.22706903517246246\n",
            "Epoch 27, Train Loss: 0.05240771174430847, Test Loss: 0.18669286370277405\n",
            "Epoch 28, Train Loss: 0.03839457035064697, Test Loss: 0.14967358112335205\n",
            "Epoch 29, Train Loss: 0.027474481612443924, Test Loss: 0.13205595314502716\n",
            "Epoch 30, Train Loss: 0.02874869853258133, Test Loss: 0.12475842982530594\n",
            "Epoch 31, Train Loss: 0.03175251558423042, Test Loss: 0.11558705568313599\n",
            "Epoch 32, Train Loss: 0.030772222205996513, Test Loss: 0.10545946657657623\n",
            "Epoch 33, Train Loss: 0.030453195795416832, Test Loss: 0.10186800360679626\n",
            "Epoch 34, Train Loss: 0.030760353431105614, Test Loss: 0.1093708872795105\n",
            "Epoch 35, Train Loss: 0.02716665156185627, Test Loss: 0.12786461412906647\n",
            "Epoch 36, Train Loss: 0.021914731711149216, Test Loss: 0.15225863456726074\n",
            "Epoch 37, Train Loss: 0.021316273137927055, Test Loss: 0.17220929265022278\n",
            "Epoch 38, Train Loss: 0.025014137849211693, Test Loss: 0.17743559181690216\n",
            "Epoch 39, Train Loss: 0.02658762037754059, Test Loss: 0.16611221432685852\n",
            "Epoch 40, Train Loss: 0.02400060184299946, Test Loss: 0.14555877447128296\n",
            "Epoch 41, Train Loss: 0.021346380934119225, Test Loss: 0.12513616681098938\n",
            "Epoch 42, Train Loss: 0.02096531353890896, Test Loss: 0.11124329268932343\n",
            "Epoch 43, Train Loss: 0.021231357008218765, Test Loss: 0.1065668910741806\n",
            "Epoch 44, Train Loss: 0.02129090204834938, Test Loss: 0.10954884439706802\n",
            "Epoch 45, Train Loss: 0.021964237093925476, Test Loss: 0.11493189632892609\n",
            "Epoch 46, Train Loss: 0.022528942674398422, Test Loss: 0.11816291511058807\n",
            "Epoch 47, Train Loss: 0.0214217659085989, Test Loss: 0.11956732720136642\n",
            "Epoch 48, Train Loss: 0.01952429488301277, Test Loss: 0.12251049280166626\n",
            "Epoch 49, Train Loss: 0.019056618213653564, Test Loss: 0.1284392923116684\n",
            "Test Loss: 0.1284392923116684\n",
            "MSE: 0.10081045\n",
            "MAE: 0.29231086\n",
            "R^2: -9.375048676698752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba Model with Case 5 (Inputs are CCDT and CCDV)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "num_buckets = 1000  # Assuming bucketing into 1000 categories for each feature\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccdt_encoded_train = np.floor(np.concatenate([X_train_ccdtB0005, X_train_ccdtB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdt_encoded_test = np.floor(np.concatenate([X_test_ccdtB0005, X_test_ccdtB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_train = np.floor(np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_test = np.floor(np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([ccdt_encoded_train, ccdv_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([ccdt_encoded_test, ccdv_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        embeddings = self.embedding(features)\n",
        "        # Aggregate embeddings: average across the sequence length (here across all features)\n",
        "        pooled_embeddings = embeddings.mean(dim=1)\n",
        "        outputs = self.mamba(inputs_embeds=pooled_embeddings.unsqueeze(1))\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training and evaluation code setup\n",
        "for epoch in range(50):\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R37lFtLD_i5z",
        "outputId": "c83dfce1-c53c-448a-e4d3-7857c49c7474"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 4.665439128875732, Test Loss: 13.348295211791992\n",
            "Epoch 1, Train Loss: 17.630626678466797, Test Loss: 0.3846375346183777\n",
            "Epoch 2, Train Loss: 0.20581316947937012, Test Loss: 1.626458764076233\n",
            "Epoch 3, Train Loss: 3.3963441848754883, Test Loss: 1.0340076684951782\n",
            "Epoch 4, Train Loss: 2.094491958618164, Test Loss: 0.19102731347084045\n",
            "Epoch 5, Train Loss: 0.27074581384658813, Test Loss: 0.6760230660438538\n",
            "Epoch 6, Train Loss: 0.5208434462547302, Test Loss: 0.9812687039375305\n",
            "Epoch 7, Train Loss: 0.8450825214385986, Test Loss: 0.5116139054298401\n",
            "Epoch 8, Train Loss: 0.35594642162323, Test Loss: 0.15284375846385956\n",
            "Epoch 9, Train Loss: 0.06434759497642517, Test Loss: 0.12361475825309753\n",
            "Epoch 10, Train Loss: 0.15865084528923035, Test Loss: 0.20304188132286072\n",
            "Epoch 11, Train Loss: 0.31830650568008423, Test Loss: 0.19441728293895721\n",
            "Epoch 12, Train Loss: 0.30452123284339905, Test Loss: 0.1219383254647255\n",
            "Epoch 13, Train Loss: 0.17622046172618866, Test Loss: 0.07437514513731003\n",
            "Epoch 14, Train Loss: 0.06564638763666153, Test Loss: 0.09308090060949326\n",
            "Epoch 15, Train Loss: 0.039088036864995956, Test Loss: 0.16021466255187988\n",
            "Epoch 16, Train Loss: 0.08325498551130295, Test Loss: 0.21555842459201813\n",
            "Epoch 17, Train Loss: 0.12437209486961365, Test Loss: 0.21863165497779846\n",
            "Epoch 18, Train Loss: 0.11232468485832214, Test Loss: 0.18287427723407745\n",
            "Epoch 19, Train Loss: 0.06925240159034729, Test Loss: 0.14044517278671265\n",
            "Epoch 20, Train Loss: 0.036993809044361115, Test Loss: 0.10995124280452728\n",
            "Epoch 21, Train Loss: 0.03158202022314072, Test Loss: 0.09363748878240585\n",
            "Epoch 22, Train Loss: 0.043457724153995514, Test Loss: 0.08628077805042267\n",
            "Epoch 23, Train Loss: 0.05552846938371658, Test Loss: 0.08298996090888977\n",
            "Epoch 24, Train Loss: 0.057666558772325516, Test Loss: 0.08280593901872635\n",
            "Epoch 25, Train Loss: 0.05036674812436104, Test Loss: 0.08779969811439514\n",
            "Epoch 26, Train Loss: 0.03941478952765465, Test Loss: 0.09975637495517731\n",
            "Epoch 27, Train Loss: 0.03015797771513462, Test Loss: 0.11775004863739014\n",
            "Epoch 28, Train Loss: 0.026272548362612724, Test Loss: 0.13765151798725128\n",
            "Epoch 29, Train Loss: 0.028735648840665817, Test Loss: 0.15325449407100677\n",
            "Epoch 30, Train Loss: 0.03379472345113754, Test Loss: 0.15921233594417572\n",
            "Epoch 31, Train Loss: 0.03581780567765236, Test Loss: 0.15416419506072998\n",
            "Epoch 32, Train Loss: 0.032973792403936386, Test Loss: 0.1411769539117813\n",
            "Epoch 33, Train Loss: 0.027778014540672302, Test Loss: 0.12545031309127808\n",
            "Epoch 34, Train Loss: 0.023695750162005424, Test Loss: 0.11151543259620667\n",
            "Epoch 35, Train Loss: 0.022404786199331284, Test Loss: 0.10173651576042175\n",
            "Epoch 36, Train Loss: 0.02334441989660263, Test Loss: 0.09642679989337921\n",
            "Epoch 37, Train Loss: 0.024869676679372787, Test Loss: 0.09485936164855957\n",
            "Epoch 38, Train Loss: 0.025602897629141808, Test Loss: 0.09625958651304245\n",
            "Epoch 39, Train Loss: 0.025072790682315826, Test Loss: 0.10021231323480606\n",
            "Epoch 40, Train Loss: 0.023621629923582077, Test Loss: 0.10642341524362564\n",
            "Epoch 41, Train Loss: 0.021996866911649704, Test Loss: 0.11418680101633072\n",
            "Epoch 42, Train Loss: 0.02091016061604023, Test Loss: 0.1220686212182045\n",
            "Epoch 43, Train Loss: 0.02067285031080246, Test Loss: 0.12816466391086578\n",
            "Epoch 44, Train Loss: 0.02105243317782879, Test Loss: 0.13086524605751038\n",
            "Epoch 45, Train Loss: 0.02147713676095009, Test Loss: 0.12963281571865082\n",
            "Epoch 46, Train Loss: 0.021470889449119568, Test Loss: 0.12523218989372253\n",
            "Epoch 47, Train Loss: 0.020975731313228607, Test Loss: 0.11926969140768051\n",
            "Epoch 48, Train Loss: 0.020313328132033348, Test Loss: 0.1134154200553894\n",
            "Epoch 49, Train Loss: 0.019866567105054855, Test Loss: 0.10882141441106796\n",
            "Test Loss: 0.10882141441106796\n",
            "MSE: 0.09813286\n",
            "MAE: 0.27041265\n",
            "R^2: -9.099480827081328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba model with Case 6 (Inputs are CCDV and RoCV)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "num_buckets = 1000  # Assuming bucketing into 1000 categories for each feature\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccdv_encoded_train = np.floor(np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_test = np.floor(np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_RoCV_encoded_train = np.floor(np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_RoCV_encoded_test = np.floor(np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([ccdt_encoded_train, ccdv_RoCV_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([ccdt_encoded_test, ccdv_RoCV_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        embeddings = self.embedding(features)\n",
        "        # Aggregate embeddings: average across the sequence length (here across all features)\n",
        "        pooled_embeddings = embeddings.mean(dim=1)\n",
        "        outputs = self.mamba(inputs_embeds=pooled_embeddings.unsqueeze(1))\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training and evaluation code setup\n",
        "for epoch in range(50):\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYjU4iX3BSyK",
        "outputId": "4d45ac12-2f31-4e6d-da48-dca06282cd40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 3.2787327766418457, Test Loss: 13.351444244384766\n",
            "Epoch 1, Train Loss: 16.174299240112305, Test Loss: 0.5206835865974426\n",
            "Epoch 2, Train Loss: 0.23975305259227753, Test Loss: 1.591067910194397\n",
            "Epoch 3, Train Loss: 3.25105357170105, Test Loss: 0.9696124792098999\n",
            "Epoch 4, Train Loss: 2.0578887462615967, Test Loss: 0.22061271965503693\n",
            "Epoch 5, Train Loss: 0.33194202184677124, Test Loss: 0.7270879745483398\n",
            "Epoch 6, Train Loss: 0.4166552424430847, Test Loss: 1.15664541721344\n",
            "Epoch 7, Train Loss: 0.8217693567276001, Test Loss: 0.7076021432876587\n",
            "Epoch 8, Train Loss: 0.4199465811252594, Test Loss: 0.2356298863887787\n",
            "Epoch 9, Train Loss: 0.08168550580739975, Test Loss: 0.12419198453426361\n",
            "Epoch 10, Train Loss: 0.14479589462280273, Test Loss: 0.20941077172756195\n",
            "Epoch 11, Train Loss: 0.3185305893421173, Test Loss: 0.22209101915359497\n",
            "Epoch 12, Train Loss: 0.29179254174232483, Test Loss: 0.17910988628864288\n",
            "Epoch 13, Train Loss: 0.15463580191135406, Test Loss: 0.17206570506095886\n",
            "Epoch 14, Train Loss: 0.056264378130435944, Test Loss: 0.2249840348958969\n",
            "Epoch 15, Train Loss: 0.04513171687722206, Test Loss: 0.3028237223625183\n",
            "Epoch 16, Train Loss: 0.09269939363002777, Test Loss: 0.344826340675354\n",
            "Epoch 17, Train Loss: 0.12530110776424408, Test Loss: 0.32570135593414307\n",
            "Epoch 18, Train Loss: 0.10406320542097092, Test Loss: 0.2723648250102997\n",
            "Epoch 19, Train Loss: 0.0576685294508934, Test Loss: 0.22148065268993378\n",
            "Epoch 20, Train Loss: 0.029465455561876297, Test Loss: 0.18984024226665497\n",
            "Epoch 21, Train Loss: 0.03376396745443344, Test Loss: 0.17457757890224457\n",
            "Epoch 22, Train Loss: 0.0542057603597641, Test Loss: 0.16537927091121674\n",
            "Epoch 23, Train Loss: 0.0656675398349762, Test Loss: 0.15709763765335083\n",
            "Epoch 24, Train Loss: 0.05896947532892227, Test Loss: 0.15264087915420532\n",
            "Epoch 25, Train Loss: 0.04329361394047737, Test Loss: 0.15672488510608673\n",
            "Epoch 26, Train Loss: 0.031080109998583794, Test Loss: 0.17026136815547943\n",
            "Epoch 27, Train Loss: 0.02712789736688137, Test Loss: 0.18947330117225647\n",
            "Epoch 28, Train Loss: 0.028952717781066895, Test Loss: 0.20831991732120514\n",
            "Epoch 29, Train Loss: 0.03213081508874893, Test Loss: 0.22148169577121735\n",
            "Epoch 30, Train Loss: 0.03377978876233101, Test Loss: 0.22626221179962158\n",
            "Epoch 31, Train Loss: 0.033024080097675323, Test Loss: 0.2229110449552536\n",
            "Epoch 32, Train Loss: 0.030357344076037407, Test Loss: 0.21371006965637207\n",
            "Epoch 33, Train Loss: 0.02701624296605587, Test Loss: 0.20161479711532593\n",
            "Epoch 34, Train Loss: 0.02431456185877323, Test Loss: 0.1891847401857376\n",
            "Epoch 35, Train Loss: 0.023030927404761314, Test Loss: 0.17815983295440674\n",
            "Epoch 36, Train Loss: 0.023150766268372536, Test Loss: 0.1695806086063385\n",
            "Epoch 37, Train Loss: 0.024019595235586166, Test Loss: 0.16408860683441162\n",
            "Epoch 38, Train Loss: 0.02472306601703167, Test Loss: 0.16210660338401794\n",
            "Epoch 39, Train Loss: 0.02454463206231594, Test Loss: 0.16380585730075836\n",
            "Epoch 40, Train Loss: 0.023368069902062416, Test Loss: 0.16893741488456726\n",
            "Epoch 41, Train Loss: 0.021762600168585777, Test Loss: 0.1766614019870758\n",
            "Epoch 42, Train Loss: 0.02058340795338154, Test Loss: 0.18551531434059143\n",
            "Epoch 43, Train Loss: 0.020344648510217667, Test Loss: 0.1936436891555786\n",
            "Epoch 44, Train Loss: 0.02087216265499592, Test Loss: 0.19929446280002594\n",
            "Epoch 45, Train Loss: 0.021500786766409874, Test Loss: 0.20138601958751678\n",
            "Epoch 46, Train Loss: 0.021613039076328278, Test Loss: 0.19982871413230896\n",
            "Epoch 47, Train Loss: 0.02106347307562828, Test Loss: 0.19542337954044342\n",
            "Epoch 48, Train Loss: 0.020193040370941162, Test Loss: 0.1894507110118866\n",
            "Epoch 49, Train Loss: 0.019508464261889458, Test Loss: 0.1832251399755478\n",
            "Test Loss: 0.1832251399755478\n",
            "MSE: 0.18701077\n",
            "MAE: 0.36412054\n",
            "R^2: -18.246474192275205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba model with Case 7 (Inputs are Discharging Capacity, CCDT, and CCDV)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "num_buckets = 1000  # Assuming bucketing into 1000 categories for each feature\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccdt_encoded_train = np.floor(np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdt_encoded_test = np.floor(np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_train = np.floor(np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_test = np.floor(np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_train = np.floor(np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_test = np.floor(np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([ccdt_encoded_train, ccdv_encoded_train, dcinput_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([ccdt_encoded_test, ccdv_encoded_test, dcinput_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        embeddings = self.embedding(features)\n",
        "        # Aggregate embeddings: average across the sequence length (here across all features)\n",
        "        pooled_embeddings = embeddings.mean(dim=1)\n",
        "        outputs = self.mamba(inputs_embeds=pooled_embeddings.unsqueeze(1))\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training and evaluation code setup\n",
        "for epoch in range(50):\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArUqEQQEJ39G",
        "outputId": "979f6d65-d7dc-47d3-8911-965a7f38301b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 2.8898022174835205, Test Loss: 6.978864669799805\n",
            "Epoch 1, Train Loss: 10.386606216430664, Test Loss: 0.22618518769741058\n",
            "Epoch 2, Train Loss: 0.06357471644878387, Test Loss: 0.4145304262638092\n",
            "Epoch 3, Train Loss: 1.8132790327072144, Test Loss: 0.5028293132781982\n",
            "Epoch 4, Train Loss: 1.7091317176818848, Test Loss: 0.25591087341308594\n",
            "Epoch 5, Train Loss: 0.6421957015991211, Test Loss: 0.15268303453922272\n",
            "Epoch 6, Train Loss: 0.12966135144233704, Test Loss: 0.28624242544174194\n",
            "Epoch 7, Train Loss: 0.3680260479450226, Test Loss: 0.326660692691803\n",
            "Epoch 8, Train Loss: 0.45881491899490356, Test Loss: 0.19686931371688843\n",
            "Epoch 9, Train Loss: 0.21493417024612427, Test Loss: 0.08844052255153656\n",
            "Epoch 10, Train Loss: 0.061762336641550064, Test Loss: 0.0725468322634697\n",
            "Epoch 11, Train Loss: 0.1046893373131752, Test Loss: 0.09950225055217743\n",
            "Epoch 12, Train Loss: 0.19622847437858582, Test Loss: 0.10268502682447433\n",
            "Epoch 13, Train Loss: 0.1898466795682907, Test Loss: 0.08557435125112534\n",
            "Epoch 14, Train Loss: 0.11593364924192429, Test Loss: 0.0741167739033699\n",
            "Epoch 15, Train Loss: 0.04888702929019928, Test Loss: 0.09033379703760147\n",
            "Epoch 16, Train Loss: 0.040279123932123184, Test Loss: 0.1269838958978653\n",
            "Epoch 17, Train Loss: 0.08165029436349869, Test Loss: 0.13140007853507996\n",
            "Epoch 18, Train Loss: 0.08442475646734238, Test Loss: 0.10996487736701965\n",
            "Epoch 19, Train Loss: 0.05129111185669899, Test Loss: 0.0930628553032875\n",
            "Epoch 20, Train Loss: 0.02966686710715294, Test Loss: 0.08640047907829285\n",
            "Epoch 21, Train Loss: 0.028794346377253532, Test Loss: 0.08320754021406174\n",
            "Epoch 22, Train Loss: 0.03593236953020096, Test Loss: 0.07861877232789993\n",
            "Epoch 23, Train Loss: 0.03970034047961235, Test Loss: 0.07276057451963425\n",
            "Epoch 24, Train Loss: 0.03708617761731148, Test Loss: 0.06836099177598953\n",
            "Epoch 25, Train Loss: 0.03111731819808483, Test Loss: 0.06778720766305923\n",
            "Epoch 26, Train Loss: 0.026273781433701515, Test Loss: 0.07136297971010208\n",
            "Epoch 27, Train Loss: 0.024924634024500847, Test Loss: 0.07733367383480072\n",
            "Epoch 28, Train Loss: 0.026189513504505157, Test Loss: 0.08319143950939178\n",
            "Epoch 29, Train Loss: 0.0275207981467247, Test Loss: 0.08718321472406387\n",
            "Epoch 30, Train Loss: 0.02726091258227825, Test Loss: 0.08878948539495468\n",
            "Epoch 31, Train Loss: 0.025685705244541168, Test Loss: 0.08825806528329849\n",
            "Epoch 32, Train Loss: 0.02406482957303524, Test Loss: 0.08609066903591156\n",
            "Epoch 33, Train Loss: 0.02324671298265457, Test Loss: 0.08290226012468338\n",
            "Epoch 34, Train Loss: 0.023123079910874367, Test Loss: 0.07945873588323593\n",
            "Epoch 35, Train Loss: 0.023084037005901337, Test Loss: 0.07662491500377655\n",
            "Epoch 36, Train Loss: 0.022744255140423775, Test Loss: 0.07514667510986328\n",
            "Epoch 37, Train Loss: 0.022231942042708397, Test Loss: 0.07534370571374893\n",
            "Epoch 38, Train Loss: 0.021876031532883644, Test Loss: 0.0768926814198494\n",
            "Epoch 39, Train Loss: 0.021724212914705276, Test Loss: 0.07891157269477844\n",
            "Epoch 40, Train Loss: 0.02147539332509041, Test Loss: 0.08039432764053345\n",
            "Epoch 41, Train Loss: 0.020909998565912247, Test Loss: 0.08073525875806808\n",
            "Epoch 42, Train Loss: 0.020257027819752693, Test Loss: 0.07996226847171783\n",
            "Epoch 43, Train Loss: 0.01998117007315159, Test Loss: 0.07855905592441559\n",
            "Epoch 44, Train Loss: 0.02021789737045765, Test Loss: 0.07711084187030792\n",
            "Epoch 45, Train Loss: 0.02056293748319149, Test Loss: 0.07606411725282669\n",
            "Epoch 46, Train Loss: 0.020496735349297523, Test Loss: 0.07566767930984497\n",
            "Epoch 47, Train Loss: 0.019951974973082542, Test Loss: 0.07597450166940689\n",
            "Epoch 48, Train Loss: 0.01937471143901348, Test Loss: 0.0768217220902443\n",
            "Epoch 49, Train Loss: 0.01922803558409214, Test Loss: 0.07784470915794373\n",
            "Test Loss: 0.07784470915794373\n",
            "MSE: 0.057869613\n",
            "MAE: 0.18885602\n",
            "R^2: -4.9557324237344895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mamba model with Case 8 (Inputs are Discharging Capacity, CCDT, CCDB, and RoCV)\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import MambaConfig, MambaModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Configuration for the Mamba model\n",
        "config = MambaConfig(\n",
        "    hidden_size=512,\n",
        "    num_hidden_layers=6,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=2048,\n",
        ")\n",
        "\n",
        "num_buckets = 1000  # Assuming bucketing into 1000 categories for each feature\n",
        "\n",
        "# Prepare the features (X) and the target (y)\n",
        "# Cycles 1 to 103 for B0005 and cycles 1 to 60 for B0006 are considered above 80% SOH condition\n",
        "X_train_ccdtB0005 = ccdtB0005[0:103, :]\n",
        "X_train_ccdtB0006 = ccdtB0006[0:60, :]\n",
        "X_train_ccdvB0005 = ccdvB0005[0:103, :]\n",
        "X_train_ccdvB0006 = ccdvB0006[0:60, :]\n",
        "X_train_dcinputB0005 = dcInputB0005[0:103, :]\n",
        "X_train_dcinputB0006 = dcInputB0006[0:60, :]\n",
        "X_train_ccdv_rocB0005 = ccdv_roc_B0005[0:103, :]\n",
        "X_train_ccdv_rocB0006 = ccdv_roc_B0006[0:60, :]\n",
        "y_train_B0005 = dcB0005[0:103, :]\n",
        "y_train_B0006 = dcB0006[0:60, :]\n",
        "\n",
        "# Cycles 104 to 167 for B0005 and cycles 61 to 167 for B0006 are considered under 80% SOH condition\n",
        "X_test_ccdtB0005 = ccdtB0005[104:, :]\n",
        "X_test_ccdtB0006 = ccdtB0006[61:, :]\n",
        "X_test_ccdvB0005 = ccdvB0005[104:, :]\n",
        "X_test_ccdvB0006 = ccdvB0006[61:, :]\n",
        "X_test_dcinputB0005 = dcInputB0005[104:, :]\n",
        "X_test_dcinputB0006 = dcInputB0006[61:, :]\n",
        "X_test_ccdv_rocB0005 = ccdv_roc_B0005[104:, :]\n",
        "X_test_ccdv_rocB0006 = ccdv_roc_B0006[61:, :]\n",
        "y_test_B0005 = dcB0005[104:, :]\n",
        "y_test_B0006 = dcB0006[61:, :]\n",
        "\n",
        "# Encoding and reshaping\n",
        "ccdt_encoded_train = np.floor(np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdt_encoded_test = np.floor(np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_train = np.floor(np.concatenate([X_train_ccdvB0005, X_train_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_encoded_test = np.floor(np.concatenate([X_test_ccdvB0005, X_test_ccdvB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_roc_encoded_train = np.floor(np.concatenate([X_train_ccdv_rocB0005, X_train_ccdv_rocB0006]) * num_buckets).astype(int) % num_buckets\n",
        "ccdv_roc_encoded_test = np.floor(np.concatenate([X_test_ccdv_rocB0005, X_test_ccdv_rocB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_train = np.floor(np.concatenate([X_train_dcinputB0005, X_train_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "dcinput_encoded_test = np.floor(np.concatenate([X_test_dcinputB0005, X_test_dcinputB0006]) * num_buckets).astype(int) % num_buckets\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(np.concatenate([ccdt_encoded_train, ccdv_encoded_train, dcinput_encoded_train, ccdv_roc_encoded_train], axis=1), dtype=torch.long)\n",
        "y_train = torch.tensor(np.concatenate([y_train_B0005, y_train_B0006]), dtype=torch.float32)\n",
        "X_test = torch.tensor(np.concatenate([ccdt_encoded_test, ccdv_encoded_test, dcinput_encoded_test, ccdv_roc_encoded_test], axis=1), dtype=torch.long)\n",
        "y_test = torch.tensor(np.concatenate([y_test_B0005, y_test_B0006]), dtype=torch.float32)\n",
        "\n",
        "class RegressionMamba(nn.Module):\n",
        "    def __init__(self, config, num_buckets):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_buckets, config.hidden_size)\n",
        "        self.mamba = MambaModel(config)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)  # Output layer for regression\n",
        "\n",
        "    def forward(self, features):\n",
        "        embeddings = self.embedding(features)\n",
        "        # Aggregate embeddings: average across the sequence length (here across all features)\n",
        "        pooled_embeddings = embeddings.mean(dim=1)\n",
        "        outputs = self.mamba(inputs_embeds=pooled_embeddings.unsqueeze(1))\n",
        "        regression_output = self.regressor(outputs.last_hidden_state[:, -1])\n",
        "        return regression_output.squeeze()\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = RegressionMamba(config, num_buckets)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_fn(predictions, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X)\n",
        "        loss = loss_fn(predictions, y)\n",
        "        return loss, predictions\n",
        "\n",
        "# Training and evaluation code setup\n",
        "for epoch in range(50):\n",
        "    train_loss = train()\n",
        "    val_loss, _ = evaluate(X_test, y_test)\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}\")\n",
        "\n",
        "# Testing and metric evaluation\n",
        "test_loss, predictions = evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Calculate MSE, MAE, and R2 score\n",
        "predictions_np = predictions.detach().numpy()\n",
        "y_test_np = y_test.detach().numpy()\n",
        "mse = mean_squared_error(y_test_np, predictions_np)\n",
        "mae = mean_absolute_error(y_test_np, predictions_np)\n",
        "r2 = r2_score(y_test_np, predictions_np)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R^2:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZrcKObzRG7l",
        "outputId": "2bba0c81-50e3-45e2-b877-39066690f38d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([163, 1])) that is different to the input size (torch.Size([163])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([169, 1])) that is different to the input size (torch.Size([169])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 3.7964632511138916, Test Loss: 9.38429069519043\n",
            "Epoch 1, Train Loss: 13.24953556060791, Test Loss: 0.33392995595932007\n",
            "Epoch 2, Train Loss: 0.09004606306552887, Test Loss: 0.3703033924102783\n",
            "Epoch 3, Train Loss: 1.6288996934890747, Test Loss: 0.4809814393520355\n",
            "Epoch 4, Train Loss: 1.5751744508743286, Test Loss: 0.2334008365869522\n",
            "Epoch 5, Train Loss: 0.5389513373374939, Test Loss: 0.15834426879882812\n",
            "Epoch 6, Train Loss: 0.11232025176286697, Test Loss: 0.3438052535057068\n",
            "Epoch 7, Train Loss: 0.4404066801071167, Test Loss: 0.32538384199142456\n",
            "Epoch 8, Train Loss: 0.3810332715511322, Test Loss: 0.1509667932987213\n",
            "Epoch 9, Train Loss: 0.10194143652915955, Test Loss: 0.0833381935954094\n",
            "Epoch 10, Train Loss: 0.10461597889661789, Test Loss: 0.11791308224201202\n",
            "Epoch 11, Train Loss: 0.24323053658008575, Test Loss: 0.1361486315727234\n",
            "Epoch 12, Train Loss: 0.23960311710834503, Test Loss: 0.12063427269458771\n",
            "Epoch 13, Train Loss: 0.12763412296772003, Test Loss: 0.10912852734327316\n",
            "Epoch 14, Train Loss: 0.04747605323791504, Test Loss: 0.12145806849002838\n",
            "Epoch 15, Train Loss: 0.06033561751246452, Test Loss: 0.14020738005638123\n",
            "Epoch 16, Train Loss: 0.1119762510061264, Test Loss: 0.1351599097251892\n",
            "Epoch 17, Train Loss: 0.10890385508537292, Test Loss: 0.1145806536078453\n",
            "Epoch 18, Train Loss: 0.06332582980394363, Test Loss: 0.10200606286525726\n",
            "Epoch 19, Train Loss: 0.03059595264494419, Test Loss: 0.10536810755729675\n",
            "Epoch 20, Train Loss: 0.030631065368652344, Test Loss: 0.11669783294200897\n",
            "Epoch 21, Train Loss: 0.04726225882768631, Test Loss: 0.12406498938798904\n",
            "Epoch 22, Train Loss: 0.056869640946388245, Test Loss: 0.12249251455068588\n",
            "Epoch 23, Train Loss: 0.05091996490955353, Test Loss: 0.11496306210756302\n",
            "Epoch 24, Train Loss: 0.03684157878160477, Test Loss: 0.10731175541877747\n",
            "Epoch 25, Train Loss: 0.026317743584513664, Test Loss: 0.10346631705760956\n",
            "Epoch 26, Train Loss: 0.025206541642546654, Test Loss: 0.10361997038125992\n",
            "Epoch 27, Train Loss: 0.030531685799360275, Test Loss: 0.10566914081573486\n",
            "Epoch 28, Train Loss: 0.03481461480259895, Test Loss: 0.10815665125846863\n",
            "Epoch 29, Train Loss: 0.03347889706492424, Test Loss: 0.11152742803096771\n",
            "Epoch 30, Train Loss: 0.028176279738545418, Test Loss: 0.11667905747890472\n",
            "Epoch 31, Train Loss: 0.023684611544013023, Test Loss: 0.1229693815112114\n",
            "Epoch 32, Train Loss: 0.02287563681602478, Test Loss: 0.12800255417823792\n",
            "Epoch 33, Train Loss: 0.024804506450891495, Test Loss: 0.12927024066448212\n",
            "Epoch 34, Train Loss: 0.02659299224615097, Test Loss: 0.12596435844898224\n",
            "Epoch 35, Train Loss: 0.026331275701522827, Test Loss: 0.11946399509906769\n",
            "Epoch 36, Train Loss: 0.02432827837765217, Test Loss: 0.1123618483543396\n",
            "Epoch 37, Train Loss: 0.02222857065498829, Test Loss: 0.10696997493505478\n",
            "Epoch 38, Train Loss: 0.021323569118976593, Test Loss: 0.10437395423650742\n",
            "Epoch 39, Train Loss: 0.021636951714754105, Test Loss: 0.10443670302629471\n",
            "Epoch 40, Train Loss: 0.02227954752743244, Test Loss: 0.1063585951924324\n",
            "Epoch 41, Train Loss: 0.02238573506474495, Test Loss: 0.10920886695384979\n",
            "Epoch 42, Train Loss: 0.021759726107120514, Test Loss: 0.11217222362756729\n",
            "Epoch 43, Train Loss: 0.020858880132436752, Test Loss: 0.11456964164972305\n",
            "Epoch 44, Train Loss: 0.020268891006708145, Test Loss: 0.1158517524600029\n",
            "Epoch 45, Train Loss: 0.020189424976706505, Test Loss: 0.115697480738163\n",
            "Epoch 46, Train Loss: 0.02036549523472786, Test Loss: 0.11416177451610565\n",
            "Epoch 47, Train Loss: 0.020421355962753296, Test Loss: 0.11171270161867142\n",
            "Epoch 48, Train Loss: 0.02020891010761261, Test Loss: 0.1090756505727768\n",
            "Epoch 49, Train Loss: 0.019869983196258545, Test Loss: 0.10695412009954453\n",
            "Test Loss: 0.10695412009954453\n",
            "MSE: 0.08587073\n",
            "MAE: 0.23645245\n",
            "R^2: -7.837506290456858\n"
          ]
        }
      ]
    }
  ]
}